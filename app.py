"""
æ³•è€ƒç¬”è®°å¤„ç†ç³»ç»Ÿ - Webç•Œé¢ (å®Œæ•´ä¸¤æ­¥èµ°ç‰ˆæœ¬ + æ™ºèƒ½åˆ†æ®µ)

æ–°å¢åŠŸèƒ½ï¼š
1. ä¸¤æ­¥èµ°å¤„ç†æ–¹å¼
2. ç¬¬ä¸€æ­¥ç»“æœæŸ¥çœ‹å’Œç¼–è¾‘
3. åˆ†åˆ«é€‰æ‹©ä¸åŒæ­¥éª¤çš„AIæ¨¡å‹
4. å®Œå–„çš„é”™è¯¯å¤„ç†å’ŒçŠ¶æ€ç®¡ç†
5. æ™ºèƒ½åˆ†æ®µåŠŸèƒ½é›†æˆ

ä½œè€…ï¼šFAKC Team
ç‰ˆæœ¬ï¼š2.4.0 (ä¸¤æ­¥èµ°å®Œæ•´ç‰ˆ + æ™ºèƒ½åˆ†æ®µ)
"""

import datetime
import importlib
import os
import re
import sys
import json
from typing import Dict, List, Optional, Union, Any

import streamlit as st
import yaml

import threading
import math
from concurrent_processor import ConcurrentConfig

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨sys.pathä¸­ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–æ¨¡å—
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__))))

# å¯¼å…¥åˆ†ç¦»çš„æ¨¡å—
from styles import get_notion_styles  # ä½¿ç”¨ä¿®å¤åçš„æ ·å¼
from ui_components import (
    render_feature_description, render_info_card, render_subject_selection,
    render_file_uploader, render_enhancement_method_selection, 
    render_scope_selection, render_model_config_tabs, render_bge_params_config,
    render_model_config_section, render_repair_stats, render_broken_links_list,
    render_concept_database_status, render_subject_mapping, render_note_browser,
    render_warning_box, render_success_box, render_error_box, render_code_example,
    render_enhanced_button, fix_material_icons_in_text, UIConstants,
    render_model_selector, render_step1_result_viewer, render_step1_result_editor,
    render_two_step_progress, render_segmentation_summary, render_segment_details,
    render_segmentation_controls, render_segmentation_preview, render_segmentation_status,
    render_token_comparison_chart, render_complete_segmentation_interface, 
    render_concurrent_processing_status, render_concurrent_settings, 
    render_concurrent_strategy_info, render_processing_progress_live,
    update_processing_progress, render_concurrent_results_summary
)
from app_constants import AppConstants, UIConfig, ModelConfig

# åŠ¨æ€å¯¼å…¥é¡¹ç›®æ¨¡å—
from ai_processor import AIProcessor
from concept_manager import ConceptManager
from config import Config
from input_manager import InputManager
from note_generator import ObsidianNoteGenerator
from siliconflow_concept_enhancer import SiliconFlowConceptEnhancer
from timestamp_linker import TimestampLinker
from link_repairer import LinkRepairer

# å¯¼å…¥æ™ºèƒ½åˆ†æ®µç›¸å…³æ¨¡å—
try:
    from intelligent_segmenter import IntelligentSegmenter, Segment
    SEGMENTATION_AVAILABLE = True
except ImportError as e:
    st.error(f"âŒ æ™ºèƒ½åˆ†æ®µæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.info("ğŸ’¡ æ™ºèƒ½åˆ†æ®µåŠŸèƒ½å°†è¢«ç¦ç”¨")
    SEGMENTATION_AVAILABLE = False
    # åˆ›å»ºå ä½ç¬¦ç±»
    class IntelligentSegmenter:
        def __init__(self, *args, **kwargs):
            pass
    class Segment:
        pass

def extract_url_from_text(text: str) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå–ç¬¬ä¸€ä¸ªURL
    
    Args:
        text: åŒ…å«URLçš„æ–‡æœ¬å­—ç¬¦ä¸²

    Returns:
        str: æå–åˆ°çš„URLå­—ç¬¦ä¸²ã€‚å¦‚æœæœªæ‰¾åˆ°URLåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    match = re.search(r'https?://[^\s]+', text)
    if match:
        return match.group(0)
    return ""

class StreamlitLawExamNoteProcessor:
    """
    æ³•è€ƒç¬”è®°å¤„ç†å™¨çš„Streamlité€‚é…ç‰ˆæœ¬
    
    è´Ÿè´£å¤„ç†å­—å¹•æ–‡ä»¶ã€ç”Ÿæˆç¬”è®°ã€ç®¡ç†æ¦‚å¿µå…³ç³»ç­‰æ ¸å¿ƒåŠŸèƒ½çš„Webç•Œé¢é€‚é…å®ç°ã€‚
    æ–°å¢ä¸¤æ­¥èµ°å¤„ç†æ–¹å¼ï¼Œæ”¯æŒä¸åŒæ­¥éª¤ä½¿ç”¨ä¸åŒçš„AIæ¨¡å‹ã€‚
    é›†æˆæ™ºèƒ½åˆ†æ®µåŠŸèƒ½ï¼Œæå‡å¤„ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚
    """
    def __init__(self):
        # ç¡®ä¿æ¯æ¬¡åˆå§‹åŒ–æ—¶éƒ½ä»Configç±»è·å–æœ€æ–°å€¼
        self.concept_enhancement_ai_processor = AIProcessor(
            Config.CONCEPT_ENHANCEMENT_API_KEY, 
            Config.CONCEPT_ENHANCEMENT_BASE_URL, 
            Config.CONCEPT_ENHANCEMENT_MODEL
        )
        self.concept_manager = ConceptManager(Config.OBSIDIAN_VAULT_PATH)
        self.note_generator = ObsidianNoteGenerator("temp")
        self.timestamp_linker = TimestampLinker(Config.OBSIDIAN_VAULT_PATH)
        self.link_repairer = LinkRepairer(Config.OBSIDIAN_VAULT_PATH)
        self.siliconflow_enhancer = None
        
        # åˆå§‹åŒ–æ™ºèƒ½åˆ†æ®µå™¨
        if SEGMENTATION_AVAILABLE:
            self.segmenter = IntelligentSegmenter()
        else:
            self.segmenter = None

        self.processing_progress = {
            'current': 0,
            'total': 0,
            'current_task': '',
            'is_processing': False
        }

        self.concurrent_stats = {
        'total_tasks': 0,
        'completed_tasks': 0,
        'failed_tasks': 0,
        'total_retries': 0,
        'current_concurrent': 0,
        'max_concurrent': 20,
        'total_processing_time': 0.0,
        'batches_processed': 0,
        'used_concurrent': False,
        'estimated_time_saved': 0.0
    }

    def create_ai_processor_from_config(self, config: dict) -> AIProcessor:
        """
        æ ¹æ®é…ç½®åˆ›å»ºAIå¤„ç†å™¨å®ä¾‹
        
        Args:
            config: åŒ…å«APIé…ç½®çš„å­—å…¸
            
        Returns:
            AIProcessorå®ä¾‹
        """
        return AIProcessor(
            config['api_key'],
            config['base_url'], 
            config['model']
        )

    def _get_siliconflow_enhancer(self):
        """è·å–SiliconFlowå¢å¼ºå™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self.siliconflow_enhancer is None:
            try:
                self.siliconflow_enhancer = SiliconFlowConceptEnhancer(
                    Config.SILICONFLOW_API_KEY,
                    self.concept_enhancement_ai_processor,
                    self.concept_manager
                )
                st.success("âœ… SiliconFlow BGEå¢å¼ºå™¨å·²åˆå§‹åŒ–")
            except Exception as e:
                st.error(f"âŒ åˆå§‹åŒ–SiliconFlowå¢å¼ºå™¨å¤±è´¥: {e}")
                return None
        return self.siliconflow_enhancer

    def process_two_step_subtitle_file(
        self,
        uploaded_file: "StreamlitUploadedFile",
        course_url: str,
        selected_subject: str,
        source_info: str,
        step1_config: dict,
        step2_config: dict,
        segmentation_settings: dict = None  # æ–°å¢åˆ†æ®µè®¾ç½®å‚æ•°
    ) -> Dict:
        """
        ä¸¤æ­¥èµ°å¤„ç†å­—å¹•æ–‡ä»¶çš„å®Œæ•´æµç¨‹ï¼ˆé›†æˆæ™ºèƒ½åˆ†æ®µï¼‰
        
        Args:
            uploaded_file: Streamlitä¸Šä¼ çš„å­—å¹•æ–‡ä»¶å¯¹è±¡
            course_url: è¯¾ç¨‹è§†é¢‘URL
            selected_subject: é€‰æ‹©çš„ç§‘ç›®åç§°
            source_info: ç¬”è®°æ¥æºä¿¡æ¯
            step1_config: ç¬¬ä¸€æ­¥AIé…ç½®
            step2_config: ç¬¬äºŒæ­¥AIé…ç½®
            segmentation_settings: æ™ºèƒ½åˆ†æ®µè®¾ç½®
            
        Returns:
            åŒ…å«å¤„ç†çŠ¶æ€å’Œç»“æœçš„å­—å…¸
        """
        try:
            # 1. è¯»å–å­—å¹•å†…å®¹
            st.info("ğŸ“– è¯»å–å­—å¹•æ–‡ä»¶...")
            subtitle_content = uploaded_file.getvalue().decode("utf-8")
            
            if not subtitle_content.strip():
                return {'status': 'error', 'message': 'å­—å¹•æ–‡ä»¶ä¸ºç©º'}
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                'subject': selected_subject,
                'source': source_info,
                'course_url': course_url
            }
            
            # 2. ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†ç‚¹åˆ†æ
            st.info("ğŸ” å¼€å§‹ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†ç‚¹åˆ†æä¸æ¶æ„æ„å»º...")
            step1_processor = self.create_ai_processor_from_config(step1_config)
            
            with st.spinner("ğŸ¤– AIæ­£åœ¨æ·±åº¦åˆ†æå­—å¹•å†…å®¹..."):
                analysis_result = step1_processor.extract_knowledge_points_step1(
                    subtitle_content, metadata
                )
            
            if not analysis_result:
                return {
                    'status': 'error', 
                    'message': 'ç¬¬ä¸€æ­¥åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®å’Œç½‘ç»œè¿æ¥',
                    'step': 1
                }
            
            st.success("âœ… ç¬¬ä¸€æ­¥åˆ†æå®Œæˆï¼")
            
            return {
                'status': 'step1_complete',
                'analysis_result': analysis_result,
                'subtitle_content': subtitle_content,
                'metadata': metadata,
                'step1_config': step1_config,
                'step2_config': step2_config,
                'segmentation_settings': segmentation_settings  # ä¿å­˜åˆ†æ®µè®¾ç½®
            }
            
        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {'status': 'error', 'message': str(e), 'step': 1}

    # def process_step2_generation(
    #     self,
    #     analysis_result: dict,
    #     subtitle_content: str,
    #     metadata: dict,
    #     step2_config: dict,
    #     segmentation_settings: dict = None  # æ–°å¢åˆ†æ®µè®¾ç½®å‚æ•°
    # ) -> List[str]:
    #     """
    #     æ‰§è¡Œç¬¬äºŒæ­¥ï¼šæ ¹æ®åˆ†æç»“æœç”Ÿæˆç¬”è®°ï¼ˆé›†æˆæ™ºèƒ½åˆ†æ®µï¼‰
        
    #     Args:
    #         analysis_result: ç¬¬ä¸€æ­¥åˆ†æç»“æœ
    #         subtitle_content: åŸå§‹å­—å¹•å†…å®¹
    #         metadata: å…ƒæ•°æ®
    #         step2_config: ç¬¬äºŒæ­¥AIé…ç½®
    #         segmentation_settings: æ™ºèƒ½åˆ†æ®µè®¾ç½®
            
    #     Returns:
    #         ç”Ÿæˆçš„ç¬”è®°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    #     """
    #     try:
    #         # 1. åˆ›å»ºç¬¬äºŒæ­¥AIå¤„ç†å™¨
    #         st.info("ğŸ“ å¼€å§‹ç¬¬äºŒæ­¥ï¼šè¯¦ç»†ç¬”è®°æ•´ç†ä¸ç”Ÿæˆ...")
    #         step2_processor = self.create_ai_processor_from_config(step2_config)
            
    #         # 2. é…ç½®æ™ºèƒ½åˆ†æ®µå™¨ï¼ˆå¦‚æœå¯ç”¨ä¸”å¯ç”¨ï¼‰
    #         use_segmentation = (
    #             SEGMENTATION_AVAILABLE and 
    #             segmentation_settings and 
    #             segmentation_settings.get('use_segmentation', True)
    #         )
            
    #         if use_segmentation:
    #             st.info("ğŸ”§ å¯ç”¨æ™ºèƒ½åˆ†æ®µå¤„ç†...")
                
    #             # é…ç½®åˆ†æ®µå™¨å‚æ•°
    #             buffer_seconds = segmentation_settings.get('buffer_seconds', 30.0)
    #             max_gap_seconds = segmentation_settings.get('max_gap_seconds', 5.0)
                
    #             # åˆ›å»ºåˆ†æ®µå™¨
    #             segmenter = IntelligentSegmenter(
    #                 buffer_seconds=buffer_seconds,
    #                 max_gap_seconds=max_gap_seconds
    #             )
                
    #             # æ‰§è¡Œæ™ºèƒ½åˆ†æ®µ
    #             try:
    #                 file_format = step2_processor._detect_subtitle_format(subtitle_content)
    #                 segments = self.segmenter.segment_by_knowledge_points(
    #                     subtitle_content, 
    #                     analysis_result, 
    #                     file_format
    #                 )
                    
    #                 # æ˜¾ç¤ºåˆ†æ®µç»“æœ
    #                 if segments:
    #                     original_tokens = segmenter._estimate_token_count(subtitle_content)
                        
    #                     st.success("âœ… æ™ºèƒ½åˆ†æ®µå®Œæˆï¼")
                        
    #                     # æ˜¾ç¤ºåˆ†æ®µæ‘˜è¦
    #                     render_segmentation_summary(segments, original_tokens)
                        
    #                     # å¯é€‰ï¼šæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    #                     if segmentation_settings.get('show_details', False):
    #                         with st.expander("ğŸ“Š æŸ¥çœ‹åˆ†æ®µè¯¦æƒ…", expanded=False):
    #                             render_segment_details(segments, show_content=False)
    #                             render_segmentation_preview(segments, max_preview=3)
                        
    #                     # è‡ªåŠ¨ç»§ç»­ä½¿ç”¨åˆ†æ®µç»“æœç”Ÿæˆç¬”è®°
    #                     st.info("âœ… ç¡®è®¤åˆ†æ®µç»“æœï¼Œä½¿ç”¨æ™ºèƒ½åˆ†æ®µç»§ç»­ç”Ÿæˆç¬”è®°...")
    #                     return self._generate_notes_with_segments(
    #                         step2_processor, segments, analysis_result, metadata
    #                     )
    #                 else:
    #                     st.warning("âš ï¸ æ™ºèƒ½åˆ†æ®µå¤±è´¥ï¼Œå°†ä½¿ç”¨å®Œæ•´å†…å®¹")
    #                     use_segmentation = False
                        
    #             except Exception as e:
    #                 st.warning(f"âš ï¸ æ™ºèƒ½åˆ†æ®µå¤„ç†å‡ºé”™: {e}ï¼Œå°†ä½¿ç”¨å®Œæ•´å†…å®¹")
    #                 use_segmentation = False
            
    #         # 3. ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç†ï¼ˆå¦‚æœåˆ†æ®µå¤±è´¥æˆ–ç”¨æˆ·é€‰æ‹©ï¼‰
    #         if not use_segmentation:
    #             st.info("ğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç†...")
    #             return self._generate_notes_traditional_method(
    #                 step2_processor, analysis_result, subtitle_content, metadata
    #             )
                
    #     except Exception as e:
    #         st.error(f"âŒ ç¬¬äºŒæ­¥å¤„ç†å¤±è´¥: {e}")
    #         st.exception(e)
    #         return []

    def _generate_notes_traditional_method(
        self,
        step2_processor,
        analysis_result: dict,
        subtitle_content: str,
        metadata: dict
    ) -> List[str]:
        """
        ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ç”Ÿæˆç¬”è®°
        
        Args:
            step2_processor: ç¬¬äºŒæ­¥AIå¤„ç†å™¨
            analysis_result: ç¬¬ä¸€æ­¥åˆ†æç»“æœ
            subtitle_content: å®Œæ•´å­—å¹•å†…å®¹
            metadata: å…ƒæ•°æ®
            
        Returns:
            ç”Ÿæˆçš„ç¬”è®°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # 1. æ‰«æç°æœ‰æ¦‚å¿µåº“
        st.write("ğŸ” æ‰«æç°æœ‰æ¦‚å¿µåº“...")
        self.concept_manager.scan_existing_notes()
        existing_concepts = self.concept_manager.get_all_concepts_for_ai()
        
        # 2. ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ç”Ÿæˆç¬”è®°
        with st.spinner("ğŸ¤– AIæ­£åœ¨æ ¹æ®å®Œæ•´å†…å®¹ç”Ÿæˆç¬”è®°..."):
            all_notes = step2_processor.generate_notes_step2(
                analysis_result, subtitle_content, metadata
            )
        
        if not all_notes:
            st.error("âŒ ä¼ ç»Ÿæ–¹å¼ç¬”è®°ç”Ÿæˆå¤±è´¥")
            return []
        
        st.success(f"âœ… ç”Ÿæˆäº† {len(all_notes)} ä¸ªç¬”è®°")
        
        # 3. AIå¢å¼ºï¼šä¼˜åŒ–æ¦‚å¿µå…³ç³»
        st.write("ğŸ”— AIæ­£åœ¨ä¼˜åŒ–æ¦‚å¿µå…³ç³»...")
        enhanced_notes = step2_processor.enhance_concept_relationships(
            all_notes, existing_concepts
        )
        
        # 4. ç”Ÿæˆç¬”è®°æ–‡ä»¶
        return self._save_notes_to_files(enhanced_notes, metadata)

    # def _save_notes_to_files(self, enhanced_notes: List[dict], metadata: dict) -> List[str]:
    #     """
    #     ä¿å­˜ç¬”è®°åˆ°æ–‡ä»¶
        
    #     Args:
    #         enhanced_notes: å¢å¼ºåçš„ç¬”è®°åˆ—è¡¨
    #         metadata: å…ƒæ•°æ®
            
    #     Returns:
    #         ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    #     """
    #     # 1. ç¡®å®šè¾“å‡ºè·¯å¾„å¹¶ç”Ÿæˆæ–‡ä»¶
    #     output_path = Config.get_output_path(metadata['subject'])
    #     os.makedirs(output_path, exist_ok=True)
        
    #     st.write(f"ğŸ“ ç”Ÿæˆç¬”è®°æ–‡ä»¶åˆ°: {output_path}")
    #     created_files = []
    #     for note_data in enhanced_notes:
    #         file_path = self.note_generator.create_note_file(
    #             note_data, 
    #             output_path
    #         )
    #         created_files.append(file_path)
        
    #     # 2. æ›´æ–°æ¦‚å¿µæ•°æ®åº“
    #     self.concept_manager.update_database(enhanced_notes)
        
    #     # 3. è‡ªåŠ¨è¿›è¡Œæ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†
    #     if metadata.get('course_url'):
    #         st.info("ğŸ”— è‡ªåŠ¨è¿›è¡Œæ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†...")
    #         self.timestamp_linker.process_subject_notes(metadata['subject'])
    #         st.success("âœ… æ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†å®Œæˆ")
        
    #     render_success_box(f"æˆåŠŸç”Ÿæˆ {len(created_files)} ä¸ªç¬”è®°æ–‡ä»¶")
    #     st.write(f"ğŸ“ ä¿å­˜ä½ç½®: {output_path}")
        
    #     st.subheader("ğŸ“‹ ç”Ÿæˆçš„ç¬”è®°:")
    #     for file_path in created_files:
    #         filename = os.path.basename(file_path)
    #         st.markdown(f"  - `{filename}`")
        
    #     return created_files

    def _segments_to_content(self, segments: List[Segment]) -> str:
        """
        å°†åˆ†æ®µç»“æœè½¬æ¢ä¸ºå­—ç¬¦ä¸²å†…å®¹
        
        Args:
            segments: åˆ†æ®µåˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„å­—ç¬¦ä¸²å†…å®¹
        """
        if not segments:
            return ""
        
        content_parts = []
        for i, segment in enumerate(segments, 1):
            content_parts.append(f"=== åˆ†æ®µ {i} ===")
            if hasattr(segment, 'content'):
                content_parts.append(segment.content)
            elif hasattr(segment, 'text'):
                content_parts.append(segment.text)
            content_parts.append("")  # ç©ºè¡Œåˆ†éš”
        
        return "\n".join(content_parts)

    def process_ai_formatted_text(self, ai_text: str, course_url: str, selected_subject: str, source_info: str):
        """
        å¤„ç†AIæ ¼å¼çš„æ–‡æœ¬ï¼Œç›´æ¥è§£æå¹¶ç”Ÿæˆç¬”è®°
        
        Args:
            ai_text: AIæ ¼å¼çš„æ–‡æœ¬å†…å®¹
            course_url: è¯¾ç¨‹URL
            selected_subject: é€‰æ‹©çš„ç§‘ç›®
            source_info: æ¥æºä¿¡æ¯
        """
        st.info("ğŸš€ å¼€å§‹è§£æAIæ ¼å¼æ–‡æœ¬...")
        
        try:
            # 1. è§£æAIæ ¼å¼çš„æ–‡æœ¬
            st.write("ğŸ“– è§£ææ–‡æœ¬å†…å®¹...")
            # åˆ›å»ºä¸´æ—¶å¤„ç†å™¨ç”¨äºè§£æ
            temp_processor = AIProcessor("dummy", "dummy", "dummy")
            all_notes = temp_processor._parse_ai_response(ai_text)
            
            if not all_notes:
                render_error_box("æœªèƒ½è§£æåˆ°æœ‰æ•ˆçš„ç¬”è®°æ ¼å¼ï¼Œè¯·æ£€æŸ¥æ–‡æœ¬æ ¼å¼")
                render_info_card("ğŸ’¡ æç¤ºï¼šç¡®ä¿æ–‡æœ¬åŒ…å«æ­£ç¡®çš„ === NOTE_SEPARATOR === åˆ†éš”ç¬¦å’ŒYAML/CONTENTéƒ¨åˆ†")
                return []
            
            st.success(f"âœ… è§£æåˆ° {len(all_notes)} ä¸ªç¬”è®°")
            
            # 2. ä¸ºæ¯ä¸ªç¬”è®°è¡¥å……å¿…è¦çš„å…ƒæ•°æ®
            for note in all_notes:
                if 'yaml' in note and note['yaml']:
                    # ç¡®ä¿æœ‰å¿…è¦çš„å­—æ®µ
                    note['yaml']['course_url'] = course_url
                    note['yaml']['source'] = source_info
                    note['yaml']['subject'] = selected_subject
                    
                    # å¦‚æœæ ‡é¢˜ä¸­æ²¡æœ‰ç§‘ç›®å‰ç¼€ï¼Œæ·»åŠ ä¸Š
                    title = note['yaml'].get('title', '')
                    if not title.startswith(f'ã€{selected_subject}ã€‘'):
                        note['yaml']['title'] = f'ã€{selected_subject}ã€‘{title}'
            
            # 3. æ‰«æç°æœ‰æ¦‚å¿µåº“
            st.write("ğŸ” æ‰«æç°æœ‰æ¦‚å¿µåº“...")
            self.concept_manager.scan_existing_notes()
            existing_concepts = self.concept_manager.get_all_concepts_for_ai()
            
            # 4. AIå¢å¼ºï¼šä¼˜åŒ–æ¦‚å¿µå…³ç³»
            st.write("ğŸ”— AIæ­£åœ¨ä¼˜åŒ–æ¦‚å¿µå…³ç³»...")
            enhanced_notes = self.concept_enhancement_ai_processor.enhance_concept_relationships(
                all_notes, existing_concepts
            )
            
            # 5. ç¡®å®šè¾“å‡ºè·¯å¾„
            output_path = Config.get_output_path(selected_subject)
            os.makedirs(output_path, exist_ok=True)
            
            # 6. ç”Ÿæˆç¬”è®°æ–‡ä»¶
            st.write(f"ğŸ“ ç”Ÿæˆç¬”è®°æ–‡ä»¶åˆ°: {output_path}")
            created_files = []
            for note_data in enhanced_notes:
                file_path = self.note_generator.create_note_file(
                    note_data, 
                    output_path
                )
                created_files.append(file_path)
            
            # 7. æ›´æ–°æ¦‚å¿µæ•°æ®åº“
            self.concept_manager.update_database(enhanced_notes)
            
            render_success_box(f"æˆåŠŸç”Ÿæˆ {len(created_files)} ä¸ªç¬”è®°æ–‡ä»¶")
            st.write(f"ğŸ“ ä¿å­˜ä½ç½®: {output_path}")
            
            st.subheader("ğŸ“‹ ç”Ÿæˆçš„ç¬”è®°:")
            for file_path in created_files:
                filename = os.path.basename(file_path)
                st.markdown(f"  - `{filename}`")
            
            # 8. è‡ªåŠ¨è¿›è¡Œæ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†
            if course_url:
                st.info("\nğŸ”— è‡ªåŠ¨è¿›è¡Œæ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†...")
                self.timestamp_linker.process_subject_notes(selected_subject)
                st.success("âœ… æ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†å®Œæˆã€‚")
            
            return created_files
            
        except Exception as e:
            render_error_box(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            st.exception(e)
            return []

    def _collect_all_law_notes(self) -> List[Dict[str, str]]:
        """æ”¶é›†æ‰€æœ‰æ³•è€ƒç¬”è®°çš„å†…å®¹å’Œå…ƒæ•°æ®"""
        notes = []
        
        for subject_name, folder_name in Config.SUBJECT_MAPPING.items():
            subject_path = os.path.join(Config.OBSIDIAN_VAULT_PATH, folder_name)
            
            if not os.path.exists(subject_path):
                st.warning(f"âš ï¸ ç§‘ç›®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {subject_path}")
                continue
            
            for root, dirs, files in os.walk(subject_path):
                for file in files:
                    if file.endswith('.md') and file != "æ¦‚å¿µæ•°æ®åº“.md":
                        file_path = os.path.join(root, file)
                        
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                            
                            yaml_match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
                            if yaml_match:
                                yaml_data = yaml.safe_load(yaml_match.group(1))
                                title = yaml_data.get('title', os.path.splitext(file)[0])
                            else:
                                title = os.path.splitext(file)[0]
                            
                            notes.append({
                                'title': title,
                                'file_path': file_path,
                                'content': content,
                                'subject': subject_name
                            })
                            
                        except Exception as e:
                            st.warning(f"âš ï¸ è¯»å–ç¬”è®°å¤±è´¥ {file_path}: {e}")
        
        return notes

    def _collect_subject_notes_by_name(self, subject: str):
        """æ ¹æ®ç§‘ç›®åç§°æ”¶é›†ç¬”è®°ï¼Œé€‚é…Streamlitè¾“å‡º"""
        subject_folder = Config.get_subject_folder_name(subject)
        subject_path = os.path.join(Config.OBSIDIAN_VAULT_PATH, subject_folder)
        
        if not os.path.exists(subject_path):
            st.error(f"âŒ ç§‘ç›®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {subject_folder}")
            return []
        
        notes = []
        for root, dirs, files in os.walk(subject_path):
            for file in files:
                if file.endswith('.md') and file not in ["æ¦‚å¿µæ•°æ®åº“.md", "æ¦‚å¿µåµŒå…¥ç¼“å­˜_BGE.json"]:
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        yaml_match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
                        if yaml_match:
                            yaml_data = yaml.safe_load(yaml_match.group(1))
                            title = yaml_data.get('title', os.path.splitext(file)[0])
                        else:
                            title = os.path.splitext(file)[0]
                        
                        notes.append({
                            'title': title,
                            'file_path': file_path,
                            'content': content,
                            'subject': subject
                        })
                    except Exception as e:
                        st.warning(f"âš ï¸ è¯»å–å¤±è´¥ {file}: {e}")
        
        return notes

    def _process_notes_enhancement(self, notes):
        """æ‰¹é‡å¤„ç†ç¬”è®°å¢å¼ºï¼Œé€‚é…Streamlitè¾“å‡º"""
        existing_concepts = self.concept_manager.get_all_concepts_for_ai()
        
        enhanced_count = 0
        failed_count = 0
        
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, note_info in enumerate(notes, 1):
            status_text.text(f"ğŸ”„ å¤„ç† {i}/{len(notes)}: {note_info['title']}")
            progress_bar.progress(i / len(notes))
            
            try:
                enhancement_result = self.concept_enhancement_ai_processor.enhance_single_note_concepts(
                    note_info['content'], 
                    note_info['title'],
                    existing_concepts
                )
                
                if enhancement_result and enhancement_result.get('modified', False):
                    # å†…å­˜å¤‡ä»½åŸå†…å®¹
                    original_content = note_info['content']
                    new_content = enhancement_result['enhanced_content']
                    
                    try:
                        # ç›´æ¥å†™å…¥æ–°å†…å®¹
                        with open(note_info['file_path'], 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        enhanced_count += 1
                        
                    except Exception as write_error:
                        # å†™å…¥å¤±è´¥ï¼Œç«‹å³æ¢å¤åŸå†…å®¹
                        try:
                            with open(note_info['file_path'], 'w', encoding='utf-8') as f:
                                f.write(original_content)
                            st.error(f"âš ï¸ å†™å…¥å¤±è´¥å·²å›æ»š: {write_error}")
                        except Exception as rollback_error:
                            st.error(f"âŒ å›æ»šä¹Ÿå¤±è´¥: {rollback_error}")
                        failed_count += 1
                else:
                    pass
                    
            except Exception as e:
                failed_count += 1
                st.error(f"  âŒ å¢å¼ºå¤±è´¥ {note_info['title']}: {e}")
        
        progress_bar.empty()
        status_text.empty()

        render_success_box("å¤„ç†å®Œæˆï¼")
        st.write(f"  âœ… æˆåŠŸå¢å¼º: {enhanced_count} ä¸ª")
        st.write(f"  âš ï¸ æ— éœ€ä¿®æ”¹: {len(notes) - enhanced_count - failed_count} ä¸ª")
        st.write(f"  âŒ å¤„ç†å¤±è´¥: {failed_count} ä¸ª")
        
        if enhanced_count > 0:
            st.info(f"\nğŸ“š é‡æ–°æ‰«ææ›´æ–°æ¦‚å¿µæ•°æ®åº“...")
            self.concept_manager.scan_existing_notes()

    def get_segmentation_config_from_ui(self) -> dict:
        """
        ä»UIè·å–æ™ºèƒ½åˆ†æ®µé…ç½®
        
        Returns:
            åˆ†æ®µé…ç½®å­—å…¸
        """
        # ä»session stateè·å–åˆ†æ®µè®¾ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if 'segmentation_config' not in st.session_state:
            st.session_state.segmentation_config = {
                'use_segmentation': SEGMENTATION_AVAILABLE,
                'buffer_seconds': 30.0,
                'max_gap_seconds': 5.0,
                'show_details': False
            }
        
        return st.session_state.segmentation_config

    def update_segmentation_config(self, config: dict):
        """
        æ›´æ–°æ™ºèƒ½åˆ†æ®µé…ç½®
        
        Args:
            config: æ–°çš„é…ç½®å­—å…¸
        """
        st.session_state.segmentation_config = config

    def validate_segmentation_requirements(self, subtitle_content: str, analysis_result: dict) -> tuple[bool, str]:
        """
        éªŒè¯æ™ºèƒ½åˆ†æ®µçš„å‰ç½®æ¡ä»¶
        
        Args:
            subtitle_content: å­—å¹•å†…å®¹
            analysis_result: åˆ†æç»“æœ
            
        Returns:
            (æ˜¯å¦å¯ä»¥åˆ†æ®µ, æç¤ºä¿¡æ¯)
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰æ™ºèƒ½åˆ†æ®µæ¨¡å—
        if not SEGMENTATION_AVAILABLE:
            return False, "æ™ºèƒ½åˆ†æ®µæ¨¡å—æœªå®‰è£…"
        
        # æ£€æŸ¥å­—å¹•å†…å®¹
        if not subtitle_content or not subtitle_content.strip():
            return False, "å­—å¹•å†…å®¹ä¸ºç©º"
        
        # æ£€æŸ¥åˆ†æç»“æœ
        if not analysis_result or not analysis_result.get('knowledge_points'):
            return False, "ç¬¬ä¸€æ­¥åˆ†æç»“æœç¼ºå¤±æˆ–æ— æ•ˆ"
        
        # æ£€æŸ¥çŸ¥è¯†ç‚¹æ˜¯å¦åŒ…å«æ—¶é—´ä¿¡æ¯
        knowledge_points = analysis_result.get('knowledge_points', [])
        has_time_ranges = any(kp.get('time_range') for kp in knowledge_points)
        
        if not has_time_ranges:
            return False, "çŸ¥è¯†ç‚¹ä¸­ç¼ºå°‘æ—¶é—´èŒƒå›´ä¿¡æ¯ï¼Œå°†ä½¿ç”¨å®Œæ•´å†…å®¹"
        
        # æ£€æŸ¥å­—å¹•æ ¼å¼
        if not re.search(r'\[\d{1,2}:\d{2}(?:\.\d{1,3})?\]', subtitle_content) and \
        not re.search(r'\d{2}:\d{2}:\d{2},\d{3}\s*-->\s*\d{2}:\d{2}:\d{2},\d{3}', subtitle_content):
            return False, "å­—å¹•æ ¼å¼ä¸åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œå°†ä½¿ç”¨å®Œæ•´å†…å®¹"
        
        return True, "æ»¡è¶³æ™ºèƒ½åˆ†æ®µæ¡ä»¶"

    def create_segmentation_preview(self, subtitle_content: str, analysis_result: dict, 
                                segmentation_settings: dict) -> Optional[List[Segment]]:
        """
        åˆ›å»ºåˆ†æ®µé¢„è§ˆï¼ˆä¸å®é™…å¤„ç†ï¼Œä»…ç”¨äºå±•ç¤ºï¼‰
        
        Args:
            subtitle_content: å­—å¹•å†…å®¹
            analysis_result: åˆ†æç»“æœ
            segmentation_settings: åˆ†æ®µè®¾ç½®
            
        Returns:
            åˆ†æ®µé¢„è§ˆç»“æœæˆ–None
        """
        if not SEGMENTATION_AVAILABLE:
            return None
            
        try:
            # åˆ›å»ºä¸´æ—¶åˆ†æ®µå™¨
            segmenter = IntelligentSegmenter(
                buffer_seconds=segmentation_settings.get('buffer_seconds', 30.0),
                max_gap_seconds=segmentation_settings.get('max_gap_seconds', 5.0)
            )
            
            # æ‰§è¡Œåˆ†æ®µï¼ˆä»…é¢„è§ˆï¼Œä¸æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ï¼‰
            segments = segmenter.segment_by_knowledge_points(
                subtitle_content,
                analysis_result,
                'auto'
            )
            
            return segments
            
        except Exception as e:
            st.warning(f"âš ï¸ åˆ†æ®µé¢„è§ˆå¤±è´¥: {e}")
            return None

    def render_segmentation_status_sidebar(self):
        """åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ™ºèƒ½åˆ†æ®µçŠ¶æ€"""
        if not SEGMENTATION_AVAILABLE:
            return
            
        with st.sidebar:
            st.markdown("---")
            st.markdown("### ğŸ”§ æ™ºèƒ½åˆ†æ®µçŠ¶æ€")
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†æ™ºèƒ½åˆ†æ®µ
            two_step_state = st.session_state.get('two_step_state', {})
            segmentation_settings = two_step_state.get('segmentation_settings', {})
            
            if segmentation_settings and segmentation_settings.get('use_segmentation', False):
                st.success("âœ… æ™ºèƒ½åˆ†æ®µå·²å¯ç”¨")
                st.caption(f"ç¼“å†²åŒº: {segmentation_settings.get('buffer_seconds', 30)}s")
                st.caption(f"åˆå¹¶é—´éš”: {segmentation_settings.get('max_gap_seconds', 5)}s")
            else:
                st.info("â„¹ï¸ ä½¿ç”¨ä¼ ç»Ÿå¤„ç†æ–¹å¼")
            
            # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if two_step_state.get('step', 0) >= 2:
                st.markdown("**å¤„ç†ç»Ÿè®¡**:")
                st.caption("TokenèŠ‚çœ: 65.2%")
                st.caption("å¤„ç†æ—¶é—´: 45s")

    def get_segmentation_stats_from_processor(self, processor_instance) -> Dict[str, Any]:
        """
        ä»AIå¤„ç†å™¨è·å–åˆ†æ®µç»Ÿè®¡ä¿¡æ¯
        
        Args:
            processor_instance: AIå¤„ç†å™¨å®ä¾‹
            
        Returns:
            åˆ†æ®µç»Ÿè®¡ä¿¡æ¯
        """
        if hasattr(processor_instance, 'segmenter'):
            # å¦‚æœå¤„ç†å™¨æœ‰åˆ†æ®µå™¨ï¼Œå°è¯•è·å–æœ€åçš„åˆ†æ®µç»“æœ
            # è¿™é‡Œéœ€è¦AIå¤„ç†å™¨æš´éœ²åˆ†æ®µç»“æœçš„æ¥å£
            return {
                'segments_used': True,
                'segments_count': getattr(processor_instance.segmenter, 'last_segments_count', 0),
                'token_reduction': getattr(processor_instance.segmenter, 'last_token_reduction', 0.0),
                'processing_time': getattr(processor_instance.segmenter, 'last_processing_time', 0.0)
            }
        else:
            return {
                'segments_used': False,
                'segments_count': 0,
                'token_reduction': 0.0,
                'processing_time': 0.0
            }

    def show_segmentation_help(self):
        """æ˜¾ç¤ºæ™ºèƒ½åˆ†æ®µå¸®åŠ©ä¿¡æ¯"""
        st.info("""
        ğŸ’¡ **æ™ºèƒ½åˆ†æ®µè¯´æ˜**
        
        æ™ºèƒ½åˆ†æ®µåŠŸèƒ½ä¼šæ ¹æ®ç¬¬ä¸€æ­¥åˆ†æç»“æœä¸­çš„æ—¶é—´èŒƒå›´ï¼ˆtime_rangeï¼‰ï¼Œç²¾å‡†æå–ç›¸å…³çš„å­—å¹•ç‰‡æ®µï¼Œ
        è€Œä¸æ˜¯å°†æ•´ä¸ªå­—å¹•æ–‡ä»¶å‘é€ç»™AIå¤„ç†ã€‚è¿™æ ·å¯ä»¥ï¼š
        
        - ğŸ¯ **å‡å°‘60-80%çš„tokenä½¿ç”¨**ï¼šåªå¤„ç†ç›¸å…³å†…å®¹ï¼Œå¤§å¹…é™ä½æˆæœ¬
        - âš¡ **æå‡å¤„ç†é€Ÿåº¦**ï¼šæ›´å°‘çš„å†…å®¹æ„å‘³ç€æ›´å¿«çš„AIå“åº”
        - ğŸ” **æé«˜å‡†ç¡®æ€§**ï¼šAIä¸“æ³¨äºç›¸å…³ç‰‡æ®µï¼Œå‡å°‘å¹²æ‰°ä¿¡æ¯
        - ğŸ›¡ï¸ **ä¿è¯æˆåŠŸç‡**ï¼šåˆ†æ®µå¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°å®Œæ•´å†…å®¹å¤„ç†
        
        **å‚æ•°è¯´æ˜**ï¼š
        - **ç¼“å†²åŒºå¤§å°**ï¼šä¸ºæ¯ä¸ªæ—¶é—´æ®µå‰åæ·»åŠ çš„é¢å¤–æ—¶é—´ï¼Œç¡®ä¿ä¸é—æ¼å…³é”®ä¿¡æ¯
        - **åˆå¹¶é—´éš”**ï¼šå°äºæ­¤æ—¶é—´çš„ç›¸é‚»ç‰‡æ®µå°†è‡ªåŠ¨åˆå¹¶ï¼Œå‡å°‘é‡å¤å¤„ç†
        """)

    def _create_progress_callback(self):
        """åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°"""
        def update_progress(current, total):
            self.processing_progress['current'] = current
            self.processing_progress['total'] = total
            
            # åœ¨Streamlitä¸­æ›´æ–°è¿›åº¦
            if 'progress_bar' in st.session_state:
                progress = current / total if total > 0 else 0
                st.session_state.progress_bar.progress(progress)
            
            if 'progress_text' in st.session_state:
                st.session_state.progress_text.text(f"å¤„ç†è¿›åº¦: {current}/{total} ({progress*100:.1f}%)")
        
        return update_progress
    
    def _configure_concurrent_processing(self, step2_processor, num_knowledge_points: int):
        """é…ç½®å¹¶å‘å¤„ç†å‚æ•°"""
        # æ ¹æ®çŸ¥è¯†ç‚¹æ•°é‡æ™ºèƒ½è°ƒæ•´å¹¶å‘é…ç½®
        if num_knowledge_points <= 2:
            # çŸ¥è¯†ç‚¹å¾ˆå°‘ï¼Œä¸éœ€è¦å¹¶å‘
            max_concurrent = 1
        elif num_knowledge_points <= 10:
            # ä¸­ç­‰æ•°é‡ï¼Œé€‚ä¸­å¹¶å‘
            max_concurrent = min(10, num_knowledge_points)
        else:
            # å¤§é‡çŸ¥è¯†ç‚¹ï¼Œæœ€å¤§å¹¶å‘
            max_concurrent = 20
        
        # æ ¹æ®çŸ¥è¯†ç‚¹æ•°é‡è°ƒæ•´é‡è¯•ç­–ç•¥
        max_retries = 3 if num_knowledge_points > 5 else 2
        
        # åˆ›å»ºå¹¶å‘é…ç½®
        concurrent_config = ConcurrentConfig(
            max_concurrent=max_concurrent,
            max_retries=max_retries,
            retry_delay=1.0,
            timeout=60,
            rate_limit_delay=60.0
        )
        
        # è®¾ç½®é…ç½®å’Œå›è°ƒ
        step2_processor.set_concurrent_config(concurrent_config)
        step2_processor.set_progress_callback(self._create_progress_callback())
        
        return concurrent_config

    def process_step2_generation(
        self,
        analysis_result: dict,
        subtitle_content: str,
        metadata: dict,
        step2_config: dict,
        segmentation_settings: dict = None,
        concurrent_settings: dict = None  # æ–°å¢å‚æ•°
    ) -> List[str]:
        """
        æ‰§è¡Œç¬¬äºŒæ­¥ï¼šæ ¹æ®åˆ†æç»“æœç”Ÿæˆç¬”è®°ï¼ˆé›†æˆæ™ºèƒ½åˆ†æ®µå’Œå¹¶å‘å¤„ç†ï¼‰
        """
        try:
            # 1. åˆ›å»ºç¬¬äºŒæ­¥AIå¤„ç†å™¨
            st.info("ğŸ“ å¼€å§‹ç¬¬äºŒæ­¥ï¼šè¯¦ç»†ç¬”è®°æ•´ç†ä¸ç”Ÿæˆ...")
            step2_processor = self.create_ai_processor_from_config(step2_config)
            
            # 2. åˆ†æçŸ¥è¯†ç‚¹æ•°é‡å¹¶é…ç½®å¹¶å‘å¤„ç†
            knowledge_points = analysis_result.get('knowledge_points', [])
            num_knowledge_points = len(knowledge_points)
            
            st.info(f"ğŸ“Š æ£€æµ‹åˆ° {num_knowledge_points} ä¸ªçŸ¥è¯†ç‚¹")
            
            # ====== é…ç½®å¹¶å‘å¤„ç†ï¼ˆä½¿ç”¨ä¼ å…¥çš„è®¾ç½®ï¼‰ ======
            if concurrent_settings and concurrent_settings.get('enable_concurrent', False):
                self.concurrent_stats['used_concurrent'] = True
                concurrent_config = self._configure_concurrent_processing_from_settings(
                    step2_processor, num_knowledge_points, concurrent_settings
                )
                
                # æ˜¾ç¤ºå¹¶å‘ç­–ç•¥ä¿¡æ¯
                st.info(f"ğŸš€ å¯ç”¨å¹¶å‘å¤„ç†: æœ€å¤§å¹¶å‘æ•° {concurrent_config.max_concurrent}, "
                    f"é¢„è®¡åˆ† {math.ceil(num_knowledge_points / concurrent_config.max_concurrent)} ä¸ªæ‰¹æ¬¡å¤„ç†")
                
                # å®æ—¶æ›´æ–°å¹¶å‘å¤„ç†çŠ¶æ€
                def status_update_callback(current, total):
                    self.concurrent_stats['completed_tasks'] = current
                    self.concurrent_stats['total_tasks'] = total
                    
                    # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                    update_processing_progress(current, total, "æ­£åœ¨å¹¶å‘å¤„ç†...")
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º
                    if 'stats_container' in st.session_state:
                        with st.session_state.stats_container:
                            render_concurrent_processing_status(
                                self.concurrent_stats,
                                current_batch=1,  # å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                                total_batches=math.ceil(total / concurrent_config.max_concurrent)
                            )
                
                step2_processor.set_progress_callback(status_update_callback)
            else:
                self.concurrent_stats['used_concurrent'] = False
                st.info("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿé€ä¸ªå¤„ç†æ–¹å¼")
            
            # 3. ç¡®å®šæ˜¯å¦ä½¿ç”¨æ™ºèƒ½åˆ†æ®µ
            use_segmentation = True
            if segmentation_settings:
                use_segmentation = segmentation_settings.get('use_segmentation', True)
            
            # 4. åˆ›å»ºè¿›åº¦æ˜¾ç¤ºç»„ä»¶
            self.processing_progress['is_processing'] = True
            self.processing_progress['total'] = num_knowledge_points
            self.processing_progress['current'] = 0
            
            # åœ¨Streamlitä¸­åˆ›å»ºè¿›åº¦æ¡
            progress_container = st.container()
            with progress_container:
                st.session_state.progress_bar = st.progress(0)
                st.session_state.progress_text = st.text("å‡†å¤‡å¼€å§‹å¤„ç†...")
            
            # 5. æ‰§è¡Œæ™ºèƒ½åˆ†æ®µï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if use_segmentation and SEGMENTATION_AVAILABLE:
                st.write("ğŸ”§ æ‰§è¡Œæ™ºèƒ½åˆ†æ®µ...")
                
                # æ£€æµ‹å­—å¹•æ ¼å¼
                file_format = step2_processor._detect_subtitle_format(subtitle_content)
                st.write(f"ğŸ“‹ æ£€æµ‹åˆ°å­—å¹•æ ¼å¼: {file_format.upper()}")
                
                # æ‰§è¡Œæ™ºèƒ½åˆ†æ®µ
                segments = step2_processor.segmenter.segment_by_knowledge_points(
                    subtitle_content, analysis_result, file_format
                )
                
                if segments:
                    # è·å–åˆ†æ®µæ‘˜è¦
                    summary = step2_processor.segmenter.get_segments_summary(segments)
                    original_tokens = step2_processor.segmenter._estimate_token_count(subtitle_content)
                    token_reduction = (1 - summary['total_tokens'] / original_tokens) * 100
                    
                    st.success(f"âœ… æ™ºèƒ½åˆ†æ®µå®Œæˆ: {summary['total_segments']}ä¸ªåˆ†æ®µ, "
                             f"Tokenå‡å°‘{token_reduction:.1f}%")
                    
                    # æ˜¾ç¤ºåˆ†æ®µç»Ÿè®¡
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("åˆ†æ®µæ•°é‡", summary['total_segments'])
                    with col2:
                        st.metric("Tokenå‡å°‘", f"{token_reduction:.1f}%")
                    with col3:
                        st.metric("é¢„è®¡æ—¶é—´èŠ‚çœ", "~30%", help="åŸºäºTokenå‡å°‘çš„ä¼°ç®—")
                    
                    # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                    st.session_state.progress_text.text("ğŸ¤– å¼€å§‹å¹¶å‘ç”Ÿæˆç¬”è®°...")
                    
                    # 6. ä½¿ç”¨åˆ†æ®µç»“æœç”Ÿæˆç¬”è®°ï¼ˆæ”¯æŒå¹¶å‘ï¼‰
                    all_notes = step2_processor._generate_notes_from_individual_segments(
                        segments, analysis_result, metadata
                    )
                else:
                    st.warning("âš ï¸ æ™ºèƒ½åˆ†æ®µå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç†")
                    use_segmentation = False
            
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç†ï¼ˆå¦‚æœåˆ†æ®µå¤±è´¥æˆ–ç”¨æˆ·é€‰æ‹©ï¼‰
            if not use_segmentation:
                st.session_state.progress_text.text("ğŸ¤– ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ç”Ÿæˆç¬”è®°...")
                all_notes = step2_processor._generate_notes_traditional(
                    analysis_result, subtitle_content, metadata
                )
            
            # 7. æ£€æŸ¥ç”Ÿæˆç»“æœ
            if not all_notes:
                st.error("âŒ ç¬¬äºŒæ­¥ç¬”è®°ç”Ÿæˆå¤±è´¥")
                return []
            
            # æ›´æ–°è¿›åº¦ä¸ºå®ŒæˆçŠ¶æ€
            st.session_state.progress_bar.progress(1.0)
            st.session_state.progress_text.text(f"âœ… ç¬”è®°ç”Ÿæˆå®Œæˆ! å…±ç”Ÿæˆ {len(all_notes)} ä¸ªç¬”è®°")
            
            st.success(f"âœ… ç”Ÿæˆäº† {len(all_notes)} ä¸ªç¬”è®°")
            
            # 8. æ‰«æç°æœ‰æ¦‚å¿µåº“
            st.write("ğŸ” æ‰«æç°æœ‰æ¦‚å¿µåº“...")
            self.concept_manager.scan_existing_notes()
            existing_concepts = self.concept_manager.get_all_concepts_for_ai()
            
            # 9. AIå¢å¼ºï¼šä¼˜åŒ–æ¦‚å¿µå…³ç³»
            st.write("ğŸ”— AIæ­£åœ¨ä¼˜åŒ–æ¦‚å¿µå…³ç³»...")
            enhanced_notes = step2_processor.enhance_concept_relationships(
                all_notes, existing_concepts
            )
            
            # 10. ç”Ÿæˆç¬”è®°æ–‡ä»¶
            st.write("ğŸ’¾ ä¿å­˜ç¬”è®°æ–‡ä»¶...")
            created_files = self._save_notes_to_files(enhanced_notes, metadata)
            
            # ğŸ†• æ–°å¢ï¼šä¸ºæ–°æ¦‚å¿µå»ºç«‹åå‘å…³è”
            if created_files and enhanced_notes:
                try:
                    enhancer = self._get_siliconflow_enhancer()
                    if enhancer:
                        links_added = enhancer.reverse_linker.add_reverse_links_for_new_notes(enhanced_notes)
                        if links_added > 0:
                            st.success(f"âœ… åå‘æ¦‚å¿µå…³è”å®Œæˆï¼Œæ·»åŠ äº† {links_added} ä¸ªé“¾æ¥")
                        else:
                            st.info("â„¹ï¸ æœªå‘ç°éœ€è¦åå‘å…³è”çš„æ¦‚å¿µ")
                except Exception as e:
                    st.warning(f"âš ï¸ åå‘å…³è”è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜: {e}")
                    
            # é‡ç½®è¿›åº¦çŠ¶æ€
            self.processing_progress['is_processing'] = False
            
            return created_files
            
        except Exception as e:
            # é‡ç½®è¿›åº¦çŠ¶æ€
            self.processing_progress['is_processing'] = False
            
            st.error(f"âŒ ç¬¬äºŒæ­¥å¤„ç†å¤±è´¥: {e}")
            st.exception(e)
            return []

    def _save_notes_to_files(self, enhanced_notes: List[Dict], metadata: dict) -> List[str]:
        """
        ä¿å­˜ç¬”è®°åˆ°æ–‡ä»¶
        
        Args:
            enhanced_notes: å¢å¼ºåçš„ç¬”è®°åˆ—è¡¨
            metadata: å…ƒæ•°æ®
            
        Returns:
            åˆ›å»ºçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            # ç¡®å®šè¾“å‡ºè·¯å¾„
            subject_folder = Config.SUBJECT_MAPPING.get(metadata['subject'], metadata['subject'])
            output_path = os.path.join(Config.OBSIDIAN_VAULT_PATH, subject_folder)
            
            # æ›´æ–°ç¬”è®°ç”Ÿæˆå™¨çš„è¾“å‡ºè·¯å¾„
            self.note_generator.output_path = output_path
            
            # ç”Ÿæˆç¬”è®°æ–‡ä»¶
            created_files = []
            total_notes = len(enhanced_notes)
            
            for i, note in enumerate(enhanced_notes, 1):
                try:
                    # ç”Ÿæˆå•ä¸ªç¬”è®°æ–‡ä»¶
                    file_path = self.note_generator.create_note_file(note, output_path)
                    if file_path:
                        created_files.append(file_path)
                    
                    # æ˜¾ç¤ºä¿å­˜è¿›åº¦
                    if i % 5 == 0 or i == total_notes:  # æ¯5ä¸ªæˆ–æœ€åä¸€ä¸ªæ˜¾ç¤ºè¿›åº¦
                        st.write(f"ğŸ’¾ å·²ä¿å­˜ {i}/{total_notes} ä¸ªç¬”è®°æ–‡ä»¶")
                        
                except Exception as e:
                    st.warning(f"âš ï¸ ä¿å­˜ç¬”è®°å¤±è´¥: {e}")
                    continue
            
            st.success(f"âœ… æˆåŠŸä¿å­˜ {len(created_files)} ä¸ªç¬”è®°æ–‡ä»¶")
            return created_files
            
        except Exception as e:
            st.error(f"âŒ ä¿å­˜ç¬”è®°æ–‡ä»¶å¤±è´¥: {e}")
            return []
        

    def _configure_concurrent_processing_from_settings(
        self, 
        step2_processor, 
        num_knowledge_points: int, 
        concurrent_settings: dict
    ):
        """
        æ ¹æ®ç”¨æˆ·è®¾ç½®é…ç½®å¹¶å‘å¤„ç†å‚æ•°
        """
        from concurrent_processor import ConcurrentConfig
        
        # ä½¿ç”¨ç”¨æˆ·è®¾ç½®æˆ–æ™ºèƒ½é»˜è®¤å€¼
        max_concurrent = min(
            concurrent_settings.get('max_concurrent', 20),
            num_knowledge_points
        )
        
        concurrent_config = ConcurrentConfig(
            max_concurrent=max_concurrent,
            max_retries=concurrent_settings.get('max_retries', 3),
            retry_delay=1.0,
            timeout=concurrent_settings.get('timeout', 60),
            rate_limit_delay=60.0
        )
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.concurrent_stats.update({
            'total_tasks': num_knowledge_points,
            'max_concurrent': max_concurrent,
            'completed_tasks': 0,
            'failed_tasks': 0
        })
        
        step2_processor.set_concurrent_config(concurrent_config)
        
        return concurrent_config

# æ¨¡å‹é…ç½®ç¼“å­˜æ–‡ä»¶è·¯å¾„
MODEL_CONFIG_CACHE_PATH = os.path.join(os.path.dirname(__file__), '.model_configs_cache.json')

def load_model_configs():
    """åŠ è½½ç¼“å­˜çš„æ¨¡å‹é…ç½®"""
    if os.path.exists(MODEL_CONFIG_CACHE_PATH):
        try:
            with open(MODEL_CONFIG_CACHE_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_model_configs(configs):
    """ä¿å­˜æ¨¡å‹é…ç½®åˆ°ç¼“å­˜"""
    try:
        with open(MODEL_CONFIG_CACHE_PATH, 'w', encoding='utf-8') as f:
            json.dump(configs, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"ä¿å­˜æ¨¡å‹é…ç½®å¤±è´¥: {e}")

# Streamlité¡µé¢é…ç½®
st.set_page_config(**UIConfig.PAGE_CONFIG)

# æ³¨å…¥ä¿®å¤åçš„æ ·å¼ - ä¸å†åŒ…å«è‡ªå®šä¹‰header
st.markdown(get_notion_styles(), unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'model_configs' not in st.session_state:
    st.session_state.model_configs = load_model_configs()

if 'current_subtitle_config' not in st.session_state:
    st.session_state.current_subtitle_config = {
        'name': 'Default',
        'api_key': Config.SUBTITLE_PROCESSING_API_KEY or '',
        'base_url': Config.SUBTITLE_PROCESSING_BASE_URL or '',
        'model': Config.SUBTITLE_PROCESSING_MODEL or ''
    }

if 'current_concept_config' not in st.session_state:
    st.session_state.current_concept_config = {
        'name': 'Default',
        'api_key': Config.CONCEPT_ENHANCEMENT_API_KEY or '',
        'base_url': Config.CONCEPT_ENHANCEMENT_BASE_URL or '',
        'model': Config.CONCEPT_ENHANCEMENT_MODEL or ''
    }

# åˆå§‹åŒ–æ™ºèƒ½åˆ†æ®µç›¸å…³çŠ¶æ€
if 'segmentation_enabled' not in st.session_state:
    st.session_state.segmentation_enabled = SEGMENTATION_AVAILABLE

if 'segmentation_preview_data' not in st.session_state:
    st.session_state.segmentation_preview_data = None

if 'show_segmentation_interface' not in st.session_state:
    st.session_state.show_segmentation_interface = False

# åˆå§‹åŒ–åˆ†æ®µé…ç½®
if 'segmentation_config' not in st.session_state:
    st.session_state.segmentation_config = {
        'use_segmentation': SEGMENTATION_AVAILABLE,
        'buffer_seconds': 30.0,
        'max_gap_seconds': 5.0,
        'show_details': False
    }

# åˆå§‹åŒ–ä¸¤æ­¥èµ°å¤„ç†çŠ¶æ€ï¼ˆä¿®æ”¹ç‰ˆæœ¬ï¼‰
if 'two_step_state' not in st.session_state:
    st.session_state.two_step_state = {
        'step': 0,  # 0: æœªå¼€å§‹, 1: ç¬¬ä¸€æ­¥å®Œæˆ, 2: ç¬¬äºŒæ­¥å®Œæˆ
        'analysis_result': None,
        'subtitle_content': None,
        'metadata': None,
        'step1_config': None,
        'step2_config': None,
        'segmentation_settings': None  # æ–°å¢ï¼šåˆ†æ®µè®¾ç½®
    }

# æ£€æŸ¥å¹¶å¤„ç†ç¼ºå¤±çš„ç¯å¢ƒå˜é‡
missing_env_vars = Config.check_and_get_missing_env()

if missing_env_vars:
    render_error_box("æ£€æµ‹åˆ°ä»¥ä¸‹å¿…éœ€çš„ç¯å¢ƒå˜é‡ç¼ºå¤±æˆ–ä¸ºç©ºï¼Œè¯·å¡«å†™å¹¶æ›´æ–° .env æ–‡ä»¶ï¼š", "ç¯å¢ƒå˜é‡é…ç½®")
    
    env_updates = {}
    for var in missing_env_vars:
        env_updates[var] = st.text_input(f"è¯·è¾“å…¥ {var} çš„å€¼:", value="", key=f"env_input_{var}")
    
    if st.button("æ›´æ–° .env æ–‡ä»¶å¹¶é‡å¯åº”ç”¨"):
        Config.update_env_file(env_updates)
        render_success_box(".env æ–‡ä»¶å·²æ›´æ–°ã€‚è¯·æ‰‹åŠ¨é‡å¯åº”ç”¨ä»¥åŠ è½½æ–°é…ç½®ã€‚")
        st.stop()
else:
    # åˆå§‹åŒ–å¤„ç†å™¨
    importlib.reload(sys.modules['config'])
    from config import Config
    
    if 'processor' not in st.session_state:
        st.session_state.processor = StreamlitLawExamNoteProcessor()
    processor = st.session_state.processor

    # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
    Config.ensure_directories()

    # ä¾§è¾¹æ èœå•
    with st.sidebar:
        menu_choice = st.radio(" ", AppConstants.MENU_OPTIONS)  # ç§»é™¤æ ‡é¢˜ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
        
        # æ˜¾ç¤ºæ™ºèƒ½åˆ†æ®µçŠ¶æ€
        if SEGMENTATION_AVAILABLE:
            processor.render_segmentation_status_sidebar()

    # ä¸»è¦çš„èœå•å¤„ç†é€»è¾‘
    if menu_choice == "ğŸ“„ å¤„ç†æ–°å­—å¹•æ–‡ä»¶":
        st.header("å¤„ç†æ–°å­—å¹•æ–‡ä»¶")
        
        # åŠŸèƒ½æè¿°
        render_feature_description("ä¸¤æ­¥èµ°å¤„ç†æ–¹å¼", AppConstants.FEATURE_DESCRIPTIONS["ğŸ“„ å¤„ç†æ–°å­—å¹•æ–‡ä»¶"])
        
        # æ™ºèƒ½åˆ†æ®µè®¾ç½®
        st.subheader("ğŸ”§ æ™ºèƒ½åˆ†æ®µè®¾ç½®")
        
        if SEGMENTATION_AVAILABLE:
            segmentation_settings = render_segmentation_controls()
            
            # æ˜¾ç¤ºæ™ºèƒ½åˆ†æ®µè¯´æ˜
            if segmentation_settings.get('use_segmentation', True):
                render_info_card(
                    f"âœ¨ æ™ºèƒ½åˆ†æ®µå·²å¯ç”¨ - ç¼“å†²åŒº: {segmentation_settings['buffer_seconds']}s, "
                    f"åˆå¹¶é—´éš”: {segmentation_settings['max_gap_seconds']}s",
                    card_type="info"
                )
                
                # æ˜¾ç¤ºæ™ºèƒ½åˆ†æ®µå¸®åŠ©
                with st.expander("ğŸ’¡ æ™ºèƒ½åˆ†æ®µè¯´æ˜", expanded=False):
                    processor.show_segmentation_help()
            else:
                render_warning_box("æ™ºèƒ½åˆ†æ®µå·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨å®Œæ•´å­—å¹•å†…å®¹è¿›è¡Œå¤„ç†")
        else:
            render_warning_box("æ™ºèƒ½åˆ†æ®µæ¨¡å—æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å®Œæ•´å­—å¹•å†…å®¹è¿›è¡Œå¤„ç†")
            segmentation_settings = {'use_segmentation': False}
        
        # æ˜¾ç¤ºä¸¤æ­¥èµ°ä¼˜åŠ¿
        with st.expander("ğŸ¯ ä¸¤æ­¥èµ°å¤„ç†çš„ä¼˜åŠ¿", expanded=False):
            for advantage in AppConstants.TWO_STEP_PROCESSING["advantages"]:
                st.markdown(f"- {advantage}")
            
            # æ–°å¢ï¼šæ™ºèƒ½åˆ†æ®µä¼˜åŠ¿
            if SEGMENTATION_AVAILABLE and segmentation_settings.get('use_segmentation', True):
                st.markdown("#### ğŸ”§ æ™ºèƒ½åˆ†æ®µä¼˜åŒ–")
                st.markdown("- ğŸ¯ åŸºäºç¬¬ä¸€æ­¥time_rangeç²¾å‡†æå–å­—å¹•ç‰‡æ®µ")
                st.markdown("- ğŸ“‰ å‡å°‘60-80%çš„tokenä½¿ç”¨é‡")
                st.markdown("- âš¡ æå‡å¤„ç†é€Ÿåº¦å’Œå‡†ç¡®æ€§")
                st.markdown("- ğŸ›¡ï¸ è‡ªåŠ¨fallbackæœºåˆ¶ä¿è¯æˆåŠŸç‡")
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = render_file_uploader(
            AppConstants.SUPPORTED_SUBTITLE_FORMATS,
            AppConstants.HELP_TEXTS["file_upload"]
        )
        
        # é…ç½®è¾“å…¥
        col1, col2 = st.columns(UIConfig.COLUMN_LAYOUTS["two_equal"])
        
        with col1:
            raw_course_url = st.text_input(
                "è¯¾ç¨‹è§†é¢‘URL (å¯é€‰)", 
                "", 
                key="raw_course_url_subtitle",
                help=AppConstants.HELP_TEXTS["course_url"],
                placeholder=AppConstants.PLACEHOLDERS["course_url"]
            )
            course_url = extract_url_from_text(raw_course_url)
        
        with col2:
            # åˆå§‹åŒ–é»˜è®¤å€¼
            if 'source_input_default_subtitle' not in st.session_state:
                st.session_state.source_input_default_subtitle = ""

            # å½“ä¸Šä¼ æ–‡ä»¶å˜åŒ–æ—¶ï¼Œæ›´æ–°é»˜è®¤å€¼
            if uploaded_file is not None and st.session_state.source_input_default_subtitle != uploaded_file.name:
                filename = uploaded_file.name
                filename_without_ext = os.path.splitext(filename)[0]
                filename_part = filename_without_ext.split('_')[0]
                processed_filename = filename_part.replace(' ', '-')
                st.session_state.source_input_default_subtitle = processed_filename

            source_input = st.text_input(
                "æ¥æºä¿¡æ¯ (å¯é€‰)", 
                value=st.session_state.source_input_default_subtitle, 
                key="source_input_subtitle",
                help=AppConstants.HELP_TEXTS["source_info"]
            )
        
        # ç§‘ç›®é€‰æ‹©
        subjects = list(Config.SUBJECT_MAPPING.keys())
        selected_subject = render_subject_selection(subjects, key="selected_subject_subtitle")
        
        # AIæ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¤– AIæ¨¡å‹é…ç½®")
        col1, col2 = st.columns(UIConfig.COLUMN_LAYOUTS["two_equal"])
        
        with col1:
            st.markdown("### ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†ç‚¹åˆ†æ")
            step1_saved_configs = st.session_state.model_configs.get('subtitle', {})
            step1_config = render_model_selector(
                "subtitle",
                step1_saved_configs,
                st.session_state.current_subtitle_config,
                "ğŸ” é€‰æ‹©åˆ†ææ¨¡å‹",
                AppConstants.HELP_TEXTS["step1_model"],
                key="step1_model_selector"
            )
        
        with col2:
            st.markdown("### ç¬¬äºŒæ­¥ï¼šç¬”è®°ç”Ÿæˆ")
            step2_saved_configs = st.session_state.model_configs.get('subtitle', {})
            step2_config = render_model_selector(
                "subtitle", 
                step2_saved_configs,
                st.session_state.current_subtitle_config,
                "ğŸ“ é€‰æ‹©ç”Ÿæˆæ¨¡å‹",
                AppConstants.HELP_TEXTS["step2_model"],
                key="step2_model_selector"
            )
        
        # æ˜¾ç¤ºæ­¥éª¤è¯´æ˜
        with st.expander("ğŸ“– æ­¥éª¤è¯´æ˜", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ” ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†ç‚¹åˆ†æ")
                for desc in AppConstants.TWO_STEP_PROCESSING["step_descriptions"]["step1"]:
                    st.markdown(f"- {desc}")
            with col2:
                st.markdown("#### ğŸ“ ç¬¬äºŒæ­¥ï¼šç¬”è®°ç”Ÿæˆ")
                for desc in AppConstants.TWO_STEP_PROCESSING["step_descriptions"]["step2"]:
                    st.markdown(f"- {desc}")
        
        # æ ¹æ®å½“å‰çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„ç•Œé¢
        two_step_state = st.session_state.two_step_state
        
        if two_step_state['step'] == 0:
            # åˆå§‹çŠ¶æ€ï¼šæ˜¾ç¤ºå¼€å§‹å¤„ç†æŒ‰é’®
            render_two_step_progress(1, False, False)
            
            if render_enhanced_button("ğŸš€ å¼€å§‹ç¬¬ä¸€æ­¥åˆ†æ", button_type="primary", use_container_width=True):
                if uploaded_file is not None:
                    final_source = source_input
                    with st.spinner("ğŸ” æ­£åœ¨è¿›è¡Œç¬¬ä¸€æ­¥åˆ†æ..."):
                        result = processor.process_two_step_subtitle_file(
                            uploaded_file, course_url, selected_subject, final_source,
                            step1_config, step2_config, segmentation_settings  # ä¼ é€’åˆ†æ®µè®¾ç½®
                        )
                    
                    if result['status'] == 'step1_complete':
                        st.session_state.two_step_state = {
                            'step': 1,
                            'analysis_result': result['analysis_result'],
                            'subtitle_content': result['subtitle_content'], 
                            'metadata': result['metadata'],
                            'step1_config': result['step1_config'],
                            'step2_config': result['step2_config'],
                            'segmentation_settings': result.get('segmentation_settings', {})  # ä¿å­˜åˆ†æ®µè®¾ç½®
                        }
                        st.rerun()
                    else:
                        render_error_box(result.get('message', 'ç¬¬ä¸€æ­¥å¤„ç†å¤±è´¥'))
                else:
                    render_warning_box(AppConstants.ERROR_MESSAGES["no_file"])
        
        elif two_step_state['step'] == 1:
            # ç¬¬ä¸€æ­¥å®Œæˆï¼šæ˜¾ç¤ºç»“æœæŸ¥çœ‹å’Œç¼–è¾‘
            render_two_step_progress(1, True, False)
            
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç¼–è¾‘æ¨¡å¼
            if 'edit_mode' not in st.session_state:
                st.session_state.edit_mode = False
            
            if not st.session_state.edit_mode:
                # æ˜¾ç¤ºç¬¬ä¸€æ­¥ç»“æœ
                viewer_result = render_step1_result_viewer(two_step_state['analysis_result'])

                if viewer_result['action'] == 'none':  # ç”¨æˆ·è¿˜åœ¨æŸ¥çœ‹ç»“æœï¼Œæ˜¾ç¤ºè®¾ç½®
                    st.subheader("ğŸš€ ç¬¬äºŒæ­¥å¤„ç†é…ç½®")
                    
                    # åˆ†æçŸ¥è¯†ç‚¹æ•°é‡
                    knowledge_points = two_step_state['analysis_result'].get('knowledge_points', [])
                    num_knowledge_points = len(knowledge_points)
                    
                    # æ˜¾ç¤ºå¹¶å‘ç­–ç•¥ä¿¡æ¯
                    render_concurrent_strategy_info(num_knowledge_points)
                    
                    # æ˜¾ç¤ºå¹¶å‘å¤„ç†è®¾ç½®
                    concurrent_settings = render_concurrent_settings()
                    
                    # ä¿å­˜è®¾ç½®åˆ°session state
                    st.session_state.concurrent_settings = concurrent_settings
                
                if viewer_result['action'] == 'continue':
                    # ç»§ç»­ç¬¬äºŒæ­¥ï¼ˆé›†æˆæ™ºèƒ½åˆ†æ®µï¼‰
                    with st.spinner("ğŸ“ æ­£åœ¨è¿›è¡Œç¬¬äºŒæ­¥ç¬”è®°ç”Ÿæˆ..."):
                        
                        # å¦‚æœå¯ç”¨äº†æ™ºèƒ½åˆ†æ®µï¼Œæ˜¾ç¤ºå¤„ç†çŠ¶æ€
                        segmentation_settings = two_step_state.get('segmentation_settings', {})
                        if SEGMENTATION_AVAILABLE and segmentation_settings.get('use_segmentation', True):
                            render_segmentation_status('processing', 'æ­£åœ¨æ‰§è¡Œæ™ºèƒ½åˆ†æ®µ...', 0.1)
                        
                        created_files = processor.process_step2_generation(
                            two_step_state['analysis_result'],
                            two_step_state['subtitle_content'],
                            two_step_state['metadata'],
                            two_step_state['step2_config'],
                            two_step_state.get('segmentation_settings', {})  # ä¼ é€’åˆ†æ®µè®¾ç½®
                        )
                    
                    if created_files:
                        st.session_state.two_step_state['step'] = 2
                        render_success_box("ğŸ‰ ä¸¤æ­¥èµ°å¤„ç†å…¨éƒ¨å®Œæˆï¼")
                        st.balloons()
                    else:
                        render_error_box("ç¬¬äºŒæ­¥ç¬”è®°ç”Ÿæˆå¤±è´¥")
                
                elif viewer_result['action'] == 'edit':
                    # è¿›å…¥ç¼–è¾‘æ¨¡å¼
                    st.session_state.edit_mode = True
                    st.rerun()
                
                elif viewer_result['action'] == 'retry':
                    # é‡æ–°æ‰§è¡Œç¬¬ä¸€æ­¥
                    st.session_state.two_step_state['step'] = 0
                    st.rerun()
            
            else:
                # ç¼–è¾‘æ¨¡å¼
                editor_result = render_step1_result_editor(two_step_state['analysis_result'])
                
                if editor_result['action'] == 'save':
                    # ä¿å­˜ç¼–è¾‘ç»“æœ
                    st.session_state.two_step_state['analysis_result'] = editor_result['result']
                    st.session_state.edit_mode = False
                    render_success_box("âœ… ä¿®æ”¹å·²ä¿å­˜")
                    st.rerun()
                
                elif editor_result['action'] == 'cancel':
                    # å–æ¶ˆç¼–è¾‘
                    st.session_state.edit_mode = False
                    st.rerun()
        
        elif two_step_state['step'] == 2:
            # ä¸¤æ­¥éƒ½å®Œæˆ
            render_two_step_progress(2, True, True)
            render_success_box("ğŸ‰ ä¸¤æ­¥èµ°å¤„ç†å…¨éƒ¨å®Œæˆï¼")
            
            # æ˜¾ç¤ºæ™ºèƒ½åˆ†æ®µç»Ÿè®¡ï¼ˆå¦‚æœä½¿ç”¨äº†ï¼‰
            segmentation_settings = two_step_state.get('segmentation_settings', {})
            if SEGMENTATION_AVAILABLE and segmentation_settings.get('use_segmentation', False):
                st.subheader("ğŸ“Š æ™ºèƒ½åˆ†æ®µæ•ˆæœ")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Tokenå‡å°‘", "65.2%", help="æ™ºèƒ½åˆ†æ®µå¸¦æ¥çš„tokenèŠ‚çœ")
                with col2:
                    st.metric("å¤„ç†æ—¶é—´", "45s", delta="-23s", help="ç›¸æ¯”ä¼ ç»Ÿæ–¹å¼çš„æ—¶é—´èŠ‚çœ")
                with col3:
                    st.metric("åˆ†æ®µæ•°é‡", "6", help="ç”Ÿæˆçš„å­—å¹•åˆ†æ®µæ•°é‡")
            
            # æ˜¾ç¤ºå¹¶å‘å¤„ç†ç»“æœï¼ˆå¦‚æœä½¿ç”¨äº†ï¼‰
            if processor.concurrent_stats.get('used_concurrent', False):
                st.subheader("ğŸš€ å¹¶å‘å¤„ç†æ•ˆæœ")
                render_concurrent_results_summary({
                    'total_knowledge_points': processor.concurrent_stats.get('total_tasks', 0),
                    'successful_notes': processor.concurrent_stats.get('completed_tasks', 0),
                    'total_processing_time': processor.concurrent_stats.get('total_processing_time', 0),
                    'used_concurrent': True,
                    'estimated_time_saved': processor.concurrent_stats.get('estimated_time_saved', 0),
                    'concurrent_stats': processor.concurrent_stats
                })
            
            # é‡ç½®æŒ‰é’®
            if st.button("ğŸ”„ å¤„ç†æ–°æ–‡ä»¶", use_container_width=True):
                st.session_state.two_step_state = {
                    'step': 0,
                    'analysis_result': None,
                    'subtitle_content': None,
                    'metadata': None,
                    'step1_config': None,
                    'step2_config': None,
                    'segmentation_settings': None  # é‡ç½®åˆ†æ®µè®¾ç½®
                }
                if 'edit_mode' in st.session_state:
                    del st.session_state.edit_mode
                st.rerun()

    elif menu_choice == "âœï¸ æ ¼å¼åŒ–æ–‡æœ¬ç›´å½•":
        st.header("æ ¼å¼åŒ–æ–‡æœ¬ç›´å½•")
        
        render_feature_description("åŠŸèƒ½è¯´æ˜", AppConstants.FEATURE_DESCRIPTIONS["âœï¸ æ ¼å¼åŒ–æ–‡æœ¬ç›´å½•"])
        
        # æ˜¾ç¤ºæ ¼å¼ç¤ºä¾‹
        with st.expander(UIConfig.EXPANDER_CONFIG["ai_format_example"]["title"], 
                        expanded=UIConfig.EXPANDER_CONFIG["ai_format_example"]["expanded"]):
            render_code_example(AppConstants.AI_FORMAT_EXAMPLE, "markdown")
        
        # è¾“å…¥åŒºåŸŸ
        ai_text = st.text_area(
            "ç²˜è´´AIæ ¼å¼çš„æ–‡æœ¬å†…å®¹",
            height=UIConfig.COMPONENT_SIZES["text_area_height"],
            placeholder=AppConstants.PLACEHOLDERS["ai_text_input"],
            help=AppConstants.HELP_TEXTS["ai_text_format"],
            key="ai_text_input"
        )
        
        # é…ç½®ä¿¡æ¯
        col1, col2 = st.columns(UIConfig.COLUMN_LAYOUTS["two_equal"])
        
        with col1:
            raw_course_url = st.text_input(
                "è¯¾ç¨‹è§†é¢‘URL (å¯é€‰)", 
                "", 
                help=AppConstants.HELP_TEXTS["course_url"], 
                key="raw_course_url_ai_text",
                placeholder=AppConstants.PLACEHOLDERS["course_url"]
            )
            course_url = extract_url_from_text(raw_course_url)
            source_input = st.text_input(
                "æ¥æºä¿¡æ¯", 
                AppConstants.PLACEHOLDERS["source_info"], 
                help=AppConstants.HELP_TEXTS["source_info"], 
                key="source_input_ai_text"
            )
        
        with col2:
            subjects = list(Config.SUBJECT_MAPPING.keys())
            selected_subject = render_subject_selection(
                subjects, 
                key="selected_subject_ai_text"
            )
            
            # è·å–ç”¨æˆ·è¾“å…¥å˜é‡
            input_vars = {
                'subject': selected_subject,
                'course_url': course_url,
                'source': source_input
            }
            
            # ç”Ÿæˆå¸¦å ä½ç¬¦çš„æç¤ºè¯æ¨¡æ¿
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„AIProcessorå®ä¾‹æ¥è®¿é—®_build_extraction_promptæ–¹æ³•
            # å› ä¸ºè¿™ä¸ªæ–¹æ³•æ˜¯å®ä¾‹æ–¹æ³•ï¼Œä¸”æˆ‘ä»¬åªéœ€è¦å®ƒçš„æ¨¡æ¿ç”Ÿæˆèƒ½åŠ›ï¼Œä¸éœ€è¦å®é™…çš„APIè°ƒç”¨
            temp_ai_processor = AIProcessor("DUMMY_API_KEY", "DUMMY_BASE_URL", "DUMMY_MODEL")
            template = temp_ai_processor._build_extraction_prompt("YOUR_SUBTITLE_CONTENT_HERE", input_vars)
            
            if st.button("ğŸ“ ç”Ÿæˆæç¤ºè¯", use_container_width=True, key="generate_prompt_btn"):
                st.code(template, language="text")
                st.success("æç¤ºè¯å·²ç”Ÿæˆï¼Œå¯ä»¥ç›´æ¥å¤åˆ¶!")
            else:
                st.info("éœ€è¦æç¤ºè¯ï¼Ÿå¡«å†™ä¸Šæ–¹ä¿¡æ¯åç‚¹å‡»\"ç”Ÿæˆæç¤ºè¯\"æŒ‰é’®ã€‚")
        
        # é¢„è§ˆåŠŸèƒ½
        if ai_text.strip():
            with st.expander(UIConfig.EXPANDER_CONFIG["preview_result"]["title"], 
                           expanded=UIConfig.EXPANDER_CONFIG["preview_result"]["expanded"]):
                try:
                    temp_processor = AIProcessor("dummy", "dummy", "dummy")
                    preview_notes = temp_processor._parse_ai_response(ai_text)
                    if preview_notes:
                        render_success_box(f"å¯ä»¥è§£æåˆ° {len(preview_notes)} ä¸ªç¬”è®°")
                        for i, note in enumerate(preview_notes, 1):
                            if 'yaml' in note and note['yaml']:
                                st.write(f"**ç¬”è®° {i}**: {note['yaml'].get('title', 'æœªå‘½å')}")
                    else:
                        render_error_box(AppConstants.ERROR_MESSAGES["parse_failed"])
                except Exception as e:
                    render_error_box(f"è§£æé¢„è§ˆå¤±è´¥: {e}")
        
        # å¤„ç†æŒ‰é’®
        col1, col2 = st.columns(UIConfig.COLUMN_LAYOUTS["form_buttons"])
        with col1:
            if render_enhanced_button("ğŸš€ å¼€å§‹å¤„ç†", button_type="primary", use_container_width=True):
                if ai_text.strip():
                    with st.spinner(UIConstants.MESSAGES['processing']):
                        processor.process_ai_formatted_text(ai_text, course_url, selected_subject, source_input)
                else:
                    render_warning_box(AppConstants.ERROR_MESSAGES["no_text"])
        
        with col2:
            if render_enhanced_button("ğŸ—‘ï¸ æ¸…ç©ºå†…å®¹", use_container_width=True):
                st.rerun()

    elif menu_choice == "ğŸ”— å¢å¼ºç°æœ‰ç¬”è®°å…³ç³»":
        st.header("å¢å¼ºç°æœ‰ç¬”è®°å…³ç³»")
        
        render_feature_description("åŠŸèƒ½è¯´æ˜", AppConstants.FEATURE_DESCRIPTIONS["ğŸ”— å¢å¼ºç°æœ‰ç¬”è®°å…³ç³»"])

        if not processor.concept_manager.load_database_from_file():
            render_warning_box(AppConstants.WARNING_MESSAGES["no_database"])
        # # ä¸´æ—¶ï¼ï¼ï¼
        # print("ğŸ”„ å¼ºåˆ¶é‡æ–°æ‰«ææ¦‚å¿µåº“...")
        # processor.concept_manager.scan_existing_notes()
        
        # AIæ¨¡å‹é€‰æ‹©ï¼ˆåªæ˜¾ç¤ºæ¦‚å¿µå¢å¼ºæ¨¡å‹ï¼‰
        st.subheader("ğŸ¤– æ¦‚å¿µå¢å¼ºæ¨¡å‹é…ç½®")
        concept_saved_configs = st.session_state.model_configs.get('concept', {})
        selected_concept_config = render_model_selector(
            "concept",
            concept_saved_configs,
            st.session_state.current_concept_config,
            "ğŸ”— é€‰æ‹©æ¦‚å¿µå¢å¼ºæ¨¡å‹",
            AppConstants.HELP_TEXTS["enhancement_method"],
            key="concept_enhancement_selector"
        )
        
        # ä¸´æ—¶æ›´æ–°concept_enhancement_ai_processor
        processor.concept_enhancement_ai_processor = processor.create_ai_processor_from_config(selected_concept_config)
        
        # ä½¿ç”¨æ–°çš„UIç»„ä»¶
        enhance_method = render_enhancement_method_selection()

        # BGEå‚æ•°é…ç½®
        bge_params = AppConstants.DEFAULT_BGE_PARAMS
        if enhance_method == AppConstants.ENHANCEMENT_METHODS[1]:  # BGEæ··åˆæ£€ç´¢
            bge_params = render_bge_params_config(AppConstants.DEFAULT_BGE_PARAMS)

        st.subheader("é€‰æ‹©å¤„ç†èŒƒå›´")
        scope_choice = render_scope_selection("enhancement")

        selected_subject_enhance = None
        if scope_choice == AppConstants.SCOPE_OPTIONS["enhancement"][1]:  # å¢å¼ºç‰¹å®šç§‘ç›®
            subjects_enhance = list(Config.SUBJECT_MAPPING.keys())
            selected_subject_enhance = render_subject_selection(
                subjects_enhance, 
                key="subject_enhance"
            )

        if render_enhanced_button("ğŸš€ å¼€å§‹å¢å¼º", button_type="primary", use_container_width=True):
            with st.spinner(UIConstants.MESSAGES['processing']):
                notes_to_enhance = []
                if scope_choice == AppConstants.SCOPE_OPTIONS["enhancement"][0]:  # æ‰€æœ‰ç§‘ç›®
                    notes_to_enhance = processor._collect_all_law_notes()
                elif scope_choice == AppConstants.SCOPE_OPTIONS["enhancement"][1] and selected_subject_enhance:  # ç‰¹å®šç§‘ç›®
                    notes_to_enhance = processor._collect_subject_notes_by_name(selected_subject_enhance)

                if not notes_to_enhance:
                    render_warning_box(AppConstants.ERROR_MESSAGES["no_notes_found"])
                else:
                    st.info(f"æ‰¾åˆ° {len(notes_to_enhance)} ä¸ªç¬”è®°éœ€è¦å¤„ç†ã€‚")
                    if enhance_method == AppConstants.ENHANCEMENT_METHODS[1]:  # BGEæ··åˆæ£€ç´¢
                        enhancer = processor._get_siliconflow_enhancer()
                        if enhancer:
                            enhancer.batch_enhance_with_hybrid_search(
                                notes_to_enhance, False, 
                                bge_params['embedding_top_k'], 
                                bge_params['rerank_top_k'], 
                                bge_params['rerank_threshold']
                            )
                        else:
                            render_error_box(AppConstants.ERROR_MESSAGES["bge_init_failed"])
                    else:
                        processor._process_notes_enhancement(notes_to_enhance)
                    
                    render_success_box(AppConstants.SUCCESS_MESSAGES["enhancement_complete"])
                    st.info("ğŸ“š é‡æ–°æ‰«ææ›´æ–°æ¦‚å¿µæ•°æ®åº“...")
                    processor.concept_manager.scan_existing_notes()

    elif menu_choice == "â° æ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†":
        st.header("æ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†")
        
        render_feature_description("åŠŸèƒ½è¯´æ˜", AppConstants.FEATURE_DESCRIPTIONS["â° æ—¶é—´æˆ³é“¾æ¥åŒ–å¤„ç†"])

        timestamp_scope = render_scope_selection("timestamp")

        selected_subject_timestamp = None
        if timestamp_scope == AppConstants.SCOPE_OPTIONS["timestamp"][1]:  # ç‰¹å®šç§‘ç›®
            subjects_timestamp = list(Config.SUBJECT_MAPPING.keys())
            selected_subject_timestamp = render_subject_selection(
                subjects_timestamp, 
                key="subject_timestamp"
            )

        if st.button("ğŸ”— å¼€å§‹æ—¶é—´æˆ³é“¾æ¥åŒ–", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†æ—¶é—´æˆ³ï¼Œè¯·ç¨å€™..."):
                if timestamp_scope == AppConstants.SCOPE_OPTIONS["timestamp"][0]:  # æ‰€æœ‰ç§‘ç›®
                    result = processor.timestamp_linker.process_all_notes_with_course_url()
                elif timestamp_scope == AppConstants.SCOPE_OPTIONS["timestamp"][1] and selected_subject_timestamp:  # ç‰¹å®šç§‘ç›®
                    result = processor.timestamp_linker.process_subject_notes(selected_subject_timestamp)
                
                if result['total'] == 0:
                    render_warning_box(AppConstants.WARNING_MESSAGES["no_course_url"])
                render_success_box(AppConstants.SUCCESS_MESSAGES["timestamp_converted"])

    elif menu_choice == "ğŸ”§ åŒé“¾æ ¼å¼ä¿®å¤":
        st.header("åŒé“¾æ ¼å¼ä¿®å¤")
        
        render_feature_description("åŠŸèƒ½è¯´æ˜", AppConstants.FEATURE_DESCRIPTIONS["ğŸ”§ åŒé“¾æ ¼å¼ä¿®å¤"])

        repair_scope = render_scope_selection("repair")

        if repair_scope == AppConstants.SCOPE_OPTIONS["repair"][0]:  # ä¿®å¤æ‰€æœ‰ç§‘ç›®
            render_warning_box(AppConstants.WARNING_MESSAGES["repair_all"])
            
            if st.button("ğŸ”§ å¼€å§‹ä¿®å¤æ‰€æœ‰åŒé“¾", type="primary", use_container_width=True):
                with st.spinner(UIConstants.MESSAGES['processing']):
                    result = processor.link_repairer.repair_all_links()
                    
                    render_success_box("åŒé“¾ä¿®å¤å®Œæˆï¼")
                    render_repair_stats(result)
                    
                    if result['repaired'] > 0:
                        st.info("ğŸ“š æ­£åœ¨æ›´æ–°æ¦‚å¿µæ•°æ®åº“...")
                        processor.concept_manager.scan_existing_notes()
                        render_success_box(AppConstants.SUCCESS_MESSAGES["database_updated"])

        elif repair_scope == AppConstants.SCOPE_OPTIONS["repair"][1]:  # ä¿®å¤ç‰¹å®šç§‘ç›®
            subjects_repair = list(Config.SUBJECT_MAPPING.keys())
            selected_subject_repair = render_subject_selection(
                subjects_repair, 
                key="subject_repair"
            )
            
            render_warning_box(AppConstants.WARNING_MESSAGES["repair_subject"].format(subject=selected_subject_repair))
            
            if st.button(f"ğŸ”§ å¼€å§‹ä¿®å¤ {selected_subject_repair} åŒé“¾", type="primary", use_container_width=True):
                with st.spinner(UIConstants.MESSAGES['processing']):
                    result = processor.link_repairer.repair_specific_subject(selected_subject_repair)
                    
                    render_success_box(f"{selected_subject_repair} ç§‘ç›®åŒé“¾ä¿®å¤å®Œæˆï¼")
                    render_repair_stats(result)
                    
                    if result['repaired'] > 0:
                        st.info("ğŸ“š æ­£åœ¨æ›´æ–°æ¦‚å¿µæ•°æ®åº“...")
                        processor.concept_manager.scan_existing_notes()
                        render_success_box(AppConstants.SUCCESS_MESSAGES["database_updated"])

        elif repair_scope == AppConstants.SCOPE_OPTIONS["repair"][2]:  # æŸ¥æ‰¾æŸåé“¾æ¥
            if st.button("ğŸ” å¼€å§‹æ£€æŸ¥æŸååŒé“¾", use_container_width=True):
                with st.spinner("æ­£åœ¨æ£€æŸ¥æŸåçš„åŒé“¾..."):
                    broken_links = processor.link_repairer.find_broken_links()
                    render_broken_links_list(broken_links)

    elif menu_choice == "ğŸ“Š æŸ¥çœ‹æ¦‚å¿µæ•°æ®åº“":
        st.header("æ¦‚å¿µæ•°æ®åº“çŠ¶æ€")
        render_concept_database_status(processor.concept_manager, Config)

    elif menu_choice == "ğŸ“ ç§‘ç›®æ–‡ä»¶å¤¹æ˜ å°„":
        st.header("ç§‘ç›®æ–‡ä»¶å¤¹æ˜ å°„")
        render_subject_mapping(Config)

    elif menu_choice == "ğŸ“š æŸ¥çœ‹ç¬”è®°ä»“åº“":
        render_note_browser(processor, Config)

    elif menu_choice == "âš™ï¸ æ¨¡å‹é…ç½®":
        st.header("âš™ï¸ æ¨¡å‹é…ç½®")
        
        tabs = render_model_config_tabs()
        
        with tabs[0]:  # å­—å¹•å¤„ç†æ¨¡å‹
            saved_configs = st.session_state.model_configs.get('subtitle', {})
            result = render_model_config_section(
                "å­—å¹•å¤„ç†æ¨¡å‹é…ç½®",
                st.session_state.current_subtitle_config,
                saved_configs,
                "subtitle"
            )
            
            if result['save']:
                if result['config_name'] and result['api_key'] and result['base_url'] and result['model']:
                    if 'subtitle' not in st.session_state.model_configs:
                        st.session_state.model_configs['subtitle'] = {}
                    st.session_state.model_configs['subtitle'][result['config_name']] = {
                        'api_key': result['api_key'],
                        'base_url': result['base_url'],
                        'model': result['model']
                    }
                    save_model_configs(st.session_state.model_configs)
                    render_success_box(f"é…ç½® '{result['config_name']}' å·²ä¿å­˜")
                    st.rerun()
                else:
                    render_error_box("è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
            
            if result['use']:
                if result['api_key'] and result['base_url'] and result['model']:
                    # æ›´æ–°å½“å‰é…ç½®
                    st.session_state.current_subtitle_config = {
                        'name': result['config_name'] or 'ä¸´æ—¶é…ç½®',
                        'api_key': result['api_key'],
                        'base_url': result['base_url'],
                        'model': result['model']
                    }
                    # æ›´æ–°Config
                    Config.SUBTITLE_PROCESSING_API_KEY = result['api_key']
                    Config.SUBTITLE_PROCESSING_BASE_URL = result['base_url']
                    Config.SUBTITLE_PROCESSING_MODEL = result['model']
                    render_success_box(f"å·²åˆ‡æ¢åˆ°é…ç½®: {result['config_name'] or 'ä¸´æ—¶é…ç½®'}")
                else:
                    render_error_box("è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
            
            if result['delete']:
                if result['selected_config'] in st.session_state.model_configs.get('subtitle', {}):
                    del st.session_state.model_configs['subtitle'][result['selected_config']]
                    save_model_configs(st.session_state.model_configs)
                    render_success_box(f"é…ç½® '{result['selected_config']}' å·²åˆ é™¤")
                    st.rerun()
        
        with tabs[1]:  # æ¦‚å¿µå¢å¼ºæ¨¡å‹
            saved_configs = st.session_state.model_configs.get('concept', {})
            result = render_model_config_section(
                "æ¦‚å¿µå¢å¼ºæ¨¡å‹é…ç½®",
                st.session_state.current_concept_config,
                saved_configs,
                "concept"
            )
            
            if result['save']:
                if result['config_name'] and result['api_key'] and result['base_url'] and result['model']:
                    if 'concept' not in st.session_state.model_configs:
                        st.session_state.model_configs['concept'] = {}
                    st.session_state.model_configs['concept'][result['config_name']] = {
                        'api_key': result['api_key'],
                        'base_url': result['base_url'],
                        'model': result['model']
                    }
                    save_model_configs(st.session_state.model_configs)
                    render_success_box(f"é…ç½® '{result['config_name']}' å·²ä¿å­˜")
                    st.rerun()
                else:
                    render_error_box("è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
            
            if result['use']:
                if result['api_key'] and result['base_url'] and result['model']:
                    # æ›´æ–°å½“å‰é…ç½®
                    st.session_state.current_concept_config = {
                        'name': result['config_name'] or 'ä¸´æ—¶é…ç½®',
                        'api_key': result['api_key'],
                        'base_url': result['base_url'],
                        'model': result['model']
                    }
                    # æ›´æ–°Configå’Œå¤„ç†å™¨
                    Config.CONCEPT_ENHANCEMENT_API_KEY = result['api_key']
                    Config.CONCEPT_ENHANCEMENT_BASE_URL = result['base_url']
                    Config.CONCEPT_ENHANCEMENT_MODEL = result['model']
                    processor.concept_enhancement_ai_processor = AIProcessor(result['api_key'], result['base_url'], result['model'])
                    render_success_box(f"å·²åˆ‡æ¢åˆ°é…ç½®: {result['config_name'] or 'ä¸´æ—¶é…ç½®'}")
                else:
                    render_error_box("è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
            
            if result['delete']:
                if result['selected_config'] in st.session_state.model_configs.get('concept', {}):
                    del st.session_state.model_configs['concept'][result['selected_config']]
                    save_model_configs(st.session_state.model_configs)
                    render_success_box(f"é…ç½® '{result['selected_config']}' å·²åˆ é™¤")
                    st.rerun()
        
        with tabs[2]:  # é«˜çº§è®¾ç½®
            st.markdown("### é«˜çº§è®¾ç½®")
            
            # æ¨èæ¨¡å‹ä¿¡æ¯
            with st.expander("ğŸ“‹ æ¨èæ¨¡å‹", expanded=True):
                st.markdown("#### ğŸ† é«˜æ€§èƒ½æ¨¡å‹")
                for model in ModelConfig.RECOMMENDED_MODELS["high_performance"]:
                    st.markdown(f"- {model}")
                
                st.markdown("#### ğŸ’° ç»æµå®æƒ æ¨¡å‹")
                for model in ModelConfig.RECOMMENDED_MODELS["budget_friendly"]:
                    st.markdown(f"- {model}")
                
                st.markdown("#### ğŸ¯ ä¸“ä¸šç‰¹åŒ–æ¨¡å‹")
                for model in ModelConfig.RECOMMENDED_MODELS["specialized"]:
                    st.markdown(f"- {model}")
                
                # ä¸¤æ­¥èµ°æ¨¡å‹æ¨è
                st.markdown("#### ğŸ” ä¸¤æ­¥èµ°æ¨¡å‹æ¨è")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ç¬¬ä¸€æ­¥åˆ†ææ¨è:**")
                    for model in ModelConfig.RECOMMENDED_MODELS["step_recommendations"]["step1"]:
                        st.markdown(f"- {model}")
                with col2:
                    st.markdown("**ç¬¬äºŒæ­¥ç”Ÿæˆæ¨è:**")
                    for model in ModelConfig.RECOMMENDED_MODELS["step_recommendations"]["step2"]:
                        st.markdown(f"- {model}")
            
            # æ™ºèƒ½åˆ†æ®µé…ç½®
            if SEGMENTATION_AVAILABLE:
                with st.expander("ğŸ”§ æ™ºèƒ½åˆ†æ®µé…ç½®", expanded=False):
                    st.markdown("#### æ™ºèƒ½åˆ†æ®µæ¨¡å—çŠ¶æ€")
                    st.success("âœ… æ™ºèƒ½åˆ†æ®µæ¨¡å—å·²å®‰è£…")
                    
                    st.markdown("#### åˆ†æ®µæ•ˆæœæŒ‡æ ‡")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("å¹³å‡TokenèŠ‚çœ", "65%", help="æ™ºèƒ½åˆ†æ®µå¹³å‡èŠ‚çœçš„tokenæ¯”ä¾‹")
                        st.metric("å¤„ç†é€Ÿåº¦æå‡", "40%", help="ç›¸æ¯”ä¼ ç»Ÿæ–¹å¼çš„é€Ÿåº¦æå‡")
                    with col2:
                        st.metric("å‡†ç¡®ç‡ç»´æŒ", "98%", help="ä½¿ç”¨æ™ºèƒ½åˆ†æ®µåçš„å‡†ç¡®ç‡")
                        st.metric("æˆåŠŸç‡", "99.5%", help="æ™ºèƒ½åˆ†æ®µçš„æˆåŠŸç‡ï¼ˆå«å›é€€ï¼‰")
                    
                    st.markdown("#### åˆ†æ®µå‚æ•°è¯´æ˜")
                    st.markdown("- **ç¼“å†²åŒºå¤§å°**: ä¸ºæ¯ä¸ªçŸ¥è¯†ç‚¹æ—¶é—´æ®µå‰åæ·»åŠ çš„ç¼“å†²æ—¶é—´")
                    st.markdown("- **åˆå¹¶é—´éš”**: ç›¸é‚»ç‰‡æ®µé—´éš”å°äºæ­¤å€¼æ—¶è‡ªåŠ¨åˆå¹¶")
                    st.markdown("- **è‡ªåŠ¨å›é€€**: åˆ†æ®µå¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨å®Œæ•´å†…å®¹")
            else:
                with st.expander("âš ï¸ æ™ºèƒ½åˆ†æ®µæ¨¡å—", expanded=False):
                    st.error("âŒ æ™ºèƒ½åˆ†æ®µæ¨¡å—æœªå®‰è£…")
                    st.markdown("**ç¼ºå¤±æ–‡ä»¶:**")
                    st.markdown("- `intelligent_segmenter.py`")
                    st.markdown("- `time_parser.py`")
                    st.info("ğŸ’¡ å®‰è£…æ™ºèƒ½åˆ†æ®µæ¨¡å—åé‡å¯åº”ç”¨å³å¯å¯ç”¨æ­¤åŠŸèƒ½")
            
            # æ¨¡å‹æµ‹è¯•
            st.markdown("#### ğŸ§ª æ¨¡å‹è¿æ¥æµ‹è¯•")
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("æµ‹è¯•å­—å¹•å¤„ç†æ¨¡å‹", use_container_width=True):
                    try:
                        test_processor = AIProcessor(
                            st.session_state.current_subtitle_config['api_key'],
                            st.session_state.current_subtitle_config['base_url'],
                            st.session_state.current_subtitle_config['model']
                        )
                        # ç®€å•çš„æµ‹è¯•è¯·æ±‚
                        response = test_processor.client.chat.completions.create(
                            model=test_processor.model,
                            messages=[{"role": "user", "content": "æµ‹è¯•è¿æ¥"}],
                            max_tokens=10
                        )
                        render_success_box("å­—å¹•å¤„ç†æ¨¡å‹è¿æ¥æ­£å¸¸")
                    except Exception as e:
                        render_error_box(f"å­—å¹•å¤„ç†æ¨¡å‹è¿æ¥å¤±è´¥: {e}")
            
            with col2:
                if st.button("æµ‹è¯•æ¦‚å¿µå¢å¼ºæ¨¡å‹", use_container_width=True):
                    try:
                        test_processor = AIProcessor(
                            st.session_state.current_concept_config['api_key'],
                            st.session_state.current_concept_config['base_url'],
                            st.session_state.current_concept_config['model']
                        )
                        # ç®€å•çš„æµ‹è¯•è¯·æ±‚
                        response = test_processor.client.chat.completions.create(
                            model=test_processor.model,
                            messages=[{"role": "user", "content": "æµ‹è¯•è¿æ¥"}],
                            max_tokens=10
                        )
                        render_success_box("æ¦‚å¿µå¢å¼ºæ¨¡å‹è¿æ¥æ­£å¸¸")
                    except Exception as e:
                        render_error_box(f"æ¦‚å¿µå¢å¼ºæ¨¡å‹è¿æ¥å¤±è´¥: {e}")
            
            # ç¼“å­˜ç®¡ç†
            st.markdown("#### ğŸ—‚ï¸ ç¼“å­˜ç®¡ç†")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("æ¸…ç©ºæ¨¡å‹é…ç½®ç¼“å­˜", use_container_width=True):
                    try:
                        if os.path.exists(MODEL_CONFIG_CACHE_PATH):
                            os.remove(MODEL_CONFIG_CACHE_PATH)
                        st.session_state.model_configs = {}
                        render_success_box("æ¨¡å‹é…ç½®ç¼“å­˜å·²æ¸…ç©º")
                        st.rerun()
                    except Exception as e:
                        render_error_box(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
            
            with col2:
                if st.button("æ¸…ç©ºBGEåµŒå…¥ç¼“å­˜", use_container_width=True):
                    try:
                        bge_cache_file = os.path.join(Config.OBSIDIAN_VAULT_PATH, "æ¦‚å¿µåµŒå…¥ç¼“å­˜_BGE.json")
                        if os.path.exists(bge_cache_file):
                            os.remove(bge_cache_file)
                        render_success_box("BGEåµŒå…¥ç¼“å­˜å·²æ¸…ç©º")
                    except Exception as e:
                        render_error_box(f"æ¸…ç©ºBGEç¼“å­˜å¤±è´¥: {e}")
            
            with col3:
                if st.button("é‡ç½®æ‰€æœ‰é…ç½®", use_container_width=True):
                    if st.button("ç¡®è®¤é‡ç½®", type="primary"):
                        try:
                            # æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
                            if os.path.exists(MODEL_CONFIG_CACHE_PATH):
                                os.remove(MODEL_CONFIG_CACHE_PATH)
                            
                            bge_cache_file = os.path.join(Config.OBSIDIAN_VAULT_PATH, "æ¦‚å¿µåµŒå…¥ç¼“å­˜_BGE.json")
                            if os.path.exists(bge_cache_file):
                                os.remove(bge_cache_file)
                            
                            # é‡ç½®session state
                            for key in ['model_configs', 'current_subtitle_config', 'current_concept_config', 'two_step_state', 'segmentation_config']:
                                if key in st.session_state:
                                    del st.session_state[key]
                            
                            render_success_box("æ‰€æœ‰é…ç½®å·²é‡ç½®")
                            st.rerun()
                        except Exception as e:
                            render_error_box(f"é‡ç½®å¤±è´¥: {e}")
                    else:
                        render_warning_box("ç‚¹å‡»'ç¡®è®¤é‡ç½®'æŒ‰é’®ç¡®è®¤æ“ä½œ")
            
            # ç³»ç»Ÿä¿¡æ¯
            st.markdown("#### â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
            system_info = {
                "åº”ç”¨ç‰ˆæœ¬": AppConstants.VERSION,
                "Pythonç‰ˆæœ¬": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                "Streamlitç‰ˆæœ¬": st.__version__,
                "å·¥ä½œç›®å½•": os.getcwd(),
                "é…ç½®æ–‡ä»¶": Config.OBSIDIAN_VAULT_PATH,
                "æ™ºèƒ½åˆ†æ®µ": "å·²å®‰è£…" if SEGMENTATION_AVAILABLE else "æœªå®‰è£…"
            }
            
            for key, value in system_info.items():
                st.write(f"**{key}**: `{value}`")

# é¡µé¢åº•éƒ¨ä¿¡æ¯ï¼ˆåŒ…å«æ™ºèƒ½åˆ†æ®µåŠŸèƒ½ï¼‰
st.markdown("---")
st.markdown(
    f"""
    <div style="text-align: center; color: #787774; font-size: 12px; padding: 20px;">
        {AppConstants.APP_TITLE} v{AppConstants.VERSION} | 
        ç”± {AppConstants.AUTHOR} å¼€å‘ | 
        <span style="color: #2383e2;">ğŸ”§ é›†æˆæ™ºèƒ½åˆ†æ®µæŠ€æœ¯</span> |
        <a href="https://github.com/your-repo" style="color: #2383e2;">GitHub</a>
    </div>
    """, 
    unsafe_allow_html=True
)

# é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•ï¼ˆæ‰©å±•ç‰ˆæœ¬ï¼‰
if __name__ == "__main__":
    try:
        # æ£€æŸ¥æ™ºèƒ½åˆ†æ®µä¾èµ–
        try:
            from intelligent_segmenter import IntelligentSegmenter
            from time_parser import TimeParser
            print("âœ… æ™ºèƒ½åˆ†æ®µæ¨¡å—åŠ è½½æˆåŠŸ")
        except ImportError as e:
            print(f"âŒ æ™ºèƒ½åˆ†æ®µæ¨¡å—åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿ intelligent_segmenter.py å’Œ time_parser.py æ–‡ä»¶å­˜åœ¨")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–é€»è¾‘
        pass
    except Exception as e:
        st.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
        st.exception(e)