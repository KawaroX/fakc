# ai_processor.py - æ›´æ–°ç‰ˆæœ¬ï¼Œé›†æˆæ™ºèƒ½åˆ†æ®µåŠŸèƒ½
import yaml
import re
import datetime
import json
from openai import OpenAI
from typing import List, Dict, Any, Optional, Tuple

from intelligent_segmenter import IntelligentSegmenter, Segment
from concurrent_processor import run_concurrent_processing, ConcurrentConfig

class AIProcessor:
    def __init__(self, api_key: str, base_url: str, model: str):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        # åˆå§‹åŒ–æ™ºèƒ½åˆ†æ®µå™¨
        self.segmenter = IntelligentSegmenter()

        # æ–°å¢ï¼šå¹¶å‘é…ç½®
        self.concurrent_config = ConcurrentConfig(
            max_concurrent=20,      # APIé™åˆ¶
            max_retries=3,          # æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay=1.0,        # é‡è¯•å»¶è¿Ÿ
            timeout=60,             # å•ä¸ªä»»åŠ¡è¶…æ—¶
            rate_limit_delay=60.0   # é€Ÿç‡é™åˆ¶ç­‰å¾…æ—¶é—´
        )
        
        # ç”¨äºè¿›åº¦å›è°ƒçš„å±æ€§
        self.progress_callback = None
    
    def _separate_markdown_content(self, full_content: str) -> tuple:
        """
        åˆ†ç¦»markdownçš„YAML frontmatterå’Œæ­£æ–‡å†…å®¹
        
        Returns:
            tuple: (yaml_data: dict, content_only: str, has_yaml: bool)
        """
        
        full_content = full_content.strip()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰YAML frontmatter
        if full_content.startswith('---'):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…YAML frontmatter
            yaml_match = re.match(r'^---\n(.*?)\n---\n?(.*)', full_content, re.DOTALL)
            if yaml_match:
                try:
                    yaml_content = yaml_match.group(1)
                    content_only = yaml_match.group(2).strip()
                    yaml_data = yaml.safe_load(yaml_content)
                    return yaml_data, content_only, True
                except yaml.YAMLError as e:
                    print(f"âš ï¸ YAMLè§£æå¤±è´¥: {e}")
                    return {}, full_content, False
        
        # æ²¡æœ‰YAML frontmatter
        return {}, full_content, False

    def _combine_markdown_content(self, yaml_data: dict, content_only: str, has_yaml: bool) -> str:
        """
        é‡æ–°ç»„åˆYAML frontmatterå’Œæ­£æ–‡å†…å®¹
        
        Args:
            yaml_data: YAMLæ•°æ®å­—å…¸
            content_only: çº¯æ­£æ–‡å†…å®¹
            has_yaml: åŸå§‹æ–‡ä»¶æ˜¯å¦æœ‰YAML
        
        Returns:
            str: å®Œæ•´çš„markdownå†…å®¹
        """
        if not has_yaml or not yaml_data:
            return content_only
        
        
        # ç”ŸæˆYAML frontmatter
        yaml_str = yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False)
        
        return f"---\n{yaml_str}---\n\n{content_only}"

    # ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†ç‚¹åˆ†æä¸æ¶æ„æ„å»º
    def extract_knowledge_points_step1(self, subtitle_content: str, metadata: Dict[str, str]) -> Dict:
        """æ‰§è¡Œç¬¬ä¸€æ­¥åˆ†æï¼Œè¾“å‡ºJSONç»“æ„"""
        prompt = self.STEP1_PROMPT_TEMPLATE.format(
            subtitle_content=subtitle_content,
            subject=metadata['subject'],
            source=metadata['source'],
            course_url=metadata.get('course_url', 'æœªæä¾›')
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0,
            )
            
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"âŒ ç¬¬ä¸€æ­¥åˆ†æå¤±è´¥: {e}")
            return {}

    # ç¬¬äºŒæ­¥ï¼šè¯¦ç»†ç¬”è®°æ•´ç†ï¼ˆé›†æˆæ™ºèƒ½åˆ†æ®µï¼‰
    def generate_notes_step2(self, analysis_result: Dict, subtitle_content: str, 
                           metadata: Dict[str, str], use_segmentation: bool = True) -> List[Dict[str, Any]]:
        """
        æ ¹æ®ç¬¬ä¸€æ­¥ç»“æœç”Ÿæˆæœ€ç»ˆç¬”è®°ï¼ˆé›†æˆæ™ºèƒ½åˆ†æ®µï¼‰
        
        Args:
            analysis_result: ç¬¬ä¸€æ­¥åˆ†æç»“æœ
            subtitle_content: åŸå§‹å­—å¹•å†…å®¹
            metadata: å…ƒæ•°æ®
            use_segmentation: æ˜¯å¦ä½¿ç”¨æ™ºèƒ½åˆ†æ®µï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            ç”Ÿæˆçš„ç¬”è®°åˆ—è¡¨
        """
        try:
            # å¦‚æœå¯ç”¨æ™ºèƒ½åˆ†æ®µ
            if use_segmentation:
                print("ğŸ”§ å¯ç”¨æ™ºèƒ½åˆ†æ®µå¤„ç†...")
                
                # æ£€æµ‹å­—å¹•æ ¼å¼
                file_format = self._detect_subtitle_format(subtitle_content)
                
                # æ‰§è¡Œæ™ºèƒ½åˆ†æ®µ
                segments = self.segmenter.segment_by_knowledge_points(
                    subtitle_content, 
                    analysis_result, 
                    file_format
                )
                
                # è·å–åˆ†æ®µæ‘˜è¦
                summary = self.segmenter.get_segments_summary(segments)
                print(f"ğŸ“Š åˆ†æ®µæ‘˜è¦: {summary['total_segments']}ä¸ªåˆ†æ®µ, "
                      f"Tokenå‡å°‘{(1-summary['total_tokens']/self.segmenter._estimate_token_count(subtitle_content))*100:.1f}%")
                
                # ä½¿ç”¨ç‹¬ç«‹åˆ†æ®µå†…å®¹ç”Ÿæˆç¬”è®°
                return self._generate_notes_from_individual_segments(segments, analysis_result, metadata)
            else:
                print("ğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç†...")
                # ä¼ ç»Ÿæ–¹å¼ï¼šä½¿ç”¨å®Œæ•´å­—å¹•å†…å®¹
                return self._generate_notes_traditional(analysis_result, subtitle_content, metadata)
                
        except Exception as e:
            print(f"âŒ ç¬¬äºŒæ­¥ç¬”è®°ç”Ÿæˆå¤±è´¥: {e}")
            # Fallbackåˆ°ä¼ ç»Ÿæ–¹å¼
            return self._generate_notes_traditional(analysis_result, subtitle_content, metadata)
    
    def _detect_subtitle_format(self, content: str) -> str:
        """
        æ£€æµ‹å­—å¹•æ–‡ä»¶æ ¼å¼
        
        Args:
            content: å­—å¹•å†…å®¹
            
        Returns:
            æ£€æµ‹åˆ°çš„æ ¼å¼ï¼š'lrc', 'srt', 'txt'
        """
        if re.search(r'\[\d{1,2}:\d{2}(?:\.\d{1,3})?\]', content):
            return 'lrc'
        elif re.search(r'\d{2}:\d{2}:\d{2},\d{3}\s*-->\s*\d{2}:\d{2}:\d{2},\d{3}', content):
            return 'srt'
        else:
            return 'txt'
    
    def _generate_notes_from_segments(self, segments: List[Segment], 
                                    analysis_result: Dict, metadata: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        åŸºäºåˆ†æ®µç»“æœç”Ÿæˆç¬”è®°
        
        Args:
            segments: æ™ºèƒ½åˆ†æ®µç»“æœ
            analysis_result: ç¬¬ä¸€æ­¥åˆ†æç»“æœ
            metadata: å…ƒæ•°æ®
            
        Returns:
            ç”Ÿæˆçš„ç¬”è®°åˆ—è¡¨
        """
        all_notes = []
        knowledge_points = analysis_result.get('knowledge_points', [])
        
        # ä¸ºæ¯ä¸ªåˆ†æ®µæ„å»ºå¯¹åº”çš„çŸ¥è¯†ç‚¹ç»„
        for segment in segments:
            if not segment.text.strip():  # è·³è¿‡ç©ºåˆ†æ®µ
                continue
                
            # æ‰¾åˆ°ä¸æ­¤åˆ†æ®µç›¸å…³çš„çŸ¥è¯†ç‚¹
            related_kps = []
            for kp in knowledge_points:
                if kp.get('id') in segment.knowledge_points:
                    related_kps.append(kp)
            
            if not related_kps:  # å¦‚æœæ²¡æœ‰å…³è”çš„çŸ¥è¯†ç‚¹ï¼Œè·³è¿‡
                continue
            
            # æ„å»ºåˆ†æ®µå¤„ç†çš„æç¤ºè¯
            segment_prompt = self._build_segment_prompt(
                segment, related_kps, analysis_result, metadata
            )
            
            try:
                # è°ƒç”¨AIå¤„ç†åˆ†æ®µ
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": segment_prompt}],
                    temperature=0,
                )
                
                # è§£æAIè¿”å›çš„ç¬”è®°
                segment_notes = self._parse_ai_response(response.choices[0].message.content)
                if segment_notes:
                    all_notes.extend(segment_notes)
                    print(f"âœ… åˆ†æ®µå¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(segment_notes)} ä¸ªç¬”è®°")
                
            except Exception as e:
                print(f"âš ï¸ åˆ†æ®µå¤„ç†å¤±è´¥ï¼Œè·³è¿‡: {e}")
                continue
        
        return all_notes
    
    # def _generate_notes_from_individual_segments(self, segments: List[Segment], 
    #                                        analysis_result: Dict, metadata: Dict[str, str]) -> List[Dict[str, Any]]:
    #     """
    #     åŸºäºç‹¬ç«‹åˆ†æ®µç»“æœç”Ÿæˆç¬”è®°ï¼ˆæ¯ä¸ªçŸ¥è¯†ç‚¹å¯¹åº”ä¸€ä¸ªæ®µè½ï¼‰
    #     """
    #     all_notes = []
    #     knowledge_points = analysis_result.get('knowledge_points', [])
        
    #     print(f"ğŸ“ å¼€å§‹å¤„ç† {len(segments)} ä¸ªç‹¬ç«‹æ®µè½...")
        
    #     # ä¸ºæ¯ä¸ªåˆ†æ®µå•ç‹¬å¤„ç†ï¼ˆæ¯ä¸ªåˆ†æ®µåªå¯¹åº”ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼‰
    #     for i, segment in enumerate(segments, 1):
    #         if not segment.text.strip():  # è·³è¿‡ç©ºåˆ†æ®µ
    #             print(f"âš ï¸ è·³è¿‡ç©ºåˆ†æ®µ {i}")
    #             continue
                
    #         # æ¯ä¸ªåˆ†æ®µåº”è¯¥åªæœ‰ä¸€ä¸ªçŸ¥è¯†ç‚¹
    #         if len(segment.knowledge_points) != 1:
    #             print(f"âš ï¸ åˆ†æ®µ {i} åŒ…å« {len(segment.knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹ï¼Œè·³è¿‡")
    #             continue
            
    #         kp_id = segment.knowledge_points[0]
            
    #         # æ‰¾åˆ°å¯¹åº”çš„çŸ¥è¯†ç‚¹
    #         target_kp = None
    #         for kp in knowledge_points:
    #             if kp.get('id') == kp_id:
    #                 target_kp = kp
    #                 break
            
    #         if not target_kp:
    #             print(f"âš ï¸ æ‰¾ä¸åˆ°çŸ¥è¯†ç‚¹ {kp_id}ï¼Œè·³è¿‡åˆ†æ®µ {i}")
    #             continue
            
    #         # æ„å»ºå•ä¸ªçŸ¥è¯†ç‚¹çš„å¤„ç†æç¤ºè¯
    #         single_kp_prompt = self._build_single_knowledge_point_prompt(
    #             segment, target_kp, analysis_result, metadata
    #         )
            
    #         try:
    #             print(f"ğŸ¤– å¤„ç†çŸ¥è¯†ç‚¹: {target_kp.get('concept_name', kp_id)} (åˆ†æ®µ {i}/{len(segments)})")
                
    #             # è°ƒç”¨AIå¤„ç†å•ä¸ªçŸ¥è¯†ç‚¹
    #             response = self.client.chat.completions.create(
    #                 model=self.model,
    #                 messages=[{"role": "user", "content": single_kp_prompt}],
    #                 temperature=0,
    #             )
                
    #             # è§£æAIè¿”å›çš„å•ä¸ªç¬”è®°ï¼ˆä¸åŒ…å«åˆ†éš”ç¬¦ï¼‰
    #             note_content = response.choices[0].message.content.strip()
                
    #             # è§£æå•ä¸ªç¬”è®°
    #             parsed_note = self._parse_single_note_response(note_content, target_kp, metadata)
                
    #             if parsed_note:
    #                 all_notes.append(parsed_note)
    #                 print(f"âœ… æˆåŠŸç”Ÿæˆç¬”è®°: {target_kp.get('concept_name', kp_id)}")
    #             else:
    #                 print(f"âš ï¸ è§£æç¬”è®°å¤±è´¥: {target_kp.get('concept_name', kp_id)}")
                
    #         except Exception as e:
    #             print(f"âš ï¸ å¤„ç†çŸ¥è¯†ç‚¹ {kp_id} å¤±è´¥: {e}")
    #             continue
        
    #     print(f"âœ… ç‹¬ç«‹åˆ†æ®µå¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_notes)} ä¸ªç¬”è®°")
    #     return all_notes
    
    def _build_segment_prompt(self, segment: Segment, related_kps: List[Dict], 
                            analysis_result: Dict, metadata: Dict[str, str]) -> str:
        """
        æ„å»ºåˆ†æ®µå¤„ç†çš„æç¤ºè¯
        
        Args:
            segment: åˆ†æ®µå¯¹è±¡
            related_kps: ç›¸å…³çŸ¥è¯†ç‚¹åˆ—è¡¨
            analysis_result: å®Œæ•´åˆ†æç»“æœ
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ„å»ºå¥½çš„æç¤ºè¯
        """
        # æå–è¯¾ç¨‹æ¦‚è§ˆå’Œæ•™å­¦æ´å¯Ÿ
        course_overview = analysis_result.get('course_overview', {})
        teaching_insights = analysis_result.get('teaching_insights', {})
        
        # æ„å»ºçŸ¥è¯†ç‚¹ä¿¡æ¯
        kp_info = []
        for kp in related_kps:
            kp_summary = {
                'id': kp.get('id', ''),
                'concept_name': kp.get('concept_name', ''),
                'concept_type': kp.get('concept_type', ''),
                'importance_level': kp.get('importance_level', ''),
                'time_range': kp.get('time_range', ''),
                'core_definition': kp.get('core_definition', {}),
                'detailed_content': kp.get('detailed_content', {}),
                'exam_relevance': kp.get('exam_relevance', {}),
                'relationships': kp.get('relationships', {})
            }
            kp_info.append(kp_summary)
        
        return self.SEGMENT_PROMPT_TEMPLATE.format(
            segment_text=segment.text,
            time_range=f"{segment.time_range.start:.1f}-{segment.time_range.end:.1f}s",
            knowledge_points=json.dumps(kp_info, ensure_ascii=False, indent=2),
            course_overview=json.dumps(course_overview, ensure_ascii=False),
            teaching_insights=json.dumps(teaching_insights, ensure_ascii=False),
            subject=metadata['subject'],
            source=metadata['source'],
            course_url=metadata.get('course_url', '')
        )
    
    def _generate_notes_traditional(self, analysis_result: Dict, subtitle_content: str, 
                                  metadata: Dict[str, str]) -> List[Dict[str, Any]]:
        """ä¼ ç»Ÿæ–¹å¼ç”Ÿæˆç¬”è®°ï¼ˆä½¿ç”¨å®Œæ•´å­—å¹•å†…å®¹ï¼‰"""
        prompt = self.STEP2_PROMPT_TEMPLATE.format(
            analysis_result=json.dumps(analysis_result, ensure_ascii=False),
            subtitle_content=subtitle_content,
            subject=metadata['subject'],
            source=metadata['source'],
            course_url=metadata.get('course_url', '')
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0,
            )
            
            return self._parse_ai_response(response.choices[0].message.content)
        except Exception as e:
            print(f"âŒ ä¼ ç»Ÿæ–¹å¼ç¬”è®°ç”Ÿæˆå¤±è´¥: {e}")
            return []

    # æ—§ç‰ˆå…¼å®¹æ–¹æ³•ï¼ˆå•æ­¥å¤„ç†ï¼‰
    def extract_all_knowledge_points(self, subtitle_content: str, metadata: Dict[str, str]) -> List[Dict[str, Any]]:
        """ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªå­—å¹•ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰"""
        # ä½¿ç”¨æ–°ä¸¤æ­¥æ³•å¤„ç†
        analysis = self.extract_knowledge_points_step1(subtitle_content, metadata)
        if not analysis:
            return []
        return self.generate_notes_step2(analysis, subtitle_content, metadata)
    
    # æ–°å¢ï¼šåˆ†æ®µå¤„ç†çš„æç¤ºè¯æ¨¡æ¿
    SEGMENT_PROMPT_TEMPLATE = """\
ä½ æ˜¯ä¸“ä¸šçš„æ³•è€ƒç¬”è®°æ•´ç†ä¸“å®¶ã€‚è¯·æ ¹æ®ç¬¬ä¸€æ­¥åˆ†æç»“æœå’Œå¯¹åº”çš„å­—å¹•ç‰‡æ®µï¼Œç”Ÿæˆå®Œæ•´çš„Obsidianç¬”è®°ã€‚

## è¾“å…¥å†…å®¹

**å­—å¹•ç‰‡æ®µ**ï¼ˆæ—¶é—´èŒƒå›´: {time_range}ï¼‰ï¼š
{segment_text}

**ç›¸å…³çŸ¥è¯†ç‚¹åˆ†æ**ï¼š
{knowledge_points}

**è¯¾ç¨‹æ¦‚è§ˆ**ï¼š
{course_overview}

**æ•™å­¦é£æ ¼æ´å¯Ÿ**ï¼š
{teaching_insights}

**è¯¾ç¨‹ä¿¡æ¯**ï¼š
- ç§‘ç›®ï¼š{subject}
- æ¥æºï¼š{source}
- è¯¾ç¨‹é“¾æ¥ï¼š{course_url}

## å¤„ç†è¦æ±‚

**ç²¾ç¡®å¯¹åº”**ï¼šä¸¥æ ¼åŸºäºæä¾›çš„çŸ¥è¯†ç‚¹åˆ†æç»“æœï¼Œä¸ºæ¯ä¸ªknowledge_pointç”Ÿæˆå¯¹åº”ç¬”è®°

**å……åˆ†åˆ©ç”¨ç‰‡æ®µå†…å®¹**ï¼šæ·±åº¦æŒ–æ˜å­—å¹•ç‰‡æ®µä¸­çš„ä¿¡æ¯ï¼Œä¿ç•™è€å¸ˆçš„åŸå§‹è¡¨è¿°å’Œé‡è¦ç»†èŠ‚

**æ—¶é—´æˆ³å¤„ç†**ï¼šä½¿ç”¨time_rangeä¿¡æ¯æ·»åŠ å‡†ç¡®çš„æ—¶é—´æˆ³æ ‡è®°ï¼Œæ ¼å¼ä¸º[MM:SS.mm]

**æ¦‚å¿µå…³è”**ï¼šåŸºäºrelationshipsä¿¡æ¯å»ºç«‹å‡†ç¡®çš„åŒé“¾å…³ç³»

## ç¬”è®°ç”Ÿæˆè§„åˆ™

**YAMLå…ƒæ•°æ®æ ‡å‡†**ï¼š
```yaml
title: "ã€{subject}ã€‘{{concept_name}}"
aliases: ["{{concept_name}}", "å…¶ä»–åˆ«å"]
tags: ["{subject}", "æ ¹æ®concept_typeç¡®å®š", "æ ¹æ®importance_levelç¡®å®š"]
source: "{source}"
course_url: "{course_url}"
time_range: "{{time_range}}"
subject: "{subject}"
exam_importance: "{{importance_level}}"
concept_id: "{{id}}"
created: "å½“å‰æ—¶é—´"
```

**ç« èŠ‚ç»“æ„æ™ºèƒ½è®¾è®¡**ï¼šæ ¹æ®concept_typeæ™ºèƒ½é€‰æ‹©ç« èŠ‚ç»“æ„
- å®šä¹‰æ€§æ¦‚å¿µï¼šæ ¸å¿ƒå®šä¹‰ + å…³é”®è¦ç´  + å…¸å‹æ¡ˆä¾‹
- æ„æˆè¦ä»¶ï¼šè¦ä»¶æ¦‚è¿° + è¦ä»¶è¯¦è§£ + ä¸¾è¯è´£ä»»
- ç¨‹åºæ€§çŸ¥è¯†ï¼šç¨‹åºæ¦‚è¿° + æ“ä½œæ­¥éª¤ + æ³¨æ„äº‹é¡¹
- åˆ¤æ–­æ ‡å‡†ï¼šæ ‡å‡†æ¦‚è¿° + åˆ¤æ–­è¦ç´  + é€‚ç”¨æƒ…å½¢
- æ³•æ¡è§„å®šï¼šæ¡æ–‡å†…å®¹ + ç«‹æ³•èƒŒæ™¯ + é€‚ç”¨æƒ…å½¢
- å®åŠ¡ç»éªŒï¼šç»éªŒæ¦‚è¿° + æ“ä½œè¦ç‚¹ + å®ç”¨æŠ€å·§

**å†…å®¹å¡«å……ç­–ç•¥**ï¼š
- æ ¸å¿ƒå®šä¹‰ï¼šä¼˜å…ˆä½¿ç”¨teacher_originalï¼Œè¡¥å……contextä¿¡æ¯
- è¯¦ç»†å±•å¼€ï¼šåŸºäºdetailed_contentçš„main_explanationå’Œexamples
- è®°å¿†è¦ç‚¹ï¼šç»“åˆmemory_tipsã€key_keywordsã€common_mistakes
- ç›¸å…³æ¦‚å¿µï¼šæ ¹æ®relationshipså»ºç«‹åŒé“¾

**è¾“å‡ºæ ¼å¼**ï¼š
```
=== NOTE_SEPARATOR ===
YAML:
---
[YAMLå…ƒæ•°æ®]
---
CONTENT:
# ã€{subject}ã€‘{{concept_name}}

## æ ¸å¿ƒå®šä¹‰

â° [æ—¶é—´æˆ³]
[åŸºäºteacher_originalå’Œå­—å¹•ç‰‡æ®µçš„å®šä¹‰]

[æ™ºèƒ½é€‰æ‹©çš„å…¶ä»–ç« èŠ‚]

## è®°å¿†è¦ç‚¹

ğŸ”® [å…³é”®è®°å¿†ç‚¹] â€” [ç®€æ´è§£é‡Š]
ğŸ“± [åº”ç”¨åœºæ™¯] â€” [å…¸å‹æƒ…å†µ]  
ğŸ’¡ [é‡è¦æé†’] â€” [æ˜“é”™æç¤º]

## ç›¸å…³æ¦‚å¿µ

[åŸºäºrelationshipsçš„åŒé“¾åˆ—è¡¨]

---
*è§†é¢‘æ—¶é—´æ®µï¼š{time_range}*

=== NOTE_SEPARATOR ===
```

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ï¼Œä¸ºæä¾›çš„æ¯ä¸ªçŸ¥è¯†ç‚¹ç”Ÿæˆå¯¹åº”çš„å®Œæ•´ç¬”è®°ã€‚ç›´æ¥è¾“å‡ºç¬”è®°å†…å®¹ï¼Œä¸éœ€è¦é¢å¤–è¯´æ˜ã€‚
"""
    
    # ç¬¬ä¸€æ­¥æç¤ºè¯æ¨¡æ¿
    STEP1_PROMPT_TEMPLATE = """\
ä½ æ˜¯ä¸“ä¸šçš„æ³•è€ƒè¯¾ç¨‹åˆ†æä¸“å®¶ã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹å­—å¹•å†…å®¹ï¼Œè¯†åˆ«æ‰€æœ‰çŸ¥è¯†ç‚¹å¹¶æ„å»ºè¯¦ç»†çš„å­¦ä¹ æ¶æ„ã€‚

å­—å¹•å†…å®¹ï¼š
{subtitle_content}

è¯¾ç¨‹ä¿¡æ¯ï¼š
- ç§‘ç›®ï¼š{subject}
- æ¥æºï¼š{source}
- è¯¾ç¨‹é“¾æ¥ï¼š{course_url}

## åˆ†æç›®æ ‡

ä½ éœ€è¦ä¸ºåç»­çš„ç¬”è®°æ•´ç†AIæä¾›å®Œæ•´çš„æŒ‡å¯¼ï¼Œç¡®ä¿ï¼š
1. **æ— é—æ¼**ï¼šè¯†åˆ«æ¯ä¸ªç‹¬ç«‹çš„æ³•å¾‹æ¦‚å¿µ
2. **ä¿ç»†èŠ‚**ï¼šä¿ç•™è€å¸ˆçš„é‡è¦è¡¨è¿°ã€å¼ºè°ƒã€ä¸¾ä¾‹
3. **å»ºå…³è”**ï¼šæ˜ç¡®æ¦‚å¿µé—´çš„é€»è¾‘å…³ç³»
4. **ä¼ é£æ ¼**ï¼šå‡†ç¡®ä¼ è¾¾è€å¸ˆçš„æ•™å­¦ç‰¹ç‚¹

## çŸ¥è¯†ç‚¹è¯†åˆ«åŸåˆ™

**è¶…ç»†åŒ–æ‹†åˆ†æ ‡å‡†**ï¼š
- æ¯ä¸ªæœ‰ç‹¬ç«‹åç§°çš„æ³•å¾‹æ¦‚å¿µéƒ½è¦å•ç‹¬è¯†åˆ«
- æ¯ä¸ªå¯èƒ½åœ¨è€ƒè¯•ä¸­å•ç‹¬è€ƒæŸ¥çš„çŸ¥è¯†ç‚¹éƒ½è¦æ‹†åˆ†
- æ¯ä¸ªåœ¨å®åŠ¡ä¸­æœ‰ç‹¬ç«‹åº”ç”¨çš„æ¦‚å¿µéƒ½è¦ç‹¬ç«‹å¤„ç†
- å®å¯æ‹†åˆ†è¿‡ç»†ï¼Œä¸è¦åˆå¹¶ç‹¬ç«‹æ¦‚å¿µ

**ç‰¹åˆ«å…³æ³¨**ï¼š
- æ³•å¾‹æ¡æ–‡ä¸­çš„å…·ä½“è§„å®š
- æ„æˆè¦ä»¶çš„æ¯ä¸ªè¦ç´ 
- ä¸åŒæƒ…å½¢ä¸‹çš„å¤„ç†åŸåˆ™
- ä¾‹å¤–è§„å®šå’Œç‰¹æ®Šæƒ…å†µ
- è€å¸ˆç‰¹åˆ«å¼ºè°ƒçš„è¦ç‚¹

## è¾“å‡ºè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

{{
  "course_overview": {{
    "main_topic": "ä¸»è¦è¯é¢˜",
    "total_duration": "æ€»æ—¶é•¿",
    "teaching_style": "è€å¸ˆæ•™å­¦é£æ ¼æè¿°ï¼ˆä¸¾ä¾‹å¤š/ç†è®ºå¼º/å®åŠ¡å¯¼å‘ç­‰ï¼‰",
    "key_emphasis": ["è€å¸ˆåå¤å¼ºè°ƒçš„è¦ç‚¹1", "è¦ç‚¹2"],
    "difficulty_level": "éš¾åº¦ç­‰çº§"
  }},
  
  "knowledge_points": [
    {{
      "id": "KP001",
      "concept_name": "æ¦‚å¿µåç§°",
      "concept_type": "å®šä¹‰æ€§æ¦‚å¿µ/ç¨‹åºæ€§çŸ¥è¯†/åˆ¤æ–­æ ‡å‡†/æ„æˆè¦ä»¶/æ³•æ¡è§„å®š/å®åŠ¡ç»éªŒ",
      "time_range": "MM:SS.mm-MM:SS.mm",
      "importance_level": "é«˜/ä¸­/ä½",
      
      "core_definition": {{
        "teacher_original": "è€å¸ˆçš„åŸå§‹è¡¨è¿°ï¼ˆå°½å¯èƒ½ä¿æŒåŸè¯ï¼‰",
        "key_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
        "context": "å®šä¹‰çš„ä¸Šä¸‹æ–‡èƒŒæ™¯"
      }},
      
      "detailed_content": {{
        "main_explanation": "ä¸»è¦è§£é‡Šå†…å®¹",
        "examples": [
          {{
            "example_content": "å…·ä½“ä¾‹å­å†…å®¹", 
            "teacher_comment": "è€å¸ˆå¯¹ä¾‹å­çš„ç‚¹è¯„æˆ–å¼ºè°ƒ"
          }}
        ],
        "special_notes": ["ç‰¹åˆ«æ³¨æ„äº‹é¡¹1", "æ³¨æ„äº‹é¡¹2"],
        "common_mistakes": ["æ˜“é”™ç‚¹1", "æ˜“é”™ç‚¹2"],
        "memory_tips": "è®°å¿†æŠ€å·§æˆ–å£è¯€"
      }},
      
      "exam_relevance": {{
        "exam_frequency": "å¸¸è€ƒ/å¶è€ƒ/åŸºç¡€",
        "question_types": ["é€‰æ‹©é¢˜", "æ¡ˆä¾‹é¢˜", "è®ºè¿°é¢˜"],
        "key_test_points": ["è€ƒç‚¹1", "è€ƒç‚¹2"]
      }},
      
      "relationships": {{
        "parent_concept": "ä¸Šä½æ¦‚å¿µID",
        "sub_concepts": ["å­æ¦‚å¿µID1", "å­æ¦‚å¿µID2"],
        "related_concepts": ["ç›¸å…³æ¦‚å¿µID1", "ç›¸å…³æ¦‚å¿µID2"],
        "contrast_concepts": ["å¯¹æ¯”æ¦‚å¿µID1", "å¯¹æ¯”æ¦‚å¿µID2"]
      }}
    }}
  ],
  
  "concept_structure": {{
    "hierarchy": "æ¦‚å¿µå±‚æ¬¡ç»“æ„çš„æ–‡å­—æè¿°",
    "main_logic_flow": "ä¸»è¦é€»è¾‘è„‰ç»œ",
    "cross_references": [
      {{
        "concept1": "æ¦‚å¿µID1",
        "concept2": "æ¦‚å¿µID2", 
        "relationship": "å…³ç³»ç±»å‹ï¼ˆåŒ…å«/å¯¹æ¯”/ä¾èµ–/å¹¶åˆ—ç­‰ï¼‰"
      }}
    ]
  }},
  
  "teaching_insights": {{
    "teacher_preferences": "è€å¸ˆçš„æ•™å­¦åå¥½ï¼ˆçˆ±ä¸¾ä¾‹/é‡ç†è®º/å¼ºè°ƒå®åŠ¡ç­‰ï¼‰",
    "emphasis_pattern": "å¼ºè°ƒæ¨¡å¼ï¼ˆé‡å¤è¯´æ˜/å¯¹æ¯”åˆ†æ/æ¡ˆä¾‹è§£é‡Šç­‰ï¼‰",
    "student_attention": ["éœ€è¦ç‰¹åˆ«æ³¨æ„çš„å­¦ä¹ è¦ç‚¹"],
    "practical_tips": ["å®åŠ¡å»ºè®®æˆ–ç»éªŒåˆ†äº«"]
  }}
}}

## ç‰¹åˆ«è¦æ±‚

1. **ä¿æŒåŸæ±åŸå‘³**ï¼šå°½å¯èƒ½ä¿ç•™è€å¸ˆçš„åŸå§‹è¡¨è¿°ï¼Œç‰¹åˆ«æ˜¯å®šä¹‰ã€å¼ºè°ƒã€ä¸¾ä¾‹
2. **æ—¶é—´æˆ³ç²¾ç¡®**ï¼šæ¯ä¸ªçŸ¥è¯†ç‚¹éƒ½è¦æœ‰å‡†ç¡®çš„æ—¶é—´èŒƒå›´ï¼Œæ ¼å¼ä¸º[MM:SS.mm-MM:SS.mm]
3. **å…³ç³»æ¸…æ™°**ï¼šæ¦‚å¿µé—´çš„å…³ç³»è¦å‡†ç¡®ï¼Œé¿å…å¾ªç¯å¼•ç”¨
4. **ç»†èŠ‚ä¸°å¯Œ**ï¼šä¸ºåç»­ç¬”è®°æ•´ç†æä¾›å……åˆ†çš„ä¿¡æ¯åŸºç¡€
5. **IDå‘½å**ï¼šçŸ¥è¯†ç‚¹IDä½¿ç”¨KP001ã€KP002æ ¼å¼ï¼Œä¾¿äºå¼•ç”¨

è¯·å¼€å§‹åˆ†æï¼Œè¾“å‡ºå®Œæ•´çš„JSONç»“æ„ã€‚"""

    # ç¬¬äºŒæ­¥æç¤ºè¯æ¨¡æ¿
    STEP2_PROMPT_TEMPLATE = """\
ä½ æ˜¯ä¸“ä¸šçš„æ³•è€ƒç¬”è®°æ•´ç†ä¸“å®¶ã€‚è¯·æ ¹æ®å‰ä¸€æ­¥çš„åˆ†æç»“æœå’ŒåŸå§‹å­—å¹•å†…å®¹ï¼Œç”Ÿæˆå®Œæ•´çš„Obsidianç¬”è®°ã€‚

## è¾“å…¥å†…å®¹

**çŸ¥è¯†ç‚¹åˆ†æç»“æœ**ï¼š
{analysis_result}

**åŸå§‹å­—å¹•å†…å®¹**ï¼š
{subtitle_content}

**è¯¾ç¨‹ä¿¡æ¯**ï¼š
- ç§‘ç›®ï¼š{subject}
- æ¥æºï¼š{source}
- è¯¾ç¨‹é“¾æ¥ï¼š{course_url}

## æ•´ç†ç›®æ ‡

åŸºäºçŸ¥è¯†ç‚¹åˆ†æï¼Œä¸ºæ¯ä¸ªè¯†åˆ«å‡ºçš„æ¦‚å¿µåˆ›å»ºå®Œæ•´çš„Obsidianç¬”è®°ï¼Œå®ç°ï¼š
1. **çŸ¥è¯†å›¾è°±èŠ‚ç‚¹**ï¼šæ¯ä¸ªç¬”è®°æ˜¯å›¾è°±ä¸­çš„æ¸…æ™°èŠ‚ç‚¹
2. **Wikiç™¾ç§‘æ¡ç›®**ï¼šç‹¬ç«‹å®Œæ•´ï¼Œå¯å•ç‹¬é˜…è¯»ç†è§£
3. **é”™é¢˜å®šä½ç´¢å¼•**ï¼šç²¾å‡†åŒ¹é…è€ƒè¯•çŸ¥è¯†ç‚¹

## æ ¸å¿ƒåŸåˆ™

**å®Œå…¨ä¾æ®åˆ†æç»“æœ**ï¼šä¸¥æ ¼æŒ‰ç…§ç¬¬ä¸€æ­¥è¯†åˆ«çš„çŸ¥è¯†ç‚¹åˆ—è¡¨ç”Ÿæˆç¬”è®°ï¼Œä¸é—æ¼ã€ä¸æ–°å¢

**ä¿æŒæ•™å­¦åŸå‘³**ï¼šå……åˆ†åˆ©ç”¨åˆ†æç»“æœä¸­çš„teacher_originalã€examplesã€teacher_commentç­‰ä¿¡æ¯

**ç»“æ„æ™ºèƒ½è®¾è®¡**ï¼šæ ¹æ®æ¯ä¸ªæ¦‚å¿µçš„ç‰¹ç‚¹ï¼ˆconcept_typeï¼‰å’Œè¯¦ç»†å†…å®¹è®¾è®¡æœ€é€‚åˆçš„ç« èŠ‚ç»“æ„

**åŒé“¾ç²¾ç¡®å»ºç«‹**ï¼šä½¿ç”¨åˆ†æç»“æœä¸­çš„relationshipsä¿¡æ¯å»ºç«‹å‡†ç¡®çš„æ¦‚å¿µå…³è”

## ç¬”è®°ç”Ÿæˆè§„åˆ™

**å¿…éœ€ç« èŠ‚**ï¼šæ¯ä¸ªç¬”è®°å¿…é¡»åŒ…å«
- æ ¸å¿ƒå®šä¹‰
- è®°å¿†è¦ç‚¹  
- ç›¸å…³æ¦‚å¿µ

**è‡ªç”±ç« èŠ‚**ï¼šæ ¹æ®æ¦‚å¿µç‰¹ç‚¹æ™ºèƒ½åˆ›é€ 
- æ„æˆè¦ä»¶ç±»ï¼šè¯¦ç»†åˆ—ä¸¾å„ä¸ªè¦ä»¶
- ç¨‹åºæ€§çŸ¥è¯†ï¼šæ­¥éª¤æˆ–æµç¨‹è¯´æ˜
- åˆ¤æ–­æ ‡å‡†ç±»ï¼šåˆ¤æ–­æ–¹æ³•å’Œæ ‡å‡†
- å®åŠ¡ç»éªŒç±»ï¼šå®é™…åº”ç”¨å’Œæ³¨æ„äº‹é¡¹
- æ³•æ¡è§„å®šç±»ï¼šæ¡æ–‡å†…å®¹å’Œé€‚ç”¨æƒ…å†µ

**ç« èŠ‚è®¾è®¡æŒ‡å¯¼**ï¼š
```
concept_type = "æ„æˆè¦ä»¶" â†’ å¯è®¾è®¡"æ„æˆè¦ä»¶è¯¦è§£"ç« èŠ‚
concept_type = "ç¨‹åºæ€§çŸ¥è¯†" â†’ å¯è®¾è®¡"æ“ä½œæµç¨‹"ç« èŠ‚  
concept_type = "åˆ¤æ–­æ ‡å‡†" â†’ å¯è®¾è®¡"åˆ¤æ–­æ–¹æ³•"ç« èŠ‚
concept_type = "å®åŠ¡ç»éªŒ" â†’ å¯è®¾è®¡"å®åŠ¡åº”ç”¨"ç« èŠ‚
concept_type = "æ³•æ¡è§„å®š" â†’ å¯è®¾è®¡"æ¡æ–‡è§£è¯»"ç« èŠ‚
```

## å†…å®¹å¡«å……ç­–ç•¥

**æ ¸å¿ƒå®šä¹‰**ï¼šä¼˜å…ˆä½¿ç”¨teacher_originalï¼Œè¡¥å……contextä¿¡æ¯

**è¯¦ç»†å†…å®¹**ï¼šå……åˆ†åˆ©ç”¨main_explanationã€examplesã€special_notes

**è®°å¿†è¦ç‚¹**ï¼šç»“åˆmemory_tipsã€key_keywordsã€common_mistakes

**ç›¸å…³æ¦‚å¿µ**ï¼šä¸¥æ ¼æŒ‰ç…§relationshipsä¸­çš„ä¿¡æ¯å»ºç«‹åŒé“¾

**æ¡ˆä¾‹ä¸¾ä¾‹**ï¼šè¯¦ç»†å±•å¼€examplesä¸­çš„å†…å®¹ï¼Œä¿ç•™teacher_comment

## æŠ€æœ¯è§„èŒƒ

**YAMLå…ƒæ•°æ®**ï¼š
```yaml
title: "ã€{subject}ã€‘{{concept_name}}"
aliases: ["{{concept_name}}", "å…¶ä»–åˆ«å"]
tags: ["{subject}", "æ ¹æ®concept_typeç¡®å®š", "æ ¹æ®importance_levelç¡®å®š"]
source: "{source}"
course_url: "{course_url}"
time_range: "{{time_range}}"
subject: "{subject}"
exam_importance: "{{importance_level}}"
concept_id: "{{id}}"
created: "å½“å‰æ—¶é—´"
```

**åŒé“¾æ ¼å¼**ï¼š
- å¼•ç”¨æ ¼å¼ï¼š[[ã€{subject}ã€‘æ¦‚å¿µå|æ¦‚å¿µå]]
- æ ¹æ®relationshipsç²¾ç¡®å»ºç«‹å…³è”

**æ—¶é—´æˆ³æ ¼å¼**ï¼š
- ä¸¥æ ¼ä½¿ç”¨[MM:SS.mm]æ ¼å¼
- ä»time_rangeä¸­æå–

## è¾“å‡ºæ ¼å¼

æ¯ä¸ªç¬”è®°ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

```
=== NOTE_SEPARATOR ===
YAML:
---
[YAMLå…ƒæ•°æ®]
---
CONTENT:
# ã€{subject}ã€‘{{concept_name}}

## æ ¸å¿ƒå®šä¹‰

â° [{{time_range}}]
[åŸºäºteacher_originalå’Œcore_definitionçš„å†…å®¹]

## [æ™ºèƒ½åˆ›é€ çš„ç« èŠ‚æ ‡é¢˜]
[åŸºäºdetailed_contentå’Œconcept_typeçš„å…·ä½“å†…å®¹]

## è®°å¿†è¦ç‚¹

ğŸ”® [åŸºäºmemory_tipsçš„å…³é”®ç‚¹] â€” [ç®€æ´è§£é‡Š]
ğŸ“± [åŸºäºexamplesçš„åº”ç”¨åœºæ™¯] â€” [å…¸å‹æƒ…å†µ]
ğŸ’¡ [åŸºäºcommon_mistakesçš„æé†’] â€” [æ˜“é”™æç¤º]

## ç›¸å…³æ¦‚å¿µ

[åŸºäºrelationshipsç²¾ç¡®å»ºç«‹çš„åŒé“¾åˆ—è¡¨]

---
*è§†é¢‘æ—¶é—´æ®µï¼š{{time_range}}*

=== NOTE_SEPARATOR ===
```

## è´¨é‡è¦æ±‚

1. **ä¸€ä¸€å¯¹åº”**ï¼šanalysis_resultä¸­æ¯ä¸ªknowledge_pointéƒ½è¦ç”Ÿæˆå¯¹åº”ç¬”è®°
2. **ä¿¡æ¯å®Œæ•´**ï¼šå……åˆ†åˆ©ç”¨åˆ†æç»“æœä¸­çš„æ‰€æœ‰æœ‰ç”¨ä¿¡æ¯
3. **é€»è¾‘æ¸…æ™°**ï¼šæ¦‚å¿µé—´å…³ç³»å‡†ç¡®ï¼ŒåŒé“¾æœ‰æ„ä¹‰
4. **ç»†èŠ‚ä¸°å¯Œ**ï¼šæ¡ˆä¾‹è¯¦ç»†ï¼Œè¯´æ˜å……åˆ†
5. **æ ¼å¼æ ‡å‡†**ï¼šä¸¥æ ¼éµå¾ªæŠ€æœ¯è§„èŒƒ

è¯·å¼€å§‹æ ¹æ®åˆ†æç»“æœç”Ÿæˆå®Œæ•´çš„Obsidianç¬”è®°ï¼ŒæŒ‰åºå·é¡ºåºå¤„ç†æ¯ä¸ªçŸ¥è¯†ç‚¹ï¼Œä¸é—æ¼ä»»ä½•æ¦‚å¿µã€‚ä¸¥æ ¼æŒ‰ç…§æ ¼å¼è¾“å‡ºï¼Œä¸éœ€è¦é¢å¤–è¯´æ˜ã€‚"""


    # æ–°å¢ï¼šå•ä¸ªçŸ¥è¯†ç‚¹å¤„ç†çš„æç¤ºè¯æ¨¡æ¿ï¼ˆä¸ä½¿ç”¨åˆ†éš”ç¬¦ï¼‰
    SINGLE_KNOWLEDGE_POINT_PROMPT_TEMPLATE = """\
ä½ æ˜¯ä¸“ä¸šçš„æ³•è€ƒç¬”è®°æ•´ç†ä¸“å®¶ã€‚è¯·æ ¹æ®å­—å¹•ç‰‡æ®µå’ŒçŸ¥è¯†ç‚¹åˆ†æï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„Obsidianç¬”è®°ã€‚

## è¾“å…¥å†…å®¹

**å­—å¹•ç‰‡æ®µ**ï¼ˆæ—¶é—´èŒƒå›´: {time_range}ï¼‰ï¼š
{segment_text}

**ç›®æ ‡çŸ¥è¯†ç‚¹**ï¼š
{knowledge_point}

**è¯¾ç¨‹æ¦‚è§ˆ**ï¼š
{course_overview}

**æ•™å­¦é£æ ¼æ´å¯Ÿ**ï¼š
{teaching_insights}

**è¯¾ç¨‹ä¿¡æ¯**ï¼š
- ç§‘ç›®ï¼š{subject}
- æ¥æºï¼š{source}
- è¯¾ç¨‹é“¾æ¥ï¼š{course_url}

## å¤„ç†è¦æ±‚

**ç²¾ç¡®å¯¹åº”**ï¼šä¸¥æ ¼åŸºäºæä¾›çš„å•ä¸ªçŸ¥è¯†ç‚¹ï¼Œç”Ÿæˆå¯¹åº”çš„å®Œæ•´ç¬”è®°

**å……åˆ†åˆ©ç”¨ç‰‡æ®µå†…å®¹**ï¼šæ·±åº¦æŒ–æ˜å­—å¹•ç‰‡æ®µä¸­çš„ä¿¡æ¯ï¼Œä¿ç•™è€å¸ˆçš„åŸå§‹è¡¨è¿°å’Œé‡è¦ç»†èŠ‚

**æ—¶é—´æˆ³å¤„ç†**ï¼šä½¿ç”¨time_rangeä¿¡æ¯æ·»åŠ å‡†ç¡®çš„æ—¶é—´æˆ³æ ‡è®°

**æ¦‚å¿µå…³è”**ï¼šåŸºäºrelationshipsä¿¡æ¯å»ºç«‹å‡†ç¡®çš„åŒé“¾å…³ç³»

## è¾“å‡ºæ ¼å¼

è¯·ç›´æ¥è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„markdownç¬”è®°ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

---
title: "ã€{subject}ã€‘{{concept_name}}"
aliases: ["{{concept_name}}"]
tags: ["{subject}", "{{concept_type}}", "{{importance_level}}"]
source: "{source}"
course_url: "{course_url}"
time_range: "{{time_range}}"
subject: "{subject}"
exam_importance: "{{importance_level}}"
concept_id: "{{id}}"
created: "{{å½“å‰æ—¶é—´}}"
---
# ã€{subject}ã€‘{{concept_name}}

## æ ¸å¿ƒå®šä¹‰

â° [æ—¶é—´æˆ³]
[åŸºäºteacher_originalå’Œå­—å¹•ç‰‡æ®µçš„å®šä¹‰]

[æ™ºèƒ½é€‰æ‹©çš„å…¶ä»–ç« èŠ‚]

## è®°å¿†è¦ç‚¹

ğŸ”® [å…³é”®è®°å¿†ç‚¹] â€” [ç®€æ´è§£é‡Š]
ğŸ“± [åº”ç”¨åœºæ™¯] â€” [å…¸å‹æƒ…å†µ]  
ğŸ’¡ [é‡è¦æé†’] â€” [æ˜“é”™æç¤º]

## ç›¸å…³æ¦‚å¿µ

[åŸºäºrelationshipsçš„åŒé“¾åˆ—è¡¨]

---
*è§†é¢‘æ—¶é—´æ®µï¼š{time_range}*

æ³¨æ„ï¼š
1. ç¡®ä¿åªæœ‰å¼€å¤´å’Œç»“å°¾å„ä¸€ä¸ª"---"åˆ†éš”ç¬¦
2. YAMLéƒ¨åˆ†ä¸è¦åŒ…å«é¢å¤–çš„åˆ†éš”ç¬¦
3. ç›´æ¥è¾“å‡ºmarkdownæ ¼å¼ï¼Œä¸è¦ç”¨ä»£ç å—åŒ…è£…

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ï¼Œä¸ºæä¾›çš„çŸ¥è¯†ç‚¹ç”Ÿæˆå¯¹åº”çš„å®Œæ•´ç¬”è®°ã€‚ç›´æ¥è¾“å‡ºç¬”è®°å†…å®¹ï¼Œä¸éœ€è¦é¢å¤–è¯´æ˜ã€‚ä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ï¼Œç›´æ¥è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„markdownç¬”è®°ã€‚
"""

    def _build_single_knowledge_point_prompt(self, segment: Segment, knowledge_point: Dict, 
                                       analysis_result: Dict, metadata: Dict[str, str]) -> str:
        """æ„å»ºå•ä¸ªçŸ¥è¯†ç‚¹çš„å¤„ç†æç¤ºè¯ï¼ˆä¸ä½¿ç”¨åˆ†éš”ç¬¦ï¼‰"""
        # æå–è¯¾ç¨‹æ¦‚è§ˆå’Œæ•™å­¦æ´å¯Ÿ
        course_overview = analysis_result.get('course_overview', {})
        teaching_insights = analysis_result.get('teaching_insights', {})
        
        return self.SINGLE_KNOWLEDGE_POINT_PROMPT_TEMPLATE.format(
            segment_text=segment.text,
            time_range=f"{segment.time_range.start:.1f}-{segment.time_range.end:.1f}s",
            knowledge_point=json.dumps(knowledge_point, ensure_ascii=False, indent=2),
            course_overview=json.dumps(course_overview, ensure_ascii=False),
            teaching_insights=json.dumps(teaching_insights, ensure_ascii=False),
            subject=metadata['subject'],
            source=metadata['source'],
            course_url=metadata.get('course_url', '')
        )

    def _parse_single_note_response(self, response_content: str, knowledge_point: Dict, metadata: Dict[str, str]) -> Optional[Dict[str, Any]]:
        """è§£æå•ä¸ªç¬”è®°çš„AIå“åº” - æ­£ç¡®å¤„ç†å¤šä¸ª---çš„ç‰ˆæœ¬"""
        try:
            response_content = response_content.strip()
            
            # æ£€æŸ¥æ˜¯å¦ä»¥---å¼€å¤´ï¼ˆæ ‡å‡†markdown frontmatteræ ¼å¼ï¼‰
            if response_content.startswith('---'):
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ª---çš„ç»“æŸä½ç½®
                first_separator_end = response_content.find('\n', 3)  # è·³è¿‡å¼€å¤´çš„---
                if first_separator_end == -1:
                    print("âš ï¸ æ ¼å¼é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¬¬ä¸€ä¸ª---åçš„æ¢è¡Œ")
                    return None
                
                # ä»ç¬¬ä¸€ä¸ª---åå¼€å§‹æŸ¥æ‰¾ç¬¬äºŒä¸ª---
                second_separator_start = response_content.find('\n---', first_separator_end)
                if second_separator_start == -1:
                    print("âš ï¸ æ ¼å¼é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¬¬äºŒä¸ª---")
                    return None
                
                # æå–YAMLå†…å®¹ï¼ˆåœ¨ä¸¤ä¸ª---ä¹‹é—´ï¼‰
                yaml_content = response_content[first_separator_end + 1:second_separator_start].strip()
                
                # æ‰¾åˆ°ç¬¬äºŒä¸ª---è¡Œçš„ç»“æŸä½ç½®
                second_separator_end = response_content.find('\n', second_separator_start + 4)
                if second_separator_end == -1:
                    second_separator_end = second_separator_start + 4
                
                # æå–markdownå†…å®¹ï¼ˆç¬¬äºŒä¸ª---ä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼‰
                markdown_content = response_content[second_separator_end + 1:].strip()
                
            else:
                print("âš ï¸ ä¸æ˜¯æ ‡å‡†frontmatteræ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†")
                yaml_content = ""
                markdown_content = response_content
            
            # è§£æYAMLæ•°æ®
            yaml_data = {}
            if yaml_content:
                try:
                    yaml_data = yaml.safe_load(yaml_content)
                    if yaml_data is None:
                        yaml_data = {}
                    print(f"âœ… YAMLè§£ææˆåŠŸï¼ŒåŒ…å« {len(yaml_data)} ä¸ªå­—æ®µ")
                except yaml.YAMLError as e:
                    print(f"âš ï¸ YAMLè§£æå¤±è´¥: {e}")
                    print(f"YAMLå†…å®¹å‰200å­—ç¬¦: {yaml_content[:200]}")
                    yaml_data = {}
            
            # å¦‚æœYAMLè§£æå¤±è´¥æˆ–ä¸ºç©ºï¼Œç”Ÿæˆé»˜è®¤çš„å…ƒæ•°æ®
            if not yaml_data:
                yaml_data = {
                    'title': f"ã€{metadata['subject']}ã€‘{knowledge_point.get('concept_name', 'æœªå‘½åæ¦‚å¿µ')}",
                    'aliases': [knowledge_point.get('concept_name', 'æœªå‘½åæ¦‚å¿µ')],
                    'tags': [metadata['subject'], knowledge_point.get('concept_type', 'å®šä¹‰æ€§æ¦‚å¿µ')],
                    'source': metadata['source'],
                    'subject': metadata['subject'],
                    'concept_id': knowledge_point.get('id', ''),
                    'created': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                if metadata.get('course_url'):
                    yaml_data['course_url'] = metadata['course_url']
                if knowledge_point.get('time_range'):
                    yaml_data['time_range'] = knowledge_point['time_range']
                if knowledge_point.get('importance_level'):
                    yaml_data['exam_importance'] = knowledge_point['importance_level']
                
                print(f"âœ… ä½¿ç”¨é»˜è®¤YAMLæ•°æ®ï¼š{yaml_data.get('title', 'æœªå‘½å')}")
            
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            if 'title' not in yaml_data:
                yaml_data['title'] = f"ã€{metadata['subject']}ã€‘{knowledge_point.get('concept_name', 'æœªå‘½åæ¦‚å¿µ')}"
            
            # è¿”å›æ ‡å‡†æ•°æ®ç»“æ„ï¼ˆä¸åŸæ¥ä¿æŒä¸€è‡´ï¼‰
            note = {
                'yaml': yaml_data,           # ä½¿ç”¨ 'yaml' é”®å
                'content': markdown_content  # ä½¿ç”¨ 'content' é”®å
            }
            
            print(f"âœ… ç¬”è®°è§£ææˆåŠŸ: {yaml_data.get('title', 'æœªå‘½å')}")
            return note
            
        except Exception as e:
            print(f"âŒ è§£æå•ä¸ªç¬”è®°å¤±è´¥: {e}")
            print(f"å“åº”å†…å®¹é•¿åº¦: {len(response_content)}")
            print(f"å“åº”å†…å®¹å‰500å­—ç¬¦: {response_content[:500]}")
            return None
    
    def enhance_concept_relationships(self, all_notes: List[Dict], existing_concepts: Dict) -> List[Dict]:
        """è®©AIåˆ†ææ‰€æœ‰ç¬”è®°å†…å®¹ï¼Œå¢å¼ºæ¦‚å¿µå…³ç³»"""
        if not all_notes:
            return all_notes
            
        prompt = self._build_enhancement_prompt(all_notes, existing_concepts)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
            )
            
            enhanced_notes = self._parse_enhancement_response(response.choices[0].message.content, all_notes)
            return enhanced_notes
        except Exception as e:
            print(f"âš ï¸ æ¦‚å¿µå…³ç³»å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {e}")
            return all_notes
    
    def enhance_single_note_concepts(self, note_content: str, note_title: str, existing_concepts: Dict) -> Optional[Dict]:
        """å¢å¼ºå•ä¸ªç¬”è®°çš„æ¦‚å¿µå…³ç³» - åˆ†ç¦»YAMLå¤„ç†ç‰ˆæœ¬"""
        
        # 1. åˆ†ç¦»YAMLå’Œæ­£æ–‡å†…å®¹
        yaml_data, content_only, has_yaml = self._separate_markdown_content(note_content)
        
        # 2. æ„å»ºæç¤ºè¯ï¼ˆåªä¼ å…¥æ­£æ–‡å†…å®¹ï¼‰
        prompt = self._build_single_note_enhancement_prompt(content_only, note_title, existing_concepts)
        
        try:
            # 3. è°ƒç”¨AIå¤„ç†
            if self.model == "gemini-2.5-flash":
                response = self.client.chat.completions.create(
                    reasoning_effort="medium",
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                )
            else:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                )
            
            # 4. è§£æAIå“åº”
            enhancement_result = self._parse_single_note_enhancement_response(
                response.choices[0].message.content, content_only
            )
            
            if not enhancement_result or not enhancement_result.get('modified', False):
                return {'modified': False}
            
            # 5. é‡æ–°ç»„åˆå®Œæ•´å†…å®¹ï¼ˆYAML + å¤„ç†åçš„æ­£æ–‡ï¼‰
            enhanced_content_only = enhancement_result['enhanced_content']
            complete_enhanced_content = self._combine_markdown_content(
                yaml_data, enhanced_content_only, has_yaml
            )
            
            return {
                'modified': True,
                'enhanced_content': complete_enhanced_content
            }
            
        except Exception as e:
            print(f"âš ï¸ æ¦‚å¿µå…³ç³»å¢å¼ºå¤±è´¥: {e}")
            return {'modified': False}
    
    def _build_extraction_prompt(self, subtitle_content: str, metadata: Dict[str, str]) -> str:
        """æ„å»ºæå–çŸ¥è¯†ç‚¹çš„æç¤ºè¯"""
        return f"""ä½ æ˜¯ä¸“ä¸šçš„æ³•è€ƒç¬”è®°æ•´ç†ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å­—å¹•å†…å®¹ï¼Œæå–æ‰€æœ‰ç‹¬ç«‹çš„çŸ¥è¯†ç‚¹ï¼Œä¸ºæ¯ä¸ªçŸ¥è¯†ç‚¹ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„Obsidianç¬”è®°ã€‚

å­—å¹•å†…å®¹ï¼š
{subtitle_content}

è¯¾ç¨‹ä¿¡æ¯ï¼š
- ç§‘ç›®ï¼š{metadata['subject']}
- æ¥æºï¼š{metadata['source']}
- è¯¾ç¨‹é“¾æ¥ï¼š{metadata.get('course_url', 'æœªæä¾›')}

## é¡¹ç›®ç›®æ ‡å’Œæ„ä¹‰

æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªå®Œæ•´çš„æ³•è€ƒçŸ¥è¯†ä½“ç³»ï¼Œå…·æœ‰ä¸‰ä¸ªæ ¸å¿ƒç›®æ ‡ï¼š

**ç›®æ ‡ä¸€ï¼šæ„å»ºObsidiançŸ¥è¯†å›¾è°±**
é€šè¿‡åŒé“¾ç¬”è®°ç³»ç»Ÿï¼Œå°†æ³•è€ƒæ‰€æœ‰çŸ¥è¯†ç‚¹è¿æ¥æˆä¸€ä¸ªå¯è§†åŒ–çš„çŸ¥è¯†ç½‘ç»œã€‚æ¯ä¸ªæ¦‚å¿µéƒ½æ˜¯å›¾è°±ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç›¸å…³æ¦‚å¿µé€šè¿‡åŒé“¾å½¢æˆçŸ¥è¯†è„‰ç»œï¼Œå¸®åŠ©ç†è§£æ¦‚å¿µé—´çš„é€»è¾‘å…³ç³»ã€‚

**ç›®æ ‡äºŒï¼šå»ºç«‹æ³•è€ƒWikiç™¾ç§‘**
åˆ›å»ºç±»ä¼¼ç»´åŸºç™¾ç§‘çš„æ³•è€ƒçŸ¥è¯†ä½“ç³»ï¼Œæ¯ä¸ªæ³•å¾‹æ¦‚å¿µéƒ½æœ‰ç‹¬ç«‹è¯¦ç»†çš„æ¡ç›®ã€‚å­¦ä¹ è€…å¯ä»¥ä»ä»»ä½•ä¸€ä¸ªæ¦‚å¿µå‡ºå‘ï¼Œé€šè¿‡åŒé“¾è·³è½¬åˆ°ç›¸å…³æ¦‚å¿µï¼Œå®ç°çŸ¥è¯†çš„æ·±åº¦æ¢ç´¢å’Œå…³è”å­¦ä¹ ã€‚

**ç›®æ ‡ä¸‰ï¼šé”™é¢˜å¿«é€Ÿå®šä½ç³»ç»Ÿ**
å½“æ•´ç†é”™é¢˜æ—¶ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®šä½åˆ°æ¶‰åŠçš„å…·ä½“çŸ¥è¯†ç‚¹ã€‚è¿™è¦æ±‚æ¯ä¸ªå¯èƒ½åœ¨è€ƒè¯•ä¸­ç‹¬ç«‹å‡ºç°çš„æ¦‚å¿µéƒ½è¦æœ‰å¯¹åº”çš„ç¬”è®°ï¼Œä¾¿äºé”™é¢˜åˆ†ææ—¶ç²¾å‡†å…³è”åˆ°ç›¸å…³çŸ¥è¯†ç‚¹ã€‚

## æ ¸å¿ƒæŒ‡å¯¼åŸåˆ™

**å†…å®¹å®Œæ•´æ€§**ï¼šä¿ç•™æ‰€æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬è€å¸ˆçš„ä¾‹å­ã€æ¡ˆä¾‹ã€è§£é‡Šã€å¼ºè°ƒã€å®åŠ¡ç»éªŒç­‰ã€‚æ¯ä¸ªç¬”è®°éƒ½è¦åƒä¸€ä¸ªå®Œæ•´çš„ç™¾ç§‘æ¡ç›®ï¼Œå®å¯è¯¦ç»†ä¹Ÿä¸è¦é—æ¼é‡è¦å†…å®¹ã€‚

**ç»†åˆ†ä¼˜å…ˆç­–ç•¥**ï¼šæåŠ›å€¾å‘äºå°†çŸ¥è¯†ç‚¹æ‹†åˆ†å¾—æ›´ç»†è‡´ã€‚æƒ³è±¡ä½ åœ¨ä¸ºä¸€ä¸ªæ³•è€ƒWikiåˆ›å»ºæ¡ç›®ï¼Œæ¯ä¸ªå…·æœ‰ç‹¬ç«‹åç§°ã€å®šä¹‰æˆ–è€ƒæŸ¥ä»·å€¼çš„æ¦‚å¿µéƒ½åº”è¯¥æœ‰ç‹¬ç«‹çš„æ¡ç›®ã€‚è¿™ç§ç»†åˆ†æ˜¯æ„å»ºçŸ¥è¯†å›¾è°±å’Œå®ç°é”™é¢˜ç²¾å‡†å®šä½çš„åŸºç¡€ã€‚

**åŒé“¾è¿æ¥é€»è¾‘**ï¼šå°†æ¯ä¸ªç¬”è®°è§†ä¸ºçŸ¥è¯†å›¾è°±ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œé€šè¿‡åŒé“¾ä¸å…¶ä»–èŠ‚ç‚¹å»ºç«‹è¿æ¥ã€‚ä¸Šä½æ¦‚å¿µé€šè¿‡åŒé“¾è¿æ¥ä¸‹ä½æ¦‚å¿µï¼Œç›¸å…³æ¦‚å¿µç›¸äº’å¼•ç”¨ï¼Œå½¢æˆç«‹ä½“çš„çŸ¥è¯†ç½‘ç»œã€‚

**Wikiå¼å®Œæ•´æ€§**ï¼šæ¯ä¸ªç¬”è®°éƒ½åº”è¯¥èƒ½å¤Ÿç‹¬ç«‹é˜…è¯»å’Œç†è§£ï¼Œå°±åƒç»´åŸºç™¾ç§‘çš„æ¡ç›®ä¸€æ ·ã€‚è¯»è€…ä»ä»»ä½•ä¸€ä¸ªç¬”è®°å¼€å§‹ï¼Œéƒ½èƒ½é€šè¿‡åŒé“¾æ·±å…¥å­¦ä¹ ç›¸å…³çŸ¥è¯†ã€‚

**è€ƒè¯•å¯¼å‘ç²¾ç¡®æ€§**ï¼šè€ƒè™‘æ¯ä¸ªçŸ¥è¯†ç‚¹åœ¨è€ƒè¯•ä¸­çš„ç‹¬ç«‹æ€§ã€‚å¦‚æœæŸä¸ªæ¦‚å¿µå¯èƒ½åœ¨é€‰æ‹©é¢˜ã€æ¡ˆä¾‹é¢˜æˆ–è®ºè¿°é¢˜ä¸­å•ç‹¬å‡ºç°ï¼Œå°±åº”è¯¥æœ‰ç‹¬ç«‹çš„ç¬”è®°ï¼Œä¾¿äºé”™é¢˜æ•´ç†æ—¶ç²¾ç¡®å…³è”ã€‚

**ç»“æ„æ™ºèƒ½æ€§**ï¼šå®Œå…¨æ ¹æ®å®é™…å†…å®¹å†³å®šç¬”è®°ç»“æ„ã€‚ä½ éœ€è¦åˆ†æè€å¸ˆçš„è®²è¯¾é‡ç‚¹å’Œæ–¹å¼ï¼Œç„¶åè®¾è®¡æœ€é€‚åˆçš„ç« èŠ‚ç»“æ„æ¥ç»„ç»‡ä¿¡æ¯ã€‚ä¸è¦è¢«ä»»ä½•é¢„è®¾çš„æ¨¡æ¿é™åˆ¶ã€‚

**ç†è§£å¯¼å‘**ï¼šä»¥å¸®åŠ©å­¦ç”Ÿç†è§£å’ŒæŒæ¡çŸ¥è¯†ä¸ºç›®æ ‡ï¼Œé€‰æ‹©æœ€æœ‰åˆ©äºå­¦ä¹ çš„ä¿¡æ¯ç»„ç»‡æ–¹å¼ï¼ŒæŒ‰ç…§éœ€è¦é€‰æ‹©è¡¨æ ¼ã€mermaidç­‰æ–¹å¼è¾…åŠ©è¡¨è¾¾ï¼Œè¿™ç‚¹ååˆ†é‡è¦ã€‚

## çŸ¥è¯†ç‚¹è¯†åˆ«å’Œæ‹†åˆ†ç­–ç•¥

**è¶…ç»†åŒ–æ‹†åˆ†æ ‡å‡†**ï¼š
- æ¯ä¸ªæœ‰ç‹¬ç«‹åç§°çš„æ³•å¾‹æ¦‚å¿µï¼ˆæ— è®ºå¤§å°ï¼‰éƒ½åº”è¯¥ç‹¬ç«‹æˆç¬”è®°
- æ¯ä¸ªå¯èƒ½åœ¨è€ƒè¯•ä¸­å•ç‹¬æåŠçš„çŸ¥è¯†ç‚¹éƒ½è¦ç‹¬ç«‹å¤„ç†
- æ¯ä¸ªåœ¨å®åŠ¡ä¸­æœ‰ç‹¬ç«‹åº”ç”¨åœºæ™¯çš„æ¦‚å¿µéƒ½è¦æ‹†åˆ†
- å®å¯æ‹†åˆ†è¿‡ç»†ä¹Ÿä¸è¦åˆå¹¶ç‹¬ç«‹æ¦‚å¿µ

**å›¾è°±èŠ‚ç‚¹è®¾è®¡çš„æŠ€æœ¯ç»†èŠ‚**ï¼š
- èŠ‚ç‚¹è¦æœ‰æ˜ç¡®çš„ä¸»é¢˜è¾¹ç•Œï¼Œä¸èƒ½æ¨¡ç³Šä¸æ¸…
- èŠ‚ç‚¹é—´é€šè¿‡åŒé“¾å½¢æˆæœ‰å‘æˆ–æ— å‘çš„è¿æ¥å…³ç³»
- é¿å…åˆ›å»ºè¿‡äºåºå¤§çš„"è¶…çº§èŠ‚ç‚¹"ï¼Œè¿™ä¼šç ´åå›¾è°±çš„æ¸…æ™°æ€§

**é”™é¢˜åŒ¹é…çš„å…·ä½“åœºæ™¯**ï¼š
- é”™é¢˜æ¶‰åŠ"å–„æ„å–å¾—"ï¼Œåº”è¯¥èƒ½ç›´æ¥æ‰¾åˆ°å¯¹åº”ç¬”è®°
- é”™é¢˜æ¶‰åŠ"è¿”è¿˜åŸç‰©è¯·æ±‚æƒçš„æ„æˆè¦ä»¶"ï¼Œæ¯ä¸ªè¦ä»¶éƒ½åº”è¯¥æœ‰å¯¹åº”çš„è¯¦ç»†è¯´æ˜
- é”™é¢˜æ¶‰åŠæŸä¸ªå…·ä½“åŸåˆ™çš„é€‚ç”¨ï¼Œè¯¥åŸåˆ™åº”è¯¥æœ‰ç‹¬ç«‹ä¸”å®Œæ•´çš„ç¬”è®°

## å­—å¹•æ ¼å¼å¤„ç†

**æ”¯æŒæ ¼å¼**ï¼šä¸»è¦æ¥å—lrcæ ¼å¼å’Œsrtæ ¼å¼çš„å­—å¹•æ–‡ä»¶ï¼Œè¿™äº›æ ¼å¼åŒ…å«æ—¶é—´æˆ³ä¿¡æ¯ã€‚ä¹Ÿå¯èƒ½æ¥æ”¶txtæ ¼å¼çš„çº¯æ–‡æœ¬æ–‡ä»¶ï¼Œæ­¤ç±»æ–‡ä»¶æ²¡æœ‰æ—¶é—´æˆ³ä¿¡æ¯ã€‚

**æ—¶é—´æˆ³å¤„ç†**ï¼š
- å¦‚æœå­—å¹•æ–‡ä»¶åŒ…å«æ—¶é—´æˆ³ï¼Œä¸¥æ ¼ä½¿ç”¨[MM:SS.mm]æ ¼å¼ï¼Œå¦‚[01:23.45]ã€[00:23.45]
- åˆ†é’Ÿæ•°å³ä½¿ä¸º0ä¹Ÿè¦ä¿ç•™ï¼Œå¦‚[00:23.45]
- ç§’å’Œæ¯«ç§’ä¹‹é—´ä½¿ç”¨è‹±æ–‡å¥ç‚¹"."åˆ†éš”
- å¦‚æœæ˜¯txtæ ¼å¼æ²¡æœ‰æ—¶é—´æˆ³ï¼Œåˆ™ä¸æ·»åŠ æ—¶é—´æˆ³æ ‡è®°

## æŠ€æœ¯è§„èŒƒè¦æ±‚

**YAMLå‰ç½®å…ƒæ•°æ®**ï¼š
- ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼ï¼Œæ¯ä¸ªå­—æ®µåé¢å¿…é¡»æœ‰ç©ºæ ¼
- titleå­—æ®µä½¿ç”¨ã€ç§‘ç›®ã€‘æ¦‚å¿µåæ ¼å¼
- aliasesç¬¬ä¸€ä¸ªåˆ«åå¿…é¡»æ˜¯å»æ‰ç§‘ç›®å‰ç¼€çš„æ¦‚å¿µå
- tagsä½¿ç”¨æ•°ç»„æ ¼å¼ï¼Œä¸éœ€è¦#å·å‰ç¼€
- æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å¿…é¡»åŒ…å«

**åŒé“¾å¼•ç”¨è§„èŒƒ**ï¼š
- å¼•ç”¨å…¶ä»–æ¦‚å¿µæ—¶ä½¿ç”¨[[ã€ç§‘ç›®ã€‘æ¦‚å¿µå|æ¦‚å¿µåï¼ˆæˆ–è€…åˆ«åï¼‰]]æ ¼å¼
- æ˜¾ç¤ºæ–‡æœ¬ä½¿ç”¨ï¼ˆæˆ–åˆ«åï¼‰ï¼ˆæ— ç§‘ç›®å‰ç¼€ï¼‰
- é“¾æ¥ç›®æ ‡ä½¿ç”¨å®Œæ•´æ ‡é¢˜ï¼ˆå«ç§‘ç›®å‰ç¼€ï¼‰
- è¦å»ºç«‹æœ‰æ„ä¹‰çš„åŒé“¾å…³ç³»ï¼Œé¿å…æ— å…³è”çš„éšæ„é“¾æ¥

**ç¬”è®°ç»“æ„è¦æ±‚**ï¼š
- æ¯ä¸ªç¬”è®°éƒ½å¿…é¡»åŒ…å«"æ ¸å¿ƒå®šä¹‰"ã€"è®°å¿†è¦ç‚¹"å’Œ"ç›¸å…³æ¦‚å¿µ"ä¸‰ä¸ªç« èŠ‚
- "è®°å¿†è¦ç‚¹"ç« èŠ‚è¦æ ¹æ®ç¬”è®°å†…å®¹å’Œè€å¸ˆè®²è¯¾é‡ç‚¹ï¼Œæç‚¼å‡ºä¾¿äºè®°å¿†çš„å…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨æ°å½“çš„emojiç¬¦å·
- å…¶ä»–ç« èŠ‚å®Œå…¨æ ¹æ®å†…å®¹éœ€è¦è‡ªç”±åˆ›é€ 
- ç« èŠ‚æ ‡é¢˜è¦å‡†ç¡®åæ˜ å†…å®¹ï¼Œä¾¿äºå¿«é€Ÿå®šä½ä¿¡æ¯
- ç¬”è®°å†…å®¹è¦è¯¦ç»†ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
  - æ ¸å¿ƒå®šä¹‰è¦å‡†ç¡®ã€æ¸…æ™°ã€ç®€æ´
  - è®°å¿†è¦ç‚¹è¦çªå‡ºé‡ç‚¹ã€æ–¹ä¾¿è®°å¿†
  - ç›¸å…³æ¦‚å¿µè¦å®Œæ•´ã€å‡†ç¡®ã€æœ‰æ„ä¹‰
  - æ¡ˆä¾‹æˆ–è€…ç¤ºä¾‹è¦è¯¦ç»†ã€æ¸…æ™°ã€æœ‰æ•ˆ

**åˆ†éš”ç¬¦ä½¿ç”¨**ï¼š
- ä½¿ç”¨ === NOTE_SEPARATOR === åˆ†éš”ä¸åŒçš„ç¬”è®°
- åˆ†éš”ç¬¦å‰åè¦æœ‰ç©ºè¡Œ

## å†…å®¹ç»„ç»‡è‡ªç”±åº¦

é™¤äº†ä¸Šè¿°å›ºå®šæŠ€æœ¯è¦æ±‚å¤–ï¼Œä½ æ‹¥æœ‰å®Œå…¨çš„è‡ªç”±æ¥ï¼š
- åˆ›é€ æœ€åˆé€‚çš„ç« èŠ‚æ ‡é¢˜ï¼Œæ ¹æ®å†…å®¹ç‰¹ç‚¹è®¾è®¡ç« èŠ‚åç§°
- å†³å®šç« èŠ‚æ•°é‡å’Œè¯¦ç•¥ç¨‹åº¦ï¼Œé‡è¦å†…å®¹è¯¦å†™ï¼Œæ¬¡è¦å†…å®¹é€‚åº¦æ¦‚æ‹¬
- è°ƒæ•´ä¿¡æ¯é‡ç‚¹å’Œå±‚æ¬¡ç»“æ„ï¼ŒæŠŠæœ€é‡è¦çš„ä¿¡æ¯æ”¾åœ¨æ˜¾çœ¼ä½ç½®
- é€‰æ‹©æœ€æœ‰åˆ©äºç†è§£çš„ç»„ç»‡æ–¹å¼ï¼Œä½¿ç”¨åˆ—è¡¨ã€å¼•ç”¨ã€åˆ†çº§æ ‡é¢˜ç­‰
- è®¾è®¡ä¿¡æ¯å±•ç¤ºæ–¹å¼ï¼Œå¦‚æ¡ˆä¾‹åˆ†æã€è¦ç‚¹åˆ—ä¸¾ã€å¯¹æ¯”è¯´æ˜ç­‰

## è®°å¿†è¦ç‚¹è®¾è®¡æŒ‡å¯¼

**è®°å¿†è¦ç‚¹ç« èŠ‚**æ˜¯æ¯ä¸ªç¬”è®°çš„å¿…éœ€éƒ¨åˆ†ï¼Œç”¨äºæç‚¼æœ€å…³é”®çš„è®°å¿†ä¿¡æ¯ï¼š

**è®¾è®¡åŸåˆ™**ï¼š
- åŸºäºè€å¸ˆçš„è®²è¯¾é‡ç‚¹å’Œå¼ºè°ƒå†…å®¹
- ä½¿ç”¨ç®€æ´æœ‰åŠ›çš„è¡¨è¿°ï¼Œä¾¿äºå¿«é€Ÿè®°å¿†
- çªå‡ºæ¦‚å¿µçš„æ ¸å¿ƒç‰¹å¾å’Œå…³é”®åŒºåˆ«ç‚¹
- åŒ…å«å…¸å‹åº”ç”¨åœºæ™¯æˆ–è€ƒè¯•è¦ç‚¹

**è¡¨è¿°æ–¹å¼**ï¼š
- ä½¿ç”¨æ°å½“çš„emojiç¬¦å·å¢å¼ºè§†è§‰è®°å¿†
- é‡‡ç”¨ã€Œå…³é”®è¯â†’æ ¸å¿ƒå«ä¹‰ã€çš„ç®€æ´æ ¼å¼
- å¯ä»¥ä½¿ç”¨å£è¯€ã€å¯¹æ¯”ã€åœºæ™¯æè¿°ç­‰è®°å¿†æŠ€å·§
- é•¿åº¦æ§åˆ¶åœ¨1-3è¡Œï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ

**å¸¸ç”¨emojiæŒ‡å¼•**ï¼š
- ğŸ”® ç”¨äºæ ¸å¿ƒæ¦‚å¿µæˆ–åŸç†æ€§å†…å®¹
- ğŸ“± ç”¨äºå…¸å‹åœºæ™¯æˆ–å®é™…åº”ç”¨
- ğŸ’¡ ç”¨äºé‡è¦æé†’æˆ–æ˜“é”™ç‚¹
- âš–ï¸ ç”¨äºæ³•å¾‹åŸåˆ™æˆ–åˆ¤æ–­æ ‡å‡†
- ğŸ¯ ç”¨äºè€ƒè¯•é‡ç‚¹æˆ–ç­”é¢˜è¦ç‚¹
- âš ï¸ ç”¨äºæ³¨æ„äº‹é¡¹æˆ–ä¾‹å¤–æƒ…å†µ

## è´¨é‡æ§åˆ¶è¦ç‚¹

- ç¡®ä¿æ¯ä¸ªç¬”è®°éƒ½èƒ½æˆä¸ºçŸ¥è¯†å›¾è°±ä¸­æœ‰ä»·å€¼çš„èŠ‚ç‚¹
- åŒé“¾å…³ç³»è¦å‡†ç¡®åæ˜ æ¦‚å¿µé—´çš„é€»è¾‘è”ç³»
- é¿å…å­¤ç«‹èŠ‚ç‚¹ï¼Œæ¯ä¸ªæ¦‚å¿µéƒ½è¦ä¸ç›¸å…³æ¦‚å¿µå»ºç«‹åˆç†è¿æ¥

**å®ç”¨æ€§è´¨é‡**ï¼š
- æ¦‚å¿µé¢—ç²’åº¦è¦é€‚åˆé”™é¢˜æ•´ç†çš„éœ€è¦
- æ ‡ç­¾å’Œåˆ†ç±»è¦æ”¯æŒå¤šè§’åº¦æ£€ç´¢
- å†…å®¹ç»„ç»‡è¦ä¾¿äºå¿«é€Ÿå®šä½å’Œç†è§£

## åˆ†æå’Œå¤„ç†å»ºè®®

1. **å…ˆç†è§£å†æ•´ç†**ï¼šä»”ç»†åˆ†æè€å¸ˆçš„è®²è¯¾å†…å®¹å’Œé‡ç‚¹ï¼Œç†è§£çŸ¥è¯†ç‚¹çš„æ ¸å¿ƒä»·å€¼
2. **ä»¥ç†è§£ä¸ºç›®æ ‡**ï¼šæ€è€ƒä»€ä¹ˆæ ·çš„ç»„ç»‡æ–¹å¼æœ€æœ‰åŠ©äºå­¦ç”Ÿç†è§£å’Œè®°å¿†
3. **ä¿ç•™æ•™å­¦ç‰¹è‰²**ï¼šå¦‚æœè€å¸ˆå–„äºä¸¾ä¾‹ï¼Œå°±é‡ç‚¹ä¿ç•™ä¾‹å­ï¼›å¦‚æœå–„äºå¯¹æ¯”ï¼Œå°±çªå‡ºå¯¹æ¯”
4. **å°Šé‡å†…å®¹ç‰¹ç‚¹**ï¼šæœ‰äº›æ¦‚å¿µé€‚åˆé€å±‚æ·±å…¥ï¼Œæœ‰äº›é€‚åˆè¦ç‚¹åˆ—ä¸¾ï¼Œæœ‰äº›é€‚åˆæ¡ˆä¾‹è¯´æ˜
5. **åˆ›é€ æœ‰æ„ä¹‰çš„ç»“æ„**ï¼šç« èŠ‚æ ‡é¢˜è¦å‡†ç¡®åæ˜ å†…å®¹ï¼Œå¸®åŠ©å¿«é€Ÿå®šä½ä¿¡æ¯

## è¾“å‡ºæ ¼å¼æ¨¡æ¿

=== NOTE_SEPARATOR ===
YAML:
---
title: "ã€{metadata['subject']}ã€‘å…·ä½“æ¦‚å¿µå"
aliases: ["å…·ä½“æ¦‚å¿µå", "ç›¸å…³åˆ«å"]
tags: ["{metadata['subject']}", "ç« èŠ‚åç§°", "çŸ¥è¯†ç‚¹ç±»å‹", "é‡è¦ç¨‹åº¦"]
source: "{metadata['source']}"
course_url: "{metadata.get('course_url', '')}"
time_range: "å¼€å§‹æ—¶é—´-ç»“æŸæ—¶é—´"
subject: "{metadata['subject']}"
exam_importance: "é«˜/ä¸­/ä½"
created: "{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
---

CONTENT:
# ã€{metadata['subject']}ã€‘å…·ä½“æ¦‚å¿µå

## æ ¸å¿ƒå®šä¹‰

â° [MM:SS.mm]ï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ï¼‰
[å‡†ç¡®çš„å®šä¹‰ï¼Œä¿ç•™è€å¸ˆçš„é‡è¦è¡¨è¿°]

[æ ¹æ®å®é™…å†…å®¹æ™ºèƒ½åˆ›é€ æœ€åˆé€‚çš„ç« èŠ‚ç»“æ„]
[ç« èŠ‚æ ‡é¢˜å®Œå…¨ç”±ä½ æ ¹æ®å†…å®¹å†³å®š]
[å¯ä»¥æ˜¯ä»»ä½•æœ‰åŠ©äºç†è§£çš„ç»„ç»‡æ–¹å¼]

## è®°å¿†è¦ç‚¹

ğŸ”® [å…³é”®è®°å¿†ç‚¹1] â€” [ç®€æ´è§£é‡Šæˆ–è®°å¿†æŠ€å·§]
ğŸ“± [å…³é”®è®°å¿†ç‚¹2] â€” [å…¸å‹åœºæ™¯æˆ–åº”ç”¨æç¤º]
ğŸ’¡ [å…³é”®è®°å¿†ç‚¹3] â€” [é‡è¦æé†’æˆ–æ˜“é”™ç‚¹]

## ç›¸å…³æ¦‚å¿µ

- [[ã€{metadata['subject']}ã€‘ç›¸å…³æ¦‚å¿µ1|åˆ«å1]]
- [[ã€{metadata['subject']}ã€‘ç›¸å…³æ¦‚å¿µ2|åˆ«å2]]
- [[ã€{metadata['subject']}ã€‘ç›¸å…³æ¦‚å¿µ3|åˆ«å3]]

---
*è§†é¢‘æ—¶é—´æ®µï¼š[å¼€å§‹æ—¶é—´]-[ç»“æŸæ—¶é—´]*ï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ï¼‰

=== NOTE_SEPARATOR ===

è¯·å¼€å§‹åˆ†æå­—å¹•å†…å®¹ã€‚è®°ä½ï¼šä½ æ­£åœ¨ä¸ºæ³•è€ƒçŸ¥è¯†å›¾è°±åˆ›å»ºèŠ‚ç‚¹ï¼Œä¸ºæ³•è€ƒWikiåˆ›å»ºæ¡ç›®ï¼Œä¸ºé”™é¢˜æ•´ç†ç³»ç»Ÿåˆ›å»ºçŸ¥è¯†ç‚¹ç´¢å¼•ã€‚æ¯ä¸ªç¬”è®°éƒ½è¦è¾¾åˆ°è¿™ä¸‰ä¸ªç›®æ ‡çš„è¦æ±‚ã€‚å€¾å‘äºè¶…ç»†åŒ–æ‹†åˆ†ï¼Œä¸ºæ¯ä¸ªç‹¬ç«‹æ¦‚å¿µåˆ›å»ºå®Œæ•´è€Œè¯¦ç»†çš„ç¬”è®°ã€‚æ— è®ºå¦‚ä½•ï¼Œåœ¨å°†å…¨éƒ¨å­—å¹•è½¬æ¢æˆç¬”è®°ä¹‹å‰ï¼Œè¯·ä¸è¦åœæ­¢è¾“å‡ºï¼Œå¹¶ä¸”ä¸¥æ ¼æŒ‰ç…§æ ¼å¼è¾“å‡ºï¼Œä¸éœ€è¦ä»»ä½•é¢å¤–è¯´æ˜ï¼š"""
    
    def _build_enhancement_prompt(self, all_notes: List[Dict], existing_concepts: Dict) -> str:
        """æ„å»ºæ¦‚å¿µå…³ç³»å¢å¼ºæç¤ºè¯"""
        notes_summary = "\n".join([f"- {note['yaml']['title']}" for note in all_notes])
        existing_concepts_list = existing_concepts.get('existing_concepts', [])
        
        return f"""ä½ æ˜¯æ³•è€ƒçŸ¥è¯†ä½“ç³»ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ–°ç”Ÿæˆçš„ç¬”è®°ï¼Œä¼˜åŒ–å…¶æ¦‚å¿µå…³ç³»é“¾æ¥ã€‚

æ–°ç”Ÿæˆçš„ç¬”è®°ï¼š
{notes_summary}

ç°æœ‰æ¦‚å¿µåº“ä¸­çš„æ¦‚å¿µï¼š
{existing_concepts_list[:50]}  # é™åˆ¶é•¿åº¦

è¦æ±‚ï¼š
1. æ£€æŸ¥æ¯ä¸ªç¬”è®°ä¸­çš„[[æ¦‚å¿µ]]é“¾æ¥æ˜¯å¦å‡†ç¡®ï¼ˆæ ¼å¼ä¸º[[ã€ç§‘ç›®ã€‘æ¦‚å¿µå|æ¦‚å¿µåï¼ˆæˆ–è€…åˆ«åï¼‰]]ï¼‰
2. è¡¥å……å¯èƒ½é—æ¼çš„é‡è¦æ¦‚å¿µå…³è”
3. ç¡®ä¿é“¾æ¥çš„æ¦‚å¿µç¡®å®å­˜åœ¨æˆ–åº”è¯¥å­˜åœ¨
4. ç§»é™¤æ— å…³æˆ–é”™è¯¯çš„æ¦‚å¿µé“¾æ¥
5. åªè¿”å›éœ€è¦ä¿®æ”¹çš„ç¬”è®°çš„æ¦‚å¿µé“¾æ¥éƒ¨åˆ†

è¾“å‡ºæ ¼å¼ï¼š
ENHANCEMENT:
ç¬”è®°æ ‡é¢˜1:
- [[ã€ç§‘ç›®ã€‘ä¿®æ­£åçš„æ¦‚å¿µ1|ä¿®æ­£åçš„æ¦‚å¿µ1ï¼ˆæˆ–è€…åˆ«åï¼‰]]
- [[ã€ç§‘ç›®ã€‘ä¿®æ­£åçš„æ¦‚å¿µ2|ä¿®æ­£åçš„æ¦‚å¿µ2ï¼ˆæˆ–è€…åˆ«åï¼‰]]

ç¬”è®°æ ‡é¢˜2:
- [[ã€ç§‘ç›®ã€‘ä¿®æ­£åçš„æ¦‚å¿µ1|ä¿®æ­£åçš„æ¦‚å¿µ1ï¼ˆæˆ–è€…åˆ«åï¼‰]]
- [[ã€ç§‘ç›®ã€‘ä¿®æ­£åçš„æ¦‚å¿µ2|ä¿®æ­£åçš„æ¦‚å¿µ2ï¼ˆæˆ–è€…åˆ«åï¼‰]]

å¦‚æœæŸä¸ªç¬”è®°ä¸éœ€è¦ä¿®æ”¹ï¼Œä¸è¦åŒ…å«åœ¨è¾“å‡ºä¸­ã€‚"""
    
    def _build_single_note_enhancement_prompt(self, note_content: str, note_title: str, existing_concepts: Dict) -> str:
        """æ„å»ºå•ä¸ªç¬”è®°å¢å¼ºçš„æç¤ºè¯"""
        existing_concepts_list = existing_concepts.get('existing_concepts', [])
        
        return f"""ä½ æ˜¯æ³•è€ƒçŸ¥è¯†ä½“ç³»ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ç¬”è®°ï¼Œæ£€æŸ¥å¹¶ä¼˜åŒ–å…¶æ¦‚å¿µå…³ç³»é“¾æ¥ã€‚

ç¬”è®°æ ‡é¢˜ï¼š{note_title}

ç¬”è®°å†…å®¹ï¼š
{note_content}

ç°æœ‰æ¦‚å¿µåº“ï¼ˆå‰100ä¸ªï¼‰ï¼š
{existing_concepts_list[:100]}

è¦æ±‚ï¼š
1. æ£€æŸ¥ç¬”è®°ä¸­ç°æœ‰çš„[[æ¦‚å¿µ]]é“¾æ¥æ˜¯å¦å‡†ç¡®ï¼ˆæ ¼å¼ä¸º[[ã€ç§‘ç›®ã€‘æ¦‚å¿µå|æ¦‚å¿µåï¼ˆæˆ–è€…åˆ«åï¼‰]]ï¼‰
2. è¯†åˆ«ç¬”è®°ä¸­å¯èƒ½é—æ¼çš„é‡è¦æ¦‚å¿µå…³è”
3. åªæ·»åŠ ç¡®å®å­˜åœ¨äºæ¦‚å¿µåº“ä¸­çš„æ¦‚å¿µé“¾æ¥
4. ç§»é™¤æŒ‡å‘ä¸å­˜åœ¨æ¦‚å¿µçš„é“¾æ¥
5. ç¡®ä¿æ–°å¢çš„æ¦‚å¿µé“¾æ¥ä¸ç¬”è®°å†…å®¹é«˜åº¦ç›¸å…³
6. åŒé“¾æ ¼å¼è¦æ±‚ï¼šå¦‚æœæ¦‚å¿µåæœ‰ã€ç§‘ç›®ã€‘å‰ç¼€ï¼Œä½¿ç”¨æ˜¾ç¤ºåˆ«åæ ¼å¼ï¼š[[ã€ç§‘ç›®ã€‘æ¦‚å¿µå|æ¦‚å¿µåï¼ˆæˆ–è€…åˆ«åï¼‰]]
7. ä¸è¦æ·»åŠ ä»»ä½•ä¼˜åŒ–è¯´æ˜æˆ–é¢å¤–å†…å®¹
8. [æ—¶é—´æˆ³]å¿…é¡»ä¸¥æ ¼ä½¿ç”¨[MM:SS.mm]([åˆ†:ç§’.æ¯«ç§’])æ ¼å¼ï¼Œä»»ä½•ä¸€ä½éƒ½ä¸èƒ½çœç•¥ã€‚å¦‚[01:23.45]ï¼Œå¦‚æœåˆ†é’Ÿæ•°ä¸º0ï¼Œè¦ä¿ç•™ï¼Œå¦‚[00:23.45]ï¼›ç§’å’Œæ¯«ç§’ä¹‹é—´ä½¿ç”¨è‹±æ–‡å¥ç‚¹"."


å¦‚æœéœ€è¦ä¿®æ”¹ï¼Œè¯·è¾“å‡ºï¼š
MODIFIED: true
ENHANCED_CONTENT:
[ä¿®æ”¹åçš„å®Œæ•´ç¬”è®°å†…å®¹]

å¦‚æœä¸éœ€è¦ä¿®æ”¹ï¼Œè¯·è¾“å‡ºï¼š
MODIFIED: false

è¯·å¼€å§‹åˆ†æï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜ï¼š"""
    
    def _parse_ai_response(self, response_content: str) -> List[Dict[str, Any]]:
        """è§£æAIè¿”å›çš„å¤šä¸ªç¬”è®°æ•°æ®"""
        notes = []
        sections = response_content.split('=== NOTE_SEPARATOR ===')
        
        for section in sections:
            if section.strip():
                note_data = self._parse_single_note(section)
                if note_data:
                    notes.append(note_data)
        
        return notes
    
    def _parse_single_note(self, section: str) -> Optional[Dict[str, Any]]:
        """è§£æå•ä¸ªç¬”è®°çš„YAMLå’Œå†…å®¹"""
        try:
            # æŸ¥æ‰¾YAMLå’ŒCONTENTéƒ¨åˆ†
            yaml_start = section.find('YAML:')
            content_start = section.find('CONTENT:')
            
            if yaml_start == -1 or content_start == -1:
                return None
            
            yaml_section = section[yaml_start + 5:content_start].strip()
            content_section = section[content_start + 8:].strip()
            
            # è§£æYAML
            yaml_content = yaml_section.replace('---', '').strip()
            # å°è¯•ä¿®å¤å¸¸è§çš„YAMLæ ¼å¼é—®é¢˜ï¼šç¡®ä¿å†’å·åæœ‰ç©ºæ ¼
            # åŒ¹é…è¡Œé¦–çš„é”®åï¼Œåé¢ç´§è·Ÿå†’å·å’Œéç©ºç™½å­—ç¬¦ï¼Œå¹¶åœ¨å†’å·åæ·»åŠ ç©ºæ ¼
            yaml_content = re.sub(r'^(?P<key>\s*\S+?):(?P<value>\S.*)', r'\g<key>: \g<value>', yaml_content, flags=re.MULTILINE)
            yaml_data = yaml.safe_load(yaml_content)
            
            return {
                'yaml': yaml_data,
                'content': content_section
            }
        except Exception as e:
            print(f"âš ï¸ è§£æç¬”è®°æ—¶å‡ºé”™: {e}")
            return None
    
    def _parse_enhancement_response(self, response: str, original_notes: List[Dict]) -> List[Dict]:
        """è§£ææ¦‚å¿µå¢å¼ºå“åº”å¹¶åº”ç”¨åˆ°åŸå§‹ç¬”è®°"""
        try:
            # æå–å¢å¼ºéƒ¨åˆ†
            enhancement_start = response.find('ENHANCEMENT:')
            if enhancement_start == -1:
                return original_notes
            
            enhancement_content = response[enhancement_start + 12:].strip()
            
            # è§£æå¢å¼ºå»ºè®®
            enhancements = {}
            current_title = None
            
            for line in enhancement_content.split('\n'):
                line = line.strip()
                if line.endswith(':') and not line.startswith('-'):
                    current_title = line[:-1]
                    enhancements[current_title] = []
                elif line.startswith('- [[') and current_title:
                    concept = re.findall(r'\[\[(.*?)\]\]', line)
                    if concept:
                        enhancements[current_title].append(f"[[{concept[0]}]]")
            
            # åº”ç”¨å¢å¼ºåˆ°åŸå§‹ç¬”è®°
            enhanced_notes = []
            for note in original_notes:
                title = note['yaml']['title']
                if title in enhancements:
                    # æ›´æ–°ç›¸å…³æ¦‚å¿µéƒ¨åˆ†
                    content = note['content']
                    # æ›¿æ¢ç›¸å…³æ¦‚å¿µéƒ¨åˆ†
                    concept_pattern = r'## ç›¸å…³æ¦‚å¿µ\n(.*?)(?=\n##|\n---|\Z)'
                    new_concepts = '\n'.join(f"- {concept}" for concept in enhancements[title])
                    content = re.sub(concept_pattern, f'## ç›¸å…³æ¦‚å¿µ\n{new_concepts}', content, flags=re.DOTALL)
                    note['content'] = content
                
                enhanced_notes.append(note)
            
            return enhanced_notes
        except Exception as e:
            print(f"âš ï¸ åº”ç”¨æ¦‚å¿µå¢å¼ºæ—¶å‡ºé”™: {e}")
            return original_notes
    
    def _parse_single_note_enhancement_response(self, response: str, original_content: str) -> Optional[Dict]:
        """è§£æå•ä¸ªç¬”è®°å¢å¼ºå“åº”"""
        try:
            if "MODIFIED: true" in response:
                content_start = response.find("ENHANCED_CONTENT:")
                if content_start != -1:
                    enhanced_content = response[content_start + 17:].strip()
                    
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤„ç†å¯èƒ½çš„ä»£ç å—åŒ…è£¹ï¼ˆæ”¯æŒè¯­è¨€æ ‡ç­¾ï¼‰
                    # åŒ¹é…å¼€å¤´ï¼š```åè·Ÿå¯é€‰çš„è¯­è¨€åç§°
                    # åŒ¹é…ç»“å°¾ï¼š```å¯èƒ½å‰åæœ‰ç©ºç™½
                    code_block_pattern = re.compile(
                        r'^\s*```[a-zA-Z0-9_+-]*\s*\n?(.*?)\s*```\s*', 
                        re.DOTALL
                    )
                    
                    match = code_block_pattern.match(enhanced_content)
                    if match:
                        # æå–ä»£ç å—å†…å®¹
                        enhanced_content = match.group(1).strip()
                    else:
                        # å¤„ç†åªæœ‰å¼€å¤´æ ‡è®°çš„æƒ…å†µ
                        if enhanced_content.startswith('```'):
                            # ç§»é™¤å¼€å¤´çš„```å’Œå¯èƒ½å­˜åœ¨çš„è¯­è¨€åç§°
                            enhanced_content = re.sub(r'^\s*```[a-zA-Z0-9_+-]*\s*', '', enhanced_content, 1)
                        
                        # å¤„ç†ç»“å°¾æ ‡è®°
                        if enhanced_content.endswith('```'):
                            enhanced_content = re.sub(r'\s*```\s*', '', enhanced_content)
                        
                        # ç¡®ä¿å»é™¤å¤šä½™ç©ºç™½
                        enhanced_content = enhanced_content.strip()
                    
                    return {
                        'modified': True,
                        'enhanced_content': enhanced_content
                    }
            
            return {'modified': False}
            
        except Exception as e:
            print(f"âš ï¸ è§£æå¢å¼ºå“åº”å¤±è´¥: {e}")
            return None
        
    def set_progress_callback(self, callback):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callback = callback
    
    def set_concurrent_config(self, config: ConcurrentConfig):
        """è®¾ç½®å¹¶å‘é…ç½®"""
        self.concurrent_config = config
    
    def _generate_notes_from_individual_segments(self, segments: List[Segment], 
                                           analysis_result: Dict, metadata: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        åŸºäºç‹¬ç«‹åˆ†æ®µç»“æœç”Ÿæˆç¬”è®°ï¼ˆæ¯ä¸ªçŸ¥è¯†ç‚¹å¯¹åº”ä¸€ä¸ªæ®µè½ï¼‰- å¹¶å‘ç‰ˆæœ¬
        """
        knowledge_points = analysis_result.get('knowledge_points', [])
        
        # éªŒè¯åˆ†æ®µæ•°æ®
        valid_segments = []
        for i, segment in enumerate(segments, 1):
            if not segment.text.strip():
                print(f"âš ï¸ è·³è¿‡ç©ºåˆ†æ®µ {i}")
                continue
                
            if len(segment.knowledge_points) != 1:
                print(f"âš ï¸ åˆ†æ®µ {i} åŒ…å« {len(segment.knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹ï¼Œè·³è¿‡")
                continue
            
            kp_id = segment.knowledge_points[0]
            
            # æ‰¾åˆ°å¯¹åº”çš„çŸ¥è¯†ç‚¹
            target_kp = None
            for kp in knowledge_points:
                if kp.get('id') == kp_id:
                    target_kp = kp
                    break
            
            if not target_kp:
                print(f"âš ï¸ æ‰¾ä¸åˆ°çŸ¥è¯†ç‚¹ {kp_id}ï¼Œè·³è¿‡åˆ†æ®µ {i}")
                continue
            
            valid_segments.append((segment, target_kp))
        
        if not valid_segments:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æ®µå¯ä»¥å¤„ç†")
            return []
        
        print(f"ğŸ“ å¼€å§‹å¹¶å‘å¤„ç† {len(valid_segments)} ä¸ªçŸ¥è¯†ç‚¹...")
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨å¹¶å‘å¤„ç†
        if len(valid_segments) <= 2:
            # å¦‚æœçŸ¥è¯†ç‚¹å¾ˆå°‘ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„é€ä¸ªå¤„ç†æ–¹å¼
            print("ğŸ”„ çŸ¥è¯†ç‚¹æ•°é‡è¾ƒå°‘ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç†...")
            return self._process_segments_traditionally(valid_segments, analysis_result, metadata)
        
        # å‡†å¤‡å¹¶å‘å¤„ç†çš„æ•°æ®
        knowledge_points_data = []
        for segment, target_kp in valid_segments:
            # æ„å»ºä¼ é€’ç»™å¹¶å‘å¤„ç†å™¨çš„æ•°æ®ç»“æ„
            kp_data = {
                'segment': segment,
                'target_kp': target_kp,
                'analysis_result': analysis_result,
                'metadata': metadata
            }
            kp_id = target_kp.get('id', 'unknown')
            knowledge_points_data.append((kp_id, kp_data))
        
        # æ„å»ºæç¤ºè¯ç”Ÿæˆå‡½æ•°
        def prompt_builder(kp_data):
            return self._build_single_knowledge_point_prompt(
                kp_data['segment'],
                kp_data['target_kp'],
                kp_data['analysis_result'],
                kp_data['metadata']
            )
        
        # è¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(completed, total):
            if self.progress_callback:
                self.progress_callback(completed, total)
            print(f"ğŸ“Š å¤„ç†è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)")
        
        # ä¼°è®¡å‰©ä½™çš„APIè°ƒç”¨æ¬¡æ•°ï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
        estimated_remaining_calls = min(20, len(valid_segments))  # ä¿å®ˆä¼°è®¡
        
        try:
            # æ‰§è¡Œå¹¶å‘å¤„ç†
            results, stats = run_concurrent_processing(
                knowledge_points_data=knowledge_points_data,
                prompt_builder=prompt_builder,
                client=self.client,
                model=self.model,
                config=self.concurrent_config,
                progress_callback=progress_callback,
                estimated_remaining_calls=estimated_remaining_calls
            )
            
            # å¤„ç†å¹¶å‘ç»“æœ
            all_notes = []
            failed_tasks = []
            
            for kp_id, original_data, result, error in results:
                if result is not None and error is None:
                    # æˆåŠŸçš„ä»»åŠ¡
                    try:
                        parsed_note = self._parse_single_note_response(
                            result, 
                            original_data['target_kp'], 
                            original_data['metadata']
                        )
                        if parsed_note:
                            all_notes.append(parsed_note)
                            print(f"âœ… æˆåŠŸç”Ÿæˆç¬”è®°: {original_data['target_kp'].get('concept_name', kp_id)}")
                        else:
                            print(f"âš ï¸ è§£æç¬”è®°å¤±è´¥: {original_data['target_kp'].get('concept_name', kp_id)}")
                            failed_tasks.append((kp_id, original_data))
                    except Exception as e:
                        print(f"âš ï¸ å¤„ç†ç»“æœå¤±è´¥ {kp_id}: {e}")
                        failed_tasks.append((kp_id, original_data))
                else:
                    # å¤±è´¥çš„ä»»åŠ¡
                    print(f"âŒ çŸ¥è¯†ç‚¹å¤„ç†å¤±è´¥ {kp_id}: {error}")
                    failed_tasks.append((kp_id, original_data))
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print(f"ğŸ“Š å¹¶å‘å¤„ç†ç»Ÿè®¡:")
            print(f"  - æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
            print(f"  - æˆåŠŸå®Œæˆ: {stats['completed_tasks']}")
            print(f"  - å¤±è´¥ä»»åŠ¡: {stats['failed_tasks']}")
            print(f"  - æ€»é‡è¯•æ¬¡æ•°: {stats['total_retries']}")
            print(f"  - æ€»å¤„ç†æ—¶é—´: {stats['total_processing_time']:.2f}ç§’")
            print(f"  - å¤„ç†æ‰¹æ¬¡: {stats['batches_processed']}")
            
            # å¦‚æœæœ‰å¤±è´¥çš„ä»»åŠ¡ï¼Œå¯ä»¥é€‰æ‹©ç”¨ä¼ ç»Ÿæ–¹å¼é‡è¯•
            if failed_tasks and len(failed_tasks) <= 3:  # åªå¯¹å°‘é‡å¤±è´¥ä»»åŠ¡é‡è¯•
                print(f"ğŸ”„ å¯¹ {len(failed_tasks)} ä¸ªå¤±è´¥ä»»åŠ¡ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼é‡è¯•...")
                retry_segments = [(data['segment'], data['target_kp']) for _, data in failed_tasks]
                retry_notes = self._process_segments_traditionally(retry_segments, analysis_result, metadata)
                all_notes.extend(retry_notes)
            
            print(f"âœ… å¹¶å‘å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_notes)} ä¸ªç¬”è®°")

            if all_notes:
                print(f"\nğŸ” è°ƒè¯•è¾“å‡ºï¼šå…± {len(all_notes)} ä¸ªç¬”è®°")
                for i, note in enumerate(all_notes[:3]):  # åªè¾“å‡ºå‰3ä¸ªé¿å…å¤ªå¤šæ—¥å¿—
                    debug_note_structure(note, i)
                
                # ########################################################self._validate_notes_structure(all_notes)

            print(f"âœ… ç‹¬ç«‹åˆ†æ®µå¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_notes)} ä¸ªç¬”è®°")
            return all_notes
            
        except Exception as e:
            print(f"âŒ å¹¶å‘å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹å¼: {e}")
            return self._process_segments_traditionally(valid_segments, analysis_result, metadata)
    
    def _process_segments_traditionally(self, valid_segments: List[Tuple], 
                                      analysis_result: Dict, metadata: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        ä¼ ç»Ÿæ–¹å¼å¤„ç†åˆ†æ®µï¼ˆé€ä¸ªå¤„ç†ï¼Œä½œä¸ºå¹¶å‘å¤„ç†çš„åå¤‡æ–¹æ¡ˆï¼‰
        """
        all_notes = []
        total_segments = len(valid_segments)
        
        for i, (segment, target_kp) in enumerate(valid_segments, 1):
            kp_id = target_kp.get('id', 'unknown')
            
            # æ„å»ºå•ä¸ªçŸ¥è¯†ç‚¹çš„å¤„ç†æç¤ºè¯
            single_kp_prompt = self._build_single_knowledge_point_prompt(
                segment, target_kp, analysis_result, metadata
            )
            
            try:
                print(f"ğŸ¤– å¤„ç†çŸ¥è¯†ç‚¹: {target_kp.get('concept_name', kp_id)} ({i}/{total_segments})")
                
                # è°ƒç”¨è¿›åº¦å›è°ƒ
                if self.progress_callback:
                    self.progress_callback(i-1, total_segments)
                
                # è°ƒç”¨AIå¤„ç†å•ä¸ªçŸ¥è¯†ç‚¹
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": single_kp_prompt}],
                    temperature=0,
                )
                
                # è§£æAIè¿”å›çš„å•ä¸ªç¬”è®°ï¼ˆä¸åŒ…å«åˆ†éš”ç¬¦ï¼‰
                note_content = response.choices[0].message.content.strip()
                
                # è§£æå•ä¸ªç¬”è®°
                parsed_note = self._parse_single_note_response(note_content, target_kp, metadata)
                
                if parsed_note:
                    all_notes.append(parsed_note)
                    print(f"âœ… æˆåŠŸç”Ÿæˆç¬”è®°: {target_kp.get('concept_name', kp_id)}")
                else:
                    print(f"âš ï¸ è§£æç¬”è®°å¤±è´¥: {target_kp.get('concept_name', kp_id)}")
                
            except Exception as e:
                print(f"âš ï¸ å¤„ç†çŸ¥è¯†ç‚¹ {kp_id} å¤±è´¥: {e}")
                continue
        
        # æœ€åä¸€æ¬¡è°ƒç”¨è¿›åº¦å›è°ƒ
        if self.progress_callback:
            self.progress_callback(total_segments, total_segments)
        
        print(f"âœ… ä¼ ç»Ÿæ–¹å¼å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_notes)} ä¸ªç¬”è®°")
        return all_notes
    
    def estimate_remaining_api_calls(self) -> int:
        """
        ä¼°è®¡å‰©ä½™çš„APIè°ƒç”¨æ¬¡æ•°
        
        è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
        æ¯”å¦‚è·Ÿè¸ªå®é™…çš„APIä½¿ç”¨æƒ…å†µ
        
        Returns:
            ä¼°è®¡çš„å‰©ä½™è°ƒç”¨æ¬¡æ•°
        """
        # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µå®ç°æ›´å¤æ‚çš„é€»è¾‘
        # æ¯”å¦‚è®°å½•å¼€å§‹æ—¶é—´ï¼Œè®¡ç®—å·²ç”¨æ¬¡æ•°ç­‰
        return 20  # ä¿å®ˆä¼°è®¡

def debug_note_structure(note: Dict[str, Any], note_index: int = 0):
    """è°ƒè¯•è¾“å‡ºç¬”è®°ç»“æ„"""
    print(f"\n=== è°ƒè¯•ç¬”è®° {note_index + 1} ç»“æ„ ===")
    print(f"ç¬”è®°é”®: {list(note.keys())}")
    
    if 'yaml' in note:
        print(f"YAMLç±»å‹: {type(note['yaml'])}")
        if isinstance(note['yaml'], dict):
            print(f"YAMLé”®: {list(note['yaml'].keys())}")
            print(f"æ ‡é¢˜: {note['yaml'].get('title', 'æœªæ‰¾åˆ°æ ‡é¢˜')}")
        else:
            print(f"YAMLå†…å®¹: {note['yaml']}")
    else:
        print("âŒ ç¼ºå°‘yamlå­—æ®µ")
    
    if 'content' in note:
        content_length = len(note['content']) if note['content'] else 0
        print(f"å†…å®¹é•¿åº¦: {content_length}")
        print(f"å†…å®¹å‰100å­—ç¬¦: {note['content'][:100] if note['content'] else 'ç©ºå†…å®¹'}")
    else:
        print("âŒ ç¼ºå°‘contentå­—æ®µ")
    print("=" * 40)