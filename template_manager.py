"""
æ¨¡æ¿ç®¡ç†æ ¸å¿ƒç±»
ç»Ÿä¸€ç®¡ç†æ¦‚å¿µæ¨¡æ¿çš„é€‰æ‹©ã€å¡«å……å’Œç”Ÿæˆæµç¨‹
"""

import json
import re
import datetime
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict

from templates.concept_templates import ConceptTemplate, TemplateRegistry
from templates.template_utils import TemplateUtils, TemplateSelectionResult

@dataclass
class TemplateProcessingResult:
    """æ¨¡æ¿å¤„ç†ç»“æœ"""
    success: bool                               # æ˜¯å¦æˆåŠŸ
    generated_note: Optional[str] = None        # ç”Ÿæˆçš„ç¬”è®°å†…å®¹
    template_used: Optional[str] = None         # ä½¿ç”¨çš„æ¨¡æ¿ç±»å‹
    extraction_prompt: Optional[str] = None     # ç”Ÿæˆçš„æå–æç¤ºè¯
    processing_info: Dict[str, Any] = None      # å¤„ç†ä¿¡æ¯
    errors: List[str] = None                    # é”™è¯¯ä¿¡æ¯
    
    def __post_init__(self):
        if self.processing_info is None:
            self.processing_info = {}
        if self.errors is None:
            self.errors = []

class TemplateManager:
    """æ¨¡æ¿ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡æ¿ç®¡ç†å™¨"""
        self.registry = TemplateRegistry
        self.utils = TemplateUtils
        self._processing_stats = {
            "total_processed": 0,
            "successful": 0,
            "failed": 0,
            "template_usage": {},
            "error_types": {}
        }
    
    def process_knowledge_point(self, 
                               knowledge_point: Dict[str, Any],
                               segment_text: str,
                               metadata: Dict[str, Any],
                               ai_extraction_function: Optional[callable] = None) -> TemplateProcessingResult:
        """
        å¤„ç†å•ä¸ªçŸ¥è¯†ç‚¹ï¼Œé€‰æ‹©æ¨¡æ¿å¹¶ç”Ÿæˆç¬”è®°
        
        Args:
            knowledge_point: çŸ¥è¯†ç‚¹ä¿¡æ¯
            segment_text: åˆ†æ®µçš„å­—å¹•æ–‡æœ¬
            metadata: å…ƒæ•°æ®ä¿¡æ¯ï¼ˆè¯¾ç¨‹ä¿¡æ¯ç­‰ï¼‰
            ai_extraction_function: AIæå–å‡½æ•°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            TemplateProcessingResult: å¤„ç†ç»“æœ
        """
        try:
            self._processing_stats["total_processed"] += 1
            
            # ç¬¬ä¸€æ­¥ï¼šè§£ææ¦‚å¿µç±»å‹
            concept_types = self._parse_concept_types(knowledge_point)
            importance_level = knowledge_point.get('importance_level', 'ä¸­')
            
            # ç¬¬äºŒæ­¥ï¼šé€‰æ‹©åˆé€‚çš„æ¨¡æ¿
            template_result = self.utils.select_template_for_concept(
                concept_types, importance_level
            )
            
            # è®°å½•æ¨¡æ¿ä½¿ç”¨ç»Ÿè®¡
            template_name = template_result.primary_template.type_name
            self._processing_stats["template_usage"][template_name] = \
                self._processing_stats["template_usage"].get(template_name, 0) + 1
            
            # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆä¿¡æ¯æå–æç¤ºè¯
            extraction_prompt = self.utils.generate_extraction_prompt(
                template_result, knowledge_point, segment_text
            )
            
            # ç¬¬å››æ­¥ï¼šAIä¿¡æ¯æå–ï¼ˆå¦‚æœæä¾›äº†AIå‡½æ•°ï¼‰
            extracted_content = {}
            if ai_extraction_function:
                try:
                    ai_response = ai_extraction_function(extraction_prompt)
                    extracted_content = self._parse_ai_extraction_response(
                        ai_response, template_result
                    )
                except Exception as e:
                    print(f"âš ï¸ AIæå–å¤±è´¥: {str(e)}")
                    # ä½¿ç”¨fallbackæ–¹å¼
                    extracted_content = self._create_fallback_content(
                        knowledge_point, segment_text, template_result
                    )
            else:
                # å¦‚æœæ²¡æœ‰AIå‡½æ•°ï¼Œåˆ›å»ºåŸºç¡€å†…å®¹
                extracted_content = self._create_basic_content(
                    knowledge_point, segment_text, template_result
                )
            
            # ç¬¬äº”æ­¥ï¼šç”Ÿæˆæ ‡å‡†åŒ–ç¬”è®°
            generated_note = self.utils.generate_template_filled_note(
                template_result, knowledge_point, extracted_content, metadata
            )
            
            # ç¬¬å…­æ­¥ï¼šéªŒè¯ç”Ÿæˆçš„å†…å®¹
            is_valid, validation_errors = self.utils.validate_template_content(generated_note)
            
            if not is_valid:
                print(f"âš ï¸ å†…å®¹éªŒè¯å¤±è´¥: {validation_errors}")
                # å°è¯•ä¿®å¤å¸¸è§é—®é¢˜
                generated_note = self._fix_common_issues(generated_note, validation_errors)
            
            # è®°å½•æˆåŠŸ
            self._processing_stats["successful"] += 1
            
            # è¿”å›å¤„ç†ç»“æœ
            return TemplateProcessingResult(
                success=True,
                generated_note=generated_note,
                template_used=template_name,
                extraction_prompt=extraction_prompt,
                processing_info={
                    "concept_types": concept_types,
                    "importance_level": importance_level,
                    "template_confidence": template_result.confidence_score,
                    "selection_reason": template_result.selection_reason,
                    "sections_count": len(template_result.merged_sections),
                    "ai_extraction_used": ai_extraction_function is not None,
                    "content_validation": is_valid,
                    "processing_time": datetime.datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            # è®°å½•å¤±è´¥
            self._processing_stats["failed"] += 1
            error_type = type(e).__name__
            self._processing_stats["error_types"][error_type] = \
                self._processing_stats["error_types"].get(error_type, 0) + 1
            
            return TemplateProcessingResult(
                success=False,
                errors=[f"æ¨¡æ¿å¤„ç†å¤±è´¥: {str(e)}"],
                processing_info={
                    "error_type": error_type,
                    "knowledge_point_id": knowledge_point.get('id', 'unknown'),
                    "processing_time": datetime.datetime.now().isoformat()
                }
            )
    
    def _parse_concept_types(self, knowledge_point: Dict[str, Any]) -> Union[str, List[str]]:
        """è§£ææ¦‚å¿µç±»å‹"""
        concept_type = knowledge_point.get('concept_type')
        
        if not concept_type:
            return "å®šä¹‰æ€§æ¦‚å¿µ"  # é»˜è®¤ç±»å‹
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªç±»å‹
        if isinstance(concept_type, str):
            # æ£€æŸ¥å¸¸è§çš„åˆ†éš”ç¬¦
            separators = [',', 'ï¼Œ', ';', 'ï¼›', '/', '|', '&', 'å’Œ']
            for sep in separators:
                if sep in concept_type:
                    types = [t.strip() for t in concept_type.split(sep) if t.strip()]
                    return types if len(types) > 1 else concept_type
            return concept_type
        
        # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨
        elif isinstance(concept_type, list):
            return [str(t).strip() for t in concept_type if str(t).strip()]
        
        return "å®šä¹‰æ€§æ¦‚å¿µ"
    
    def _parse_ai_extraction_response(self, 
                                    ai_response: str, 
                                    template_result: TemplateSelectionResult) -> Dict[str, str]:
        """è§£æAIæå–å“åº”"""
        extracted_content = {}
        
        # å°è¯•æŒ‰ç« èŠ‚è§£æå“åº”
        for section in template_result.merged_sections:
            section_title = section.title
            
            # æŸ¥æ‰¾ç« èŠ‚å†…å®¹çš„å„ç§æ¨¡å¼
            patterns = [
                rf"{re.escape(section_title)}[ï¼š:]\s*(.*?)(?=\n\d+\.|$)",
                rf"\d+\.\s*{re.escape(section_title)}[ï¼š:]\s*(.*?)(?=\n\d+\.|$)",
                rf"##\s*{re.escape(section_title)}\s*(.*?)(?=\n##|$)",
                rf"ã€{re.escape(section_title)}ã€‘\s*(.*?)(?=\nã€|$)"
            ]
            
            content = ""
            for pattern in patterns:
                match = re.search(pattern, ai_response, re.DOTALL | re.IGNORECASE)
                if match:
                    content = match.group(1).strip()
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨å…³é”®è¯æœç´¢
            if not content:
                keywords = self._get_section_keywords(section_title)
                for keyword in keywords:
                    pattern = rf"{re.escape(keyword)}[ï¼š:]\s*(.*?)(?=\n|$)"
                    match = re.search(pattern, ai_response, re.IGNORECASE)
                    if match:
                        content = match.group(1).strip()
                        break
            
            # æ¸…ç†å†…å®¹
            if content:
                content = self._clean_extracted_content(content)
            
            extracted_content[section_title] = content
        
        return extracted_content
    
    def _get_section_keywords(self, section_title: str) -> List[str]:
        """è·å–ç« èŠ‚çš„å…³é”®è¯"""
        keyword_map = {
            "æ ¸å¿ƒå®šä¹‰": ["å®šä¹‰", "å«ä¹‰", "æ¦‚å¿µ"],
            "å…³é”®è¦ç´ ": ["è¦ç´ ", "ç‰¹å¾", "ç»„æˆ"],
            "è¦ä»¶æ¦‚è¿°": ["è¦ä»¶", "æ¦‚è¿°", "æ€»ä½“"],
            "è¦ä»¶è¯¦è§£": ["è¯¦è§£", "å…·ä½“è¦ä»¶", "åˆ†æ"],
            "ç¨‹åºæ¦‚è¿°": ["ç¨‹åº", "æ¦‚è¿°", "æµç¨‹"],
            "æ“ä½œæ­¥éª¤": ["æ­¥éª¤", "æµç¨‹", "è¿‡ç¨‹"],
            "æ ‡å‡†æ¦‚è¿°": ["æ ‡å‡†", "æ¦‚è¿°", "åŸåˆ™"],
            "åˆ¤æ–­è¦ç´ ": ["åˆ¤æ–­", "è¦ç´ ", "æ ‡å‡†"],
            "æ¡æ–‡å†…å®¹": ["æ¡æ–‡", "æ³•æ¡", "è§„å®š"],
            "é€‚ç”¨æƒ…å½¢": ["é€‚ç”¨", "æƒ…å½¢", "èŒƒå›´"],
            "ç»éªŒæ¦‚è¿°": ["ç»éªŒ", "æ¦‚è¿°", "æ€»ç»“"],
            "æ“ä½œè¦ç‚¹": ["è¦ç‚¹", "æŠ€å·§", "æ–¹æ³•"],
            "å…¸å‹æ¡ˆä¾‹": ["æ¡ˆä¾‹", "ä¾‹å­", "å®ä¾‹"],
            "æ³¨æ„äº‹é¡¹": ["æ³¨æ„", "äº‹é¡¹", "æé†’"],
            "è®°å¿†è¦ç‚¹": ["è®°å¿†", "è¦ç‚¹", "å£è¯€"]
        }
        
        return keyword_map.get(section_title, [section_title])
    
    def _clean_extracted_content(self, content: str) -> str:
        """æ¸…ç†æå–çš„å†…å®¹"""
        if not content:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n\s*\n', '\n\n', content)
        
        # ç§»é™¤å¼€å¤´çš„åºå·æˆ–æ ‡è®°
        content = re.sub(r'^[\d\.\-\*\+ã€‘ã€‘\s]*', '', content)
        
        # ç§»é™¤æœ«å°¾çš„å¤šä½™å­—ç¬¦
        content = content.rstrip('ã€‚ï¼Œã€ï¼›')
        
        return content.strip()
    
    def _create_fallback_content(self, 
                               knowledge_point: Dict[str, Any],
                               segment_text: str,
                               template_result: TemplateSelectionResult) -> Dict[str, str]:
        """åˆ›å»ºfallbackå†…å®¹"""
        content = {}
        concept_name = knowledge_point.get('concept_name', 'æœªå‘½åæ¦‚å¿µ')
        
        # ä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºåŸºç¡€å†…å®¹
        for section in template_result.merged_sections:
            section_title = section.title
            
            if section_title == "æ ¸å¿ƒå®šä¹‰":
                content[section_title] = f"{concept_name}çš„å®šä¹‰éœ€è¦ä»è¯¾ç¨‹å†…å®¹ä¸­è¡¥å……ã€‚"
            elif section_title == "è®°å¿†è¦ç‚¹":
                content[section_title] = f"ğŸ”® é‡è¦æ¦‚å¿µ â€” {concept_name}\nğŸ“± å®é™…åº”ç”¨ â€” éœ€è¦ç»“åˆå…·ä½“æƒ…å†µ\nğŸ’¡ æ³¨æ„äº‹é¡¹ â€” æ³¨æ„ä¸ç›¸å…³æ¦‚å¿µçš„åŒºåˆ«"
            else:
                content[section_title] = f"å…³äº{section_title}çš„å†…å®¹éœ€è¦ä»è¯¾ç¨‹å†…å®¹ä¸­è¡¥å……ã€‚"
        
        return content
    
    def _create_basic_content(self, 
                            knowledge_point: Dict[str, Any],
                            segment_text: str,
                            template_result: TemplateSelectionResult) -> Dict[str, str]:
        """åˆ›å»ºåŸºç¡€å†…å®¹ï¼ˆä¸ä½¿ç”¨AIï¼‰"""
        content = {}
        concept_name = knowledge_point.get('concept_name', 'æœªå‘½åæ¦‚å¿µ')
        core_definition = knowledge_point.get('core_definition', '')
        
        # ä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºå†…å®¹
        for section in template_result.merged_sections:
            section_title = section.title
            
            if section_title == "æ ¸å¿ƒå®šä¹‰" and core_definition:
                content[section_title] = core_definition
            elif section_title == "è®°å¿†è¦ç‚¹":
                importance = knowledge_point.get('importance_level', 'ä¸­')
                content[section_title] = f"ğŸ”® {importance}é‡è¦æ¦‚å¿µ â€” {concept_name}\nğŸ“± åº”ç”¨åœºæ™¯ â€” æ ¹æ®å…·ä½“æƒ…å†µç¡®å®š\nğŸ’¡ é‡è¦æé†’ â€” æ³¨æ„å‡†ç¡®ç†è§£å’Œåº”ç”¨"
            else:
                # å°è¯•ä»å­—å¹•æ–‡æœ¬ä¸­æå–ç›¸å…³å†…å®¹
                relevant_text = self._extract_relevant_text(segment_text, section_title, concept_name)
                content[section_title] = relevant_text if relevant_text else f"*{section_title}å†…å®¹å¾…è¡¥å……*"
        
        return content
    
    def _extract_relevant_text(self, text: str, section_title: str, concept_name: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–ç›¸å…³å†…å®¹"""
        if not text:
            return ""
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        keywords = self._get_section_keywords(section_title)
        
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        relevant_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¦‚å¿µåç§°
            if concept_name in sentence:
                relevant_sentences.append(sentence)
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
            for keyword in keywords:
                if keyword in sentence:
                    relevant_sentences.append(sentence)
                    break
        
        if relevant_sentences:
            return "ã€‚".join(relevant_sentences[:3]) + "ã€‚"  # æœ€å¤š3å¥
        
        return ""
    
    def _fix_common_issues(self, content: str, errors: List[str]) -> str:
        """ä¿®å¤å¸¸è§é—®é¢˜"""
        fixed_content = content
        
        # ä¿®å¤YAMLå¤´éƒ¨é—®é¢˜
        if "ç¼ºå°‘YAMLå¤´éƒ¨" in errors:
            if not fixed_content.startswith('---'):
                fixed_content = '---\n' + fixed_content
        
        # ä¿®å¤YAMLç»“æ„é—®é¢˜
        if "YAMLå¤´éƒ¨æ ¼å¼é”™è¯¯" in errors:
            lines = fixed_content.split('\n')
            yaml_end_index = -1
            for i, line in enumerate(lines[1:], 1):
                if line.strip() == '---':
                    yaml_end_index = i
                    break
            
            if yaml_end_index == -1:
                # åœ¨ç¬¬ä¸€ä¸ªéYAMLè¡Œå‰æ·»åŠ ç»“æŸæ ‡è®°
                for i, line in enumerate(lines[1:], 1):
                    if not line.startswith((' ', 'title:', 'aliases:', 'tags:', 'source:')):
                        lines.insert(i, '---')
                        break
                fixed_content = '\n'.join(lines)
        
        # ä¿®å¤å¿…éœ€å­—æ®µé—®é¢˜
        for error in errors:
            if error.startswith("ç¼ºå°‘å¿…éœ€å­—æ®µï¼š"):
                field = error.split("ï¼š")[1]
                if field == 'concept_id':
                    fixed_content = fixed_content.replace(
                        '---\n', f'---\nconcept_id: "auto_generated_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}"\n'
                    )
        
        return fixed_content
    
    def get_available_templates(self) -> Dict[str, ConceptTemplate]:
        """è·å–æ‰€æœ‰å¯ç”¨æ¨¡æ¿"""
        return self.registry.get_all_templates()
    
    def get_template_info(self, template_type: str) -> Optional[Dict[str, Any]]:
        """è·å–æ¨¡æ¿ä¿¡æ¯"""
        template = self.registry.get_template(template_type)
        if not template:
            return None
        
        return {
            "type_name": template.type_name,
            "display_name": template.display_name,
            "description": template.description,
            "sections": [
                {
                    "title": section.title,
                    "required": section.required,
                    "description": section.description,
                    "importance_levels": section.importance_levels
                }
                for section in template.sections
            ],
            "priority": template.priority,
            "compatible_types": template.compatible_types
        }
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self._processing_stats.copy()
        if stats["total_processed"] > 0:
            stats["success_rate"] = stats["successful"] / stats["total_processed"]
        else:
            stats["success_rate"] = 0.0
        
        return stats
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self._processing_stats = {
            "total_processed": 0,
            "successful": 0,
            "failed": 0,
            "template_usage": {},
            "error_types": {}
        }
    
    def batch_process_knowledge_points(self,
                                     knowledge_points: List[Dict[str, Any]],
                                     segments: List[Any],  # Segmentå¯¹è±¡åˆ—è¡¨
                                     metadata: Dict[str, Any],
                                     ai_extraction_function: Optional[callable] = None,
                                     progress_callback: Optional[callable] = None) -> List[TemplateProcessingResult]:
        """
        æ‰¹é‡å¤„ç†çŸ¥è¯†ç‚¹
        
        Args:
            knowledge_points: çŸ¥è¯†ç‚¹åˆ—è¡¨
            segments: åˆ†æ®µåˆ—è¡¨
            metadata: å…ƒæ•°æ®ä¿¡æ¯
            ai_extraction_function: AIæå–å‡½æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            List[TemplateProcessingResult]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []
        
        # åˆ›å»ºçŸ¥è¯†ç‚¹IDåˆ°åˆ†æ®µçš„æ˜ å°„
        kp_to_segment = {}
        for segment in segments:
            for kp_id in segment.knowledge_points:
                kp_to_segment[kp_id] = segment
        
        total_count = len(knowledge_points)
        
        for i, kp in enumerate(knowledge_points):
            kp_id = kp.get('id', f'kp_{i}')
            
            # æ‰¾åˆ°å¯¹åº”çš„åˆ†æ®µ
            segment = kp_to_segment.get(kp_id)
            segment_text = segment.text if segment else ""
            
            # å¤„ç†çŸ¥è¯†ç‚¹
            result = self.process_knowledge_point(
                kp, segment_text, metadata, ai_extraction_function
            )
            results.append(result)
            
            # è°ƒç”¨è¿›åº¦å›è°ƒ
            if progress_callback:
                progress_callback(i + 1, total_count, result.success)
        
        return results
